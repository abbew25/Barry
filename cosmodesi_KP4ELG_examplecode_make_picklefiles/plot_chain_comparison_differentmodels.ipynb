{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6d568e-827b-491d-a651-f12f31bb17f6",
   "metadata": {},
   "source": [
    "## import stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7470de3-44ad-496f-bc08-689c0276da32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "\n",
    "CV = True \n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-broadbandpoly2/output/desi_kp4_abacus_cubic_ELG-broadbandpoly2.fitter.pkl\"\n",
    "\n",
    "pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-polybroadband2/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-polybroadband2.fitter.pkl\"\n",
    "    \n",
    "pfns = [\n",
    "        pfn1, \n",
    "        pfn2\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d0998-d23e-44b9-8ef0-f22fe1c85d22",
   "metadata": {},
   "source": [
    "## looping through and saving the chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8aaac8-7f4f-4067-9475-f6712697d7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']:\n",
    "            continue \n",
    "            \n",
    "        if 'Pk' not in extra['name']:\n",
    "            continue \n",
    "#         CVfile = '' # making sure we adjust this parameter if CV or not and skipping depending on value of CV \n",
    "#         if CV:\n",
    "#             CVfile = 'CV'\n",
    "#             if \"CV\" not in extra[\"name\"] or \"Pk\" not in extra[\"name\"]:\n",
    "#                continue\n",
    "#         else:\n",
    "#             if \"CV\" in extra['name']:\n",
    "#                 continue \n",
    "#             if \"Pk\" not in extra['name']:\n",
    "#                 continue \n",
    "                \n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        extraname = ''\n",
    "        if i == 1:\n",
    "            extraname = ' beta model'\n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extra.pop(\"realisation\", 'mean')#+ extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "        \n",
    "        #print(extra)\n",
    "\n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        #print('test')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec33fa-2fd6-4f9d-b359-a6910e4eee22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "truth = {\"$\\\\alpha$\": 1.0, \"$\\\\epsilon$\": 0, \"$\\\\alpha_\\\\perp$\": 1.0, \"$\\\\alpha_\\\\parallel$\": 1.0}\n",
    "#truth = {\"$\\\\alpha_\\\\parallel$\": 1.0, \"$\\\\alpha_\\\\perp$\": 1.0, \"$\\\\alpha_\\\\perp$\": 1.0, \"$\\\\alpha_\\\\parallel$\": 1.0}\n",
    "\n",
    "\n",
    "truth[\"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\"] = 1.0\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "parameters.append(\"$\\\\Sigma_{nl,||}$\")\n",
    "parameters.append(\"$\\\\Sigma_{nl,\\\\perp}$\")\n",
    "parameters.append(\"$\\\\Sigma_s$\")\n",
    "\n",
    "print(dir(c))\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2] + [parameters[4]],\n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(12,12), \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40092733-6b7e-4e00-bb83-1de82ee9fdc3",
   "metadata": {},
   "source": [
    "## import stuff (now plotting with varying Omega_m, Neff) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f56e4-70a4-4af4-ad2b-07b9eb28b434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "\n",
    "CV = True \n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_omfree/output/desi_kp4_abacus_cubic_ELG_omfree.fitter.pkl\"\n",
    "\n",
    "pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_nefffree/output/desi_kp4_abacus_cubic_ELG_nefffree.fitter.pkl\"\n",
    "    \n",
    "pfns = [\n",
    "        pfn1, \n",
    "        pfn2\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ee723-f225-431d-8dbb-c2f7fc2d0e65",
   "metadata": {},
   "source": [
    "## do the loops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c1438-75de-41d4-a63e-62c57f38660e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']:\n",
    "            continue \n",
    "            \n",
    "        # if 'Pk' not in extra['name']:\n",
    "        #     continue \n",
    "#         CVfile = '' # making sure we adjust this parameter if CV or not and skipping depending on value of CV \n",
    "#         if CV:\n",
    "#             CVfile = 'CV'\n",
    "#             if \"CV\" not in extra[\"name\"] or \"Pk\" not in extra[\"name\"]:\n",
    "#                continue\n",
    "#         else:\n",
    "#             if \"CV\" in extra['name']:\n",
    "#                 continue \n",
    "#             if \"Pk\" not in extra['name']:\n",
    "#                 continue \n",
    "                \n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        extraname = ''\n",
    "        if i == 0:\n",
    "            extraname = ' om model'\n",
    "        if i == 1: \n",
    "            extraname = ' neff model'\n",
    "            \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extra.pop(\"realisation\", 'mean')#+ extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "        \n",
    "        #print(extra)\n",
    "        #print(df)\n",
    "\n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        #print('test')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb22f68-344b-4483-8279-8cfff32e7443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']:\n",
    "            continue \n",
    "            \n",
    "        # if 'Pk' not in extra['name']:\n",
    "        #     continue \n",
    "#         CVfile = '' # making sure we adjust this parameter if CV or not and skipping depending on value of CV \n",
    "#         if CV:\n",
    "#             CVfile = 'CV'\n",
    "#             if \"CV\" not in extra[\"name\"] or \"Pk\" not in extra[\"name\"]:\n",
    "#                continue\n",
    "#         else:\n",
    "#             if \"CV\" in extra['name']:\n",
    "#                 continue \n",
    "#             if \"Pk\" not in extra['name']:\n",
    "#                 continue \n",
    "                \n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        extraname = ''\n",
    "        if i == 0:\n",
    "            extraname = ' om model'\n",
    "        if i == 1: \n",
    "            extraname = ' neff model'\n",
    "            \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extra.pop(\"realisation\", 'mean')#+ extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "        \n",
    "        #print(extra)\n",
    "        #print(df)\n",
    "\n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        #print('test')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d8ef19-d45a-4b29-96c5-27ede90e089b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "truth = {\"$\\\\alpha$\": 1.0, \"$\\\\epsilon$\": 0, \"$\\\\alpha_\\\\perp$\": 1.0, \"$\\\\alpha_\\\\parallel$\": 1.0}\n",
    "\n",
    "truth[\"$\\\\Omega_m$\"] = 0.31\n",
    "truth[\"$N_{\\\\mathrm{eff}}$\"] = 3.044\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "# parameters.append(\"$\\\\Sigma_{nl,||}$\")\n",
    "# parameters.append(\"$\\\\Sigma_{nl,\\\\perp}$\")\n",
    "# parameters.append(\"$\\\\Sigma_s$\")\n",
    "\n",
    "print(dir(c))\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2]+parameters[4:],\n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(9,9), \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9acda-e123-46e4-a19c-5cd5cf21fd23",
   "metadata": {},
   "source": [
    "## attempt 3 - best nuisance parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ce648-e0f6-41cf-8c8e-c8cfc0e9393a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_bestnuisance/output/desi_kp4_abacus_cubic_ELG_bestnuisance.fitter.pkl\"\n",
    " \n",
    "pfns = [\n",
    "        pfn1, \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7db988-5a51-4f84-aa06-d8d9f60411e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']:\n",
    "            continue \n",
    "            \n",
    "        # if 'Pk' not in extra['name']:\n",
    "        #     continue \n",
    "#         CVfile = '' # making sure we adjust this parameter if CV or not and skipping depending on value of CV \n",
    "#         if CV:\n",
    "#             CVfile = 'CV'\n",
    "#             if \"CV\" not in extra[\"name\"] or \"Pk\" not in extra[\"name\"]:\n",
    "#                continue\n",
    "#         else:\n",
    "#             if \"CV\" in extra['name']:\n",
    "#                 continue \n",
    "#             if \"Pk\" not in extra['name']:\n",
    "#                 continue \n",
    "                \n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extra.pop(\"realisation\", 'mean')#+ extraname)\n",
    "        #extra[\"name\"] = extra['name'] + extraname\n",
    "        \n",
    "        #print(extra)\n",
    "        #print(df)\n",
    "\n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        #print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab4dc6-94f3-4e38-87a8-0c059950ea70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#truth = {\"$\\\\alpha$\": 1.0, \"$\\\\epsilon$\": 0, \"$\\\\alpha_\\\\perp$\": 1.0, \"$\\\\alpha_\\\\parallel$\": 1.0}\n",
    "\n",
    "#truth[\"$\\\\Omega_m$\"] = 0.31\n",
    "#truth[\"$N_{\\\\mathrm{eff}}$\"] = 3.044\n",
    "\n",
    "#parameters = [names for names in truth]\n",
    "# parameters.append(\"$\\\\Sigma_{nl,||}$\")\n",
    "# parameters.append(\"$\\\\Sigma_{nl,\\\\perp}$\")\n",
    "# parameters.append(\"$\\\\Sigma_s$\")\n",
    "\n",
    "print(dir(c))\n",
    "\n",
    "c.plotter.plot(\n",
    "    #truth=truth,\n",
    "        parameters = [\"$\\\\Sigma_s$\", \"$\\\\Sigma_{nl,\\\\perp}$\", \"$\\Sigma_{nl,||}$\"],\n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(9,9), \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5e6df-8453-4028-9bc1-74e529bf16ec",
   "metadata": {},
   "source": [
    "## now looking at fits to 6 c003 cubic mocks with c000 clustering power spectrum measurements (template is c000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77dd937-fa71-432f-aec5-611df7efa41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-c003/output/desi_kp4_abacus_cubic_ELG-c003.fitter.pkl\"\n",
    "\n",
    "pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003.fitter.pkl\"\n",
    "    \n",
    "pfns = [\n",
    "        pfn1, \n",
    "        pfn2\n",
    "]\n",
    "\n",
    "\n",
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']: # making sure we only get results from recon \n",
    "            continue  \n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "        \n",
    "        print(df)\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extraname = ''\n",
    "        if i == 1:\n",
    "            extraname = 'phaseshift'\n",
    "            \n",
    "        extra.pop(\"realisation\", 'mean' + extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "        \n",
    "        #print(extra)\n",
    "        #print(df)\n",
    "\n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        #print('test')\n",
    "    \n",
    "couplingterm = 1.0/0.22710731766023898\n",
    "beta_approx = (3.044/(3.044+couplingterm) * (3.7+couplingterm)/3.7) \n",
    "\n",
    "alpha, eps = model.get_reverse_alphas(0.99906947, 0.98927880) \n",
    "\n",
    "truth = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\alpha_\\\\parallel$\": 0.99906947, \"$\\\\alpha_\\\\perp$\": 0.98927880, \n",
    "         \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": beta_approx}\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2]+parameters[4:], \n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(9,9), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8a445-b7ec-415c-ad04-b3c02850335f",
   "metadata": {},
   "source": [
    "## now looking at fits to 6 c003 cubic mocks with c000 clustering power spectrum measurements (template is c003!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137942f-8497-4929-b392-1fb78fcfb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-c003-template003/output/desi_kp4_abacus_cubic_ELG-c003-template003.fitter.pkl\"\n",
    "\n",
    "pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-template003/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-template003.fitter.pkl\"\n",
    "    \n",
    "pfns = [\n",
    "        pfn1, \n",
    "        pfn2\n",
    "]\n",
    "\n",
    "\n",
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']: # making sure we only get results from recon \n",
    "            continue  \n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "        \n",
    "        print(df)\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extraname = ''\n",
    "        if i == 1:\n",
    "            extraname = ' phaseshift'\n",
    "            \n",
    "        extra.pop(\"realisation\", 'mean' + extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "        \n",
    "        #print(extra)\n",
    "        #print(df)\n",
    "\n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        #print('test')\n",
    "    \n",
    "#couplingterm = 1.0/0.22710731766023898\n",
    "#beta_approx = (3.044/(3.044+couplingterm) * (3.7+couplingterm)/3.7) \n",
    "\n",
    "alpha, eps = model.get_reverse_alphas(1.02131937, 1.01131066) \n",
    "\n",
    "truth = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\alpha_\\\\parallel$\": 1.02131937, \"$\\\\alpha_\\\\perp$\": 1.01131066, \n",
    "         \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.0}\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2]+parameters[4:], \n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(9,9), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02301399-dc68-414f-ae5b-cda4f4e75838",
   "metadata": {},
   "source": [
    "## comparing smoothing methods results for phase shift constraints for c000 ELG mocks with c000 clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecdb6c4-8bbe-4ab8-91d9-7b5df4279a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree.fitter.pkl\"\n",
    "\n",
    "pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-wallisch18/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-wallisch18.fitter.pkl\"\n",
    "\n",
    "pfn3 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-eh1998/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-eh1998.fitter.pkl\"\n",
    "\n",
    "pfns = [\n",
    "    \n",
    "        pfn1, \n",
    "        pfn2,\n",
    "        pfn3\n",
    "]\n",
    "\n",
    "\n",
    "c = ChainConsumer() \n",
    "\n",
    "fig, axes = plt.subplots(3, 2, sharex=True, sharey=True)\n",
    "\n",
    "#ks = np.logspace(-3, 2, 100, base=10)\n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    count = 0\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']: # making sure we only get results from recon \n",
    "            continue  \n",
    "            \n",
    "        # if 'CV' in extra['name']:\n",
    "        #     continue\n",
    "            \n",
    "        if 'Xi' in extra['name']:\n",
    "            continue\n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extraname = ''\n",
    "        if i == 0:\n",
    "            extraname = ' Hinton17'\n",
    "        elif i == 1:\n",
    "            extraname = ' Wallisch18'\n",
    "        elif i == 2:\n",
    "            extraname = ' eh1998'\n",
    "            \n",
    "        if 'CV' in extra['name']:\n",
    "            extraname = extraname + ' CV'\n",
    "            \n",
    "        extra.pop(\"realisation\", 'mean' + extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "       \n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        \n",
    "        model.set_data(data)\n",
    "        r_s = model.camb.get_data()[\"r_s\"]\n",
    "        max_post = posterior.argmax()\n",
    "        params = df.loc[max_post]\n",
    "        params_dict = model.get_param_dict(chain[max_post])\n",
    "        for name, val in params_dict.items():\n",
    "            model.set_default(name, val)\n",
    "\n",
    "        new_chi_squared, dof, bband, mods, smooths = model.plot(params_dict, display=False)\n",
    "        k = model.data[0][\"ks\"]\n",
    "        axes[i][count].scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        axes[i][count].plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        axes[i][count].legend()\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "plt.subplots_adjust(wspace=0, hspace=0)        \n",
    "        \n",
    "        \n",
    "#couplingterm = 1.0/0.22710731766023898\n",
    "#beta_approx = (3.044/(3.044+couplingterm) * (3.7+couplingterm)/3.\n",
    "#alpha, eps = model.get_reverse_alphas(1.02131937, 1.01131066) \n",
    "\n",
    "\n",
    "\n",
    "truth = {\"$\\\\alpha$\": 1.0, \"$\\\\epsilon$\": 0.0, \"$\\\\alpha_\\\\parallel$\": 1, \"$\\\\alpha_\\\\perp$\": 1,\n",
    "         \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.0}\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(r'$k$ $\\mathrm{Mpc}^{-1} h$')\n",
    "plt.ylabel(r'$k P_0(k)$ $\\mathrm{Mpc}^2 h^{-2}$')\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2]+parameters[4:], \n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(11, 11), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e878388-e45d-46ad-8805-75eb1ad8226a",
   "metadata": {},
   "source": [
    "## comparing smoothing methods results for phase shift constraints for c003 ELG mocks with c000 clustering, c000 template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855eba6-03e1-4860-aa3e-f464d41644c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003.fitter.pkl\"\n",
    "\n",
    "pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-Wallisch/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-Wallisch.fitter.pkl\"\n",
    "\n",
    "pfn3 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-eh1998/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-eh1998.fitter.pkl\"\n",
    "\n",
    "\n",
    "# pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-template003/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-template003.fitter.pkl\"\n",
    "\n",
    "# pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-template003-Wallisch/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-template003-Wallisch.fitter.pkl\"\n",
    "\n",
    "# pfn3 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-template003-eh1998/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-template003-eh1998.fitter.pkl\"\n",
    "\n",
    "pfns = [\n",
    "        pfn1, \n",
    "        pfn2,\n",
    "        pfn3\n",
    "]\n",
    "\n",
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']: # making sure we only get results from recon \n",
    "            continue  \n",
    "            \n",
    "        #if 'CV' not in extra['name']:\n",
    "        #    continue\n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "        \n",
    "        #print(df)\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extraname = ''\n",
    "        if i == 0:\n",
    "            extraname = ' Hinton17'\n",
    "        elif i == 1:\n",
    "            extraname = ' Wallisch18'\n",
    "        elif i == 2:\n",
    "            extraname = ' eh1998'\n",
    "            \n",
    "        extra.pop(\"realisation\", 'mean' + extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "        \n",
    "        #print(extra)\n",
    "        #print(df)\n",
    "\n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        #print('test')\n",
    "        \n",
    "        model.set_data(data)\n",
    "        r_s = model.camb.get_data()[\"r_s\"]\n",
    "        max_post = posterior.argmax()\n",
    "        params = df.loc[max_post]\n",
    "        params_dict = model.get_param_dict(chain[max_post])\n",
    "        for name, val in params_dict.items():\n",
    "            model.set_default(name, val)\n",
    "\n",
    "        new_chi_squared, dof, bband, mods, smooths = model.plot(params_dict, display=False)\n",
    "        k = model.data[0][\"ks\"]\n",
    "        #plt.scatter(k, model.data[0]['pk0'][0]- smooths[0][0], label= extraname + ' data')\n",
    "        plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        \n",
    "    \n",
    "couplingterm = 1.0/0.22710731766023898\n",
    "beta_approx = (3.044/(3.044+couplingterm) * (3.7+couplingterm)/3.7) \n",
    "\n",
    "alpha, eps = model.get_reverse_alphas(0.99906947, 0.98927880) \n",
    "\n",
    "truth = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\alpha_\\\\parallel$\": 0.99906947, \"$\\\\alpha_\\\\perp$\": 0.98927880, \n",
    "         \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": beta_approx}\n",
    "\n",
    "\n",
    "# alpha, eps = model.get_reverse_alphas(1.02131937, 1.01131066) \n",
    "\n",
    "# truth = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\alpha_\\\\parallel$\": 1.02131937, \"$\\\\alpha_\\\\perp$\": 1.01131066, \n",
    "#          \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.0}\n",
    "\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2]+parameters[4:],#+[\"$\\\\beta$\"], \n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(12, 12), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113aa5be-a683-46e5-92de-6b98e474a4d4",
   "metadata": {},
   "source": [
    "## plot results with Hinton dewiggling - different broadband settings, c000/grid000 mocks - power spectrum only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c206fe-83f8-4300-bf87-9b8c04c892a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG/output/desi_kp4_abacus_cubic_ELG.fitter.pkl\"\n",
    "\n",
    "# pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_splinebroadband/output/desi_kp4_abacus_cubic_ELG_splinebroadband.fitter.pkl\"\n",
    "\n",
    "pfn3 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-broadbandpoly/output/desi_kp4_abacus_cubic_ELG-broadbandpoly.fitter.pkl\"\n",
    "\n",
    "pfns = [\n",
    "    \n",
    "        pfn1, \n",
    "        #pfn2,\n",
    "        pfn3\n",
    "]\n",
    "\n",
    "\n",
    "c = ChainConsumer() \n",
    "\n",
    "# fig, axes = plt.subplots(3, 2, sharex=True, sharey=True)\n",
    "\n",
    "# ks = np.logspace(-3, 2, 100, base=10)\n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    #print(i)\n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    count = 0\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']: # making sure we only get results from recon \n",
    "            continue  \n",
    "            \n",
    "        # if 'CV' in extra['name']:\n",
    "        #     continue\n",
    "            \n",
    "        if 'Xi' in extra['name']:\n",
    "            continue\n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extraname = ''\n",
    "        if i == 0:\n",
    "            extraname = ' None'\n",
    "        elif i == 1:\n",
    "            extraname = ' poly'\n",
    "        #elif i == 2:\n",
    "         #   extraname = ' poly'\n",
    "         #   \n",
    "        if 'CV' in extra['name']:\n",
    "            extraname = extraname + ' CV'\n",
    "            \n",
    "        extra.pop(\"realisation\", 'mean' + extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "       \n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        \n",
    "        model.set_data(data)\n",
    "        r_s = model.camb.get_data()[\"r_s\"]\n",
    "        max_post = posterior.argmax()\n",
    "        params = df.loc[max_post]\n",
    "        params_dict = model.get_param_dict(chain[max_post])\n",
    "        for name, val in params_dict.items():\n",
    "            model.set_default(name, val)\n",
    "\n",
    "        new_chi_squared, dof, bband, mods, smooths = model.plot(params_dict, display=False)\n",
    "        k = model.data[0][\"ks\"]\n",
    "        # axes[i][count].scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        # axes[i][count].plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # axes[i][count].legend()\n",
    "        \n",
    "        #plt.scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        plt.legend()\n",
    "        count += 1\n",
    "\n",
    "        \n",
    "        # if i == 0:\n",
    "        #     default = smooths[0][0]\n",
    "        # # plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # plt.plot(k, (smooths[0][0]/default)*k, label=extraname)\n",
    "        \n",
    "        \n",
    "        \n",
    "# plt.subplots_adjust(wspace=0, hspace=0)        \n",
    "        \n",
    "        \n",
    "#couplingterm = 1.0/0.22710731766023898\n",
    "#beta_approx = (3.044/(3.044+couplingterm) * (3.7+couplingterm)/3.\n",
    "#alpha, eps = model.get_reverse_alphas(1.02131937, 1.01131066) \n",
    "\n",
    "\n",
    "\n",
    "truth = {\"$\\\\alpha$\": 1.0, \"$\\\\epsilon$\": 0.0, \"$\\\\alpha_\\\\parallel$\": 1, \"$\\\\alpha_\\\\perp$\": 1,\n",
    "        }# \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.0}\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel(r'$k$ $\\mathrm{Mpc}^{-1} h$')\n",
    "# plt.ylabel(r'$k P_0(k)$ $\\mathrm{Mpc}^2 h^{-2}$')\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2]+parameters[4:], \n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(11, 11), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599cb02-33af-4069-b6c3-5f2fb99df916",
   "metadata": {},
   "source": [
    "## plot results with Hinton dewiggling - different broadband settings, c003/grid000/template000/003 mocks - power spectrum only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68db293-cc49-4f5d-ac6c-4913ee01bc86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-c003/output/desi_kp4_abacus_cubic_ELG-c003.fitter.pkl\"\n",
    "\n",
    "#pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-splinebroadband/output/desi_kp4_abacus_cubic_ELG_phaseshiftfree-splinebroadband.fitter.pkl\"\n",
    "\n",
    "pfn3 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-c003-broadbandpoly/output/desi_kp4_abacus_cubic_ELG-c003-broadbandpoly.fitter.pkl\"\n",
    "\n",
    "pfns = [\n",
    "    \n",
    "        pfn1, \n",
    "        #pfn2,\n",
    "        pfn3\n",
    "]\n",
    "\n",
    "\n",
    "c = ChainConsumer() \n",
    "\n",
    "# fig, axes = plt.subplots(3, 2, sharex=True, sharey=True)\n",
    "\n",
    "# ks = np.logspace(-3, 2, 100, base=10)\n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    #print(i)\n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    count = 0\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']: # making sure we only get results from recon \n",
    "            continue  \n",
    "            \n",
    "        # if 'CV' in extra['name']:\n",
    "        #     continue\n",
    "            \n",
    "        if 'Xi' in extra['name']:\n",
    "            continue\n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extraname = ''\n",
    "        if i == 0:\n",
    "            extraname = ' None'\n",
    "        elif i == 1:\n",
    "            extraname = ' poly'\n",
    "#         elif i == 2:\n",
    "#             extraname = ' poly'\n",
    "            \n",
    "        if 'CV' in extra['name']:\n",
    "            extraname = extraname + ' CV'\n",
    "            \n",
    "        extra.pop(\"realisation\", 'mean' + extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "       \n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        \n",
    "        model.set_data(data)\n",
    "        r_s = model.camb.get_data()[\"r_s\"]\n",
    "        max_post = posterior.argmax()\n",
    "        params = df.loc[max_post]\n",
    "        params_dict = model.get_param_dict(chain[max_post])\n",
    "        for name, val in params_dict.items():\n",
    "            model.set_default(name, val)\n",
    "\n",
    "        new_chi_squared, dof, bband, mods, smooths = model.plot(params_dict, display=False)\n",
    "        k = model.data[0][\"ks\"]\n",
    "        # axes[i][count].scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        # axes[i][count].plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # axes[i][count].legend()\n",
    "        \n",
    "        #plt.scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        plt.legend()\n",
    "        count += 1\n",
    "\n",
    "        \n",
    "        # if i == 0:\n",
    "        #     default = smooths[0][0]\n",
    "        # # plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # plt.plot(k, (smooths[0][0]/default)*k, label=extraname)\n",
    "        \n",
    "        \n",
    "        \n",
    "# plt.subplots_adjust(wspace=0, hspace=0)        \n",
    "        \n",
    "        \n",
    "couplingterm = 1.0/0.22710731766023898\n",
    "beta_approx = (3.044/(3.044+couplingterm) * (3.7+couplingterm)/3.7) \n",
    "\n",
    "alpha, eps = model.get_reverse_alphas(0.99906947, 0.98927880) \n",
    "\n",
    "truth = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\alpha_\\\\parallel$\": 0.99906947, \"$\\\\alpha_\\\\perp$\": 0.98927880, \n",
    "        }#\"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": beta_approx}\n",
    "\n",
    "# alpha, eps = model.get_reverse_alphas(1.02131937, 1.01131066) \n",
    "\n",
    "# truth = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\alpha_\\\\parallel$\": 1.02131937, \"$\\\\alpha_\\\\perp$\": 1.01131066, \n",
    "#         }# \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.0}\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel(r'$k$ $\\mathrm{Mpc}^{-1} h$')\n",
    "# plt.ylabel(r'$k P_0(k)$ $\\mathrm{Mpc}^2 h^{-2}$')\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2]+parameters[4:], \n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(11, 11), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8272ca71-a3d5-4044-a4a0-493de04d2315",
   "metadata": {},
   "source": [
    "## plot results with Hinton dewiggling - broadband_type = poly, c000/grid003/template000/003 mocks - power spectrum only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62049c0c-7e6c-4207-bbdd-9de4a1718274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-c000_grid003-template000/output/desi_kp4_abacus_cubic_ELG-c000_grid003-template000.fitter.pkl\"\n",
    "\n",
    "pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-c000_grid003-template000-phaseshift/output/desi_kp4_abacus_cubic_ELG-c000_grid003-template000-phaseshift.fitter.pkl\"\n",
    "\n",
    "pfn3 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-c000_grid003-template003/output/desi_kp4_abacus_cubic_ELG-c000_grid003-template003.fitter.pkl\"\n",
    "\n",
    "pfn4 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-c000_grid003-template003-phaseshift/output/desi_kp4_abacus_cubic_ELG-c000_grid003-template003-phaseshift.fitter.pkl\"\n",
    "\n",
    "\n",
    "pfns = [\n",
    "    \n",
    "        # pfn1, \n",
    "        # pfn2,\n",
    "        pfn3,\n",
    "        pfn4, \n",
    "]\n",
    "\n",
    "\n",
    "c = ChainConsumer() \n",
    "\n",
    "# fig, axes = plt.subplots(3, 2, sharex=True, sharey=True)\n",
    "\n",
    "# ks = np.logspace(-3, 2, 100, base=10)\n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    #print(i)\n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    count = 0\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']: # making sure we only get results from recon \n",
    "            continue  \n",
    "            \n",
    "        # if 'CV' in extra['name']:\n",
    "        #     continue\n",
    "            \n",
    "        if 'Xi' in extra['name']:\n",
    "            continue\n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extraname = ''\n",
    "        \n",
    "        # if i == 0:\n",
    "        #     extraname = ' None'\n",
    "        # elif i == 1:\n",
    "        #     extraname = ' poly'\n",
    "#         elif i == 2:\n",
    "#             extraname = ' poly'\n",
    "            \n",
    "#         if 'CV' in extra['name']:\n",
    "#             extraname = extraname + ' CV'\n",
    "        if i == 1: \n",
    "            extraname = ' beta(Neff)'\n",
    "            \n",
    "        extra.pop(\"realisation\", 'mean' + extraname)\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "       \n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        \n",
    "        # model.set_data(data)\n",
    "        # r_s = model.camb.get_data()[\"r_s\"]\n",
    "        # max_post = posterior.argmax()\n",
    "        # params = df.loc[max_post]\n",
    "        # params_dict = model.get_param_dict(chain[max_post])\n",
    "        # for name, val in params_dict.items():\n",
    "        #     model.set_default(name, val)\n",
    "\n",
    "        # new_chi_squared, dof, bband, mods, smooths = model.plot(params_dict, display=False)\n",
    "        # k = model.data[0][\"ks\"]\n",
    "        # axes[i][count].scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        # axes[i][count].plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # axes[i][count].legend()\n",
    "        \n",
    "        #plt.scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        # plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # plt.legend()\n",
    "        # count += 1\n",
    "\n",
    "        \n",
    "        # if i == 0:\n",
    "        #     default = smooths[0][0]\n",
    "        # # plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # plt.plot(k, (smooths[0][0]/default)*k, label=extraname)\n",
    "        \n",
    "        \n",
    "    \n",
    "# alpha_para, alpha_perp, beta = 0.97912566, 0.98881584, 1.0\n",
    "\n",
    "alpha_para, alpha_perp = 1.00093140, 1.01083738\n",
    "couplingterm = 1.0/0.22710731766023898\n",
    "beta = (3.044/(3.044+couplingterm)) / (3.7/(3.7+couplingterm))  \n",
    "\n",
    "alpha, eps = model.get_reverse_alphas(alpha_para, alpha_perp)\n",
    "   \n",
    "truth = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\alpha_\\\\parallel$\": alpha_para, \"$\\\\alpha_\\\\perp$\": alpha_perp, \n",
    "        \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": beta}\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel(r'$k$ $\\mathrm{Mpc}^{-1} h$')\n",
    "# plt.ylabel(r'$k P_0(k)$ $\\mathrm{Mpc}^2 h^{-2}$')\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2]+parameters[4:], \n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(11, 11), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55abfad-4746-402c-befb-5aa341c431cb",
   "metadata": {},
   "source": [
    "# some initial results with secondgen mocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682350de-1bdb-4283-ad08-4cbda7164121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237c741-cd52-4c6c-976b-ca16ab4445c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "\n",
    "path_p1 = '/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/'\n",
    "\n",
    "# ELGs z = 0.8 - 1.1 \n",
    "pfn1 = path_p1 + \"desi_kp4_abacus_cubic_ELG-secondgenmocks/output/desi_kp4_abacus_cubic_ELG-secondgenmocks.fitter.pkl\"\n",
    "pfn2 = path_p1 + \"desi_kp4_abacus_cubic_ELG-secondgenmocks-phaseshift/output/desi_kp4_abacus_cubic_ELG-secondgenmocks-phaseshift.fitter.pkl\"\n",
    "\n",
    "# ELGs z = 1.1 - 1.6 \n",
    "pfn3 = path_p1 + \"desi_kp4_abacus_cubic_ELG-secondgenmocks-z11-16/output/desi_kp4_abacus_cubic_ELG-secondgenmocks-z11-16.fitter.pkl\"\n",
    "pfn4 = path_p1 + \"desi_kp4_abacus_cubic_ELG-secondgenmocks-phaseshift-z11-16/output/desi_kp4_abacus_cubic_ELG-secondgenmocks-phaseshift-z11-16.fitter.pkl\"\n",
    "\n",
    "# LRGs z = 0.4 - 0.6 \n",
    "pfn5 = path_p1 + \"desi_kp4_abacus_cubic_LRG-secondgenmocks-z04-06/output/desi_kp4_abacus_cubic_LRG-secondgenmocks-z04-06.fitter.pkl\"\n",
    "pfn6 = path_p1 + \"desi_kp4_abacus_cubic_LRG-secondgenmocks-phaseshift-z04-06/output/desi_kp4_abacus_cubic_LRG-secondgenmocks-phaseshift-z04-06.fitter.pkl\"\n",
    "\n",
    "# LRGs z = 0.6 - 0.8 \n",
    "pfn7 = path_p1 + \"desi_kp4_abacus_cubic_LRG-secondgenmocks-z06-08/output/desi_kp4_abacus_cubic_LRG-secondgenmocks-z06-08.fitter.pkl\"\n",
    "pfn8 = path_p1 + \"desi_kp4_abacus_cubic_LRG-secondgenmocks-phaseshift-z06-08/output/desi_kp4_abacus_cubic_LRG-secondgenmocks-phaseshift-z06-08.fitter.pkl\"\n",
    "\n",
    "# LRGs z = 0.8 - 1.1 \n",
    "pfn9 = path_p1 + \"desi_kp4_abacus_cubic_LRG-secondgenmocks-z08-11/output/desi_kp4_abacus_cubic_LRG-secondgenmocks-z08-11.fitter.pkl\"\n",
    "pfn10 = path_p1 + \"desi_kp4_abacus_cubic_LRG-secondgenmocks-phaseshift-z08-11/output/desi_kp4_abacus_cubic_LRG-secondgenmocks-phaseshift-z08-11.fitter.pkl\"\n",
    "\n",
    "# QSOs z = 0.8 - 2.1 \n",
    "pfn11 = path_p1 + \"desi_kp4_abacus_cubic_QSO-secondgenmocks-z08-21/output/desi_kp4_abacus_cubic_QSO-secondgenmocks-z08-21.fitter.pkl\"\n",
    "pfn12 = path_p1 + \"desi_kp4_abacus_cubic_QSO-secondgenmocks-phaseshift-z08-21/output/desi_kp4_abacus_cubic_QSO-secondgenmocks-phaseshift-z08-21.fitter.pkl\"\n",
    "\n",
    "# names = ['ELG z = 0.8 - 1.1', 'ELG z = 1.1 - 1.6', 'LRG z = 0.4 - 0.6', \n",
    " #         'LRG z = 0.6 - 0.8', 'LRG z = 0.8 - 1.1', 'QSO z = 0.8 - 2.1']\n",
    "\n",
    "pfns = [\n",
    "    \n",
    "        # pfn1, \n",
    "         # pfn2,\n",
    "        # pfn3,\n",
    "        # pfn4,\n",
    "        # pfn5, \n",
    "        # pfn6,\n",
    "        # pfn7, \n",
    "        #  pfn8,\n",
    "        # pfn9, \n",
    "        # pfn10,\n",
    "        pfn11, \n",
    "        pfn12,\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    #print(i)\n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    count = 0\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']: # making sure we only get results from recon \n",
    "            continue  \n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extraname = ''\n",
    "\n",
    "        if i%2 == 1: \n",
    "            extraname = ' beta(Neff)'\n",
    "            \n",
    "        extra.pop(\"realisation\", 'mean' + extraname)\n",
    "        # extra[\"name\"] = names[i] + extraname\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "        \n",
    "       \n",
    "        c.add_chain(df, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        \n",
    "        # model.set_data(data)\n",
    "        # r_s = model.camb.get_data()[\"r_s\"]\n",
    "        # max_post = posterior.argmax()\n",
    "        # params = df.loc[max_post]\n",
    "        # params_dict = model.get_param_dict(chain[max_post])\n",
    "        # for name, val in params_dict.items():\n",
    "        #     model.set_default(name, val)\n",
    "\n",
    "        # new_chi_squared, dof, bband, mods, smooths = model.plot(params_dict, display=False)\n",
    "        # k = model.data[0][\"ks\"]\n",
    "        # axes[i][count].scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        # axes[i][count].plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # axes[i][count].legend()\n",
    "        \n",
    "        #plt.scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        # plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # plt.legend()\n",
    "        # count += 1\n",
    "\n",
    "        \n",
    "        # if i == 0:\n",
    "        #     default = smooths[0][0]\n",
    "        # # plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # plt.plot(k, (smooths[0][0]/default)*k, label=extraname)\n",
    "        \n",
    "        \n",
    "    \n",
    "# alpha_para, alpha_perp, beta = 0.97912566, 0.98881584, 1.0\n",
    "\n",
    "alpha_para, alpha_perp = 1.0, 1.0 # 1.00093140, 1.01083738\n",
    "#couplingterm = 1.0/0.22710731766023898\n",
    "#beta = (3.044/(3.044+couplingterm)) / (3.7/(3.7+couplingterm))  \n",
    "beta = 1.0\n",
    "\n",
    "alpha, eps = 1.0, 0.0 #model.get_reverse_alphas(alpha_para, alpha_perp)\n",
    "   \n",
    "truth = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\alpha_\\\\parallel$\": alpha_para, \"$\\\\alpha_\\\\perp$\": alpha_perp, \n",
    "        \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": beta}\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel(r'$k$ $\\mathrm{Mpc}^{-1} h$')\n",
    "# plt.ylabel(r'$k P_0(k)$ $\\mathrm{Mpc}^2 h^{-2}$')\n",
    "\n",
    "c.plotter.plot(\n",
    "    truth=truth,\n",
    "        parameters = parameters[:2]+parameters[4:], \n",
    "        legend=True,\n",
    "        display=False,\n",
    "        figsize=(13, 13), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e903d7-0837-497a-acb1-23d39f4248bb",
   "metadata": {},
   "source": [
    "# We want to compare the value of the fitted alpha for some results in which beta is and isn't free "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ee6f7-1c77-4f78-8eaa-1d750351f58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "filepath_ELG_anisotropic_pk_recon = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-c003-broadbandpoly/output/Barry_fit_Pk_Recon.txt\"\n",
    "filepath_ELG_anisotropic_with_betaneff_pk_recon = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG_phaseshiftfree-c003-broadbandpoly/output/Barry_fit_Pk_Recon.txt\" \n",
    "\n",
    "dat_anisotropic_pk_recon = pd.read_csv(filepath_ELG_anisotropic_pk_recon, skiprows=0, nrows=6, index_col=False)\n",
    "dat_anisotropic_beta_pk_recon = pd.read_csv(filepath_ELG_anisotropic_with_betaneff_pk_recon, skiprows=0, nrows=6, index_col=False)\n",
    "dat_anisotropic_pk_recon.columns = [i.strip() for i in dat_anisotropic_pk_recon.columns]\n",
    "dat_anisotropic_beta_pk_recon.columns = [i.strip() for i in dat_anisotropic_beta_pk_recon.columns]\n",
    "\n",
    "cm = matplotlib.colormaps['rainbow']\n",
    "colors = dat_anisotropic_beta_pk_recon['beta'].to_numpy()\n",
    "norm = mpl.colors.Normalize(vmin=np.min(colors), vmax=np.max(colors))\n",
    "\n",
    "# add alpha, epsilon as additional rows to the models \n",
    "dat_anisotropic_pk_recon['alpha'] = dat_anisotropic_pk_recon['alpha_perp']**(1.0/3.0) * dat_anisotropic_pk_recon['alpha_par']**(2.0/3.0)\n",
    "dat_anisotropic_pk_recon['epsilon'] = (dat_anisotropic_pk_recon['alpha_perp']/dat_anisotropic_pk_recon['alpha_par'])**(1.0/3.0) - 1.0\n",
    "dat_anisotropic_beta_pk_recon['alpha'] = dat_anisotropic_beta_pk_recon['alpha_perp']**(1.0/3.0) * dat_anisotropic_beta_pk_recon['alpha_par']**(2.0/3.0)\n",
    "dat_anisotropic_beta_pk_recon['epsilon'] = (dat_anisotropic_beta_pk_recon['alpha_perp']/dat_anisotropic_beta_pk_recon['alpha_par'])**(1.0/3.0) - 1.0\n",
    "\n",
    "# plot the values against each other \n",
    "plt.figure(figsize=(16,7))\n",
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "axes = [ax1, ax2] \n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "ax1.plot([0.97, 1.03],[0.97, 1.03], linestyle='--', color='k')\n",
    "ax1.scatter(dat_anisotropic_pk_recon['alpha'], dat_anisotropic_beta_pk_recon['alpha'], c=colors, cmap=cm)\n",
    "ax1.set_xlabel(r\"$\\alpha$ standard\")\n",
    "ax1.set_ylabel(r\"$\\alpha$ with $\\beta_{N_{\\mathrm{eff}}}$\")\n",
    "ax1.set_title('First gen mocks, ELGs, c000, grid 000, template 000')\n",
    "#ax1.set_xlim([0.97, 1.03])\n",
    "#ax1.set_ylim([0.97, 1.03])\n",
    "\n",
    "# plot the values against each other \n",
    "ax2.plot([-0.015, 0.015],[-0.015, 0.015], linestyle='--', color='k')\n",
    "ax2.scatter(dat_anisotropic_pk_recon['epsilon'], dat_anisotropic_beta_pk_recon['epsilon'], c=colors, cmap=cm)\n",
    "ax2.set_xlabel(r\"$\\epsilon$ standard\")\n",
    "ax2.set_ylabel(r\"$\\epsilon$ with $\\beta_{N_{\\mathrm{eff}}}$\")\n",
    "#plt.xlim([-0.01, 0.01])\n",
    "#plt.ylim([-0.01, 0.01])\n",
    "sm = plt.cm.ScalarMappable(cmap=cm, norm=norm)\n",
    "#plt.colorbar(sm)\n",
    "plt.colorbar(sm, label=r'$\\beta_{N_{\\mathrm{eff}}}$',ax=ax2)#, norm=norm)\n",
    "plt.colorbar(sm, label=r'$\\beta_{N_{\\mathrm{eff}}}$',ax=ax1)#, norm=norm)\n",
    "\n",
    "#sm.set_array([])\n",
    "plt.subplots_adjust(left=0, right=2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd7176-2f96-4c74-b03b-8fdc3096566c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab0c9b14-671a-41ce-9eb1-e28a2a20bd3e",
   "metadata": {},
   "source": [
    "# comparing fit to best model fits based on settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999b017-a65e-4683-ac23-d229d5ce89ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "from chainconsumer import Chain, Truth \n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-modelfitdata_spline/output/desi_kp4_abacus_cubic_ELG-modelfitdata_spline.fitter.pkl\"\n",
    "\n",
    "pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-modelfitdata_poly/output/desi_kp4_abacus_cubic_ELG-modelfitdata_poly.fitter.pkl\"\n",
    "    \n",
    "pfns = [\n",
    "        pfn1, \n",
    "        pfn2\n",
    "]\n",
    "\n",
    "filelocs = [\n",
    "    \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-modelfitdata_spline/output/desi_kp4_abacus_cubic_ELG-modelfitdata_spline-\",\n",
    "    \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-modelfitdata_poly/output/desi_kp4_abacus_cubic_ELG-modelfitdata_poly-\"\n",
    "]\n",
    "plt.figure(figsize=(20,5))\n",
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        print(extra['name'])\n",
    "        if 'mean' in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']:\n",
    "            continue \n",
    "            \n",
    "        if '0' in extra['name']:\n",
    "            #continue \n",
    "            namedat = 'best model fit \\n from poly method'\n",
    "            # count+= 1\n",
    "        else:\n",
    "            # continue \n",
    "            namedat = 'best model fit \\n from spline method'\n",
    "        if 'CV' in extra['name']:\n",
    "            namedat = namedat + ' CV'\n",
    "        \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "\n",
    "        extraname = ''\n",
    "        if i == 0:\n",
    "            # continue \n",
    "            extraname = 'spline fit'\n",
    "        if i == 1:  \n",
    "            extraname = 'poly fit'\n",
    "            \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        #extra.pop(\"realisation\", namedat)\n",
    "        #extra[\"name\"] = extra['name'] + ', data is ' + namedat\n",
    "        #print(df)\n",
    "        #c.add_chain(Chain(samples=df[[\"$\\\\alpha$\", \"$\\\\epsilon$\", \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\"]], name=extraname + ', data - ' + namedat + ' mock'))#, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        c.add_chain(Chain(samples=df, name=extraname + ', data - ' + namedat + ' mock'))#, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        \n",
    "        df_for_file = df\n",
    "        df['weights'] = weight\n",
    "        df_for_file.to_csv(filelocs[i] + extra['name'] +'.csv')\n",
    "        \n",
    "truth = {\"$\\\\alpha$\": 1.0, \"$\\\\epsilon$\": 0.0, \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.0}#, \"$\\\\Sigma_s$\": 0.0}# , \"$\\\\Sigma_{nl,\\\\perp}$\": 1.5, \"$\\\\Sigma_{nl,||}$\": 5.4\n",
    "       # }#, \"$\\\\alpha_\\\\perp$\": 1.0, \"$\\\\alpha_\\\\parallel$\": 1.0}\n",
    "\n",
    "\n",
    "mocksandmodels = {\n",
    "            \"poly best fit mean of mocks\": [1.0007, 1.0005, 1.057],\n",
    "            \"poly best fit mean of mocks (CV)\": [0.9977, 0.9975, 0.7452],\n",
    "            \"spline best fit mean of mocks\": [1.0063, 1.0054, 1.4633],\n",
    "            \"spline best fit mean of mocks (CV)\": [1.0018, 1.0013, 1.0549],\n",
    "            \"poly default\": [1.0, 1.0, 1.0], \n",
    "            \"spline default\": [1.0, 1.0, 1.0] \n",
    "            }\n",
    "\n",
    "alpha, eps = model.get_reverse_alphas(1.0007, 1.0005)\n",
    "truthpoly = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.057, \n",
    "            \"$\\\\Sigma_s$\": 0.0, \"$\\\\Sigma_{nl,\\\\perp}$\": 1.5, \"$\\\\Sigma_{nl,||}$\": 5.4}\n",
    "\n",
    "alpha, eps = model.get_reverse_alphas(0.9977, 0.9975)\n",
    "truthCVpoly = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 0.7452,\n",
    "               \"$\\\\Sigma_s$\": 0.0, \"$\\\\Sigma_{nl,\\\\perp}$\": 1.5, \"$\\\\Sigma_{nl,||}$\": 5.4}\n",
    "\n",
    "alpha, eps = model.get_reverse_alphas(1.0063, 1.0054)\n",
    "truthspline = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.4633,\n",
    "               \"$\\\\Sigma_s$\": 0.0, \"$\\\\Sigma_{nl,\\\\perp}$\": 1.5, \"$\\\\Sigma_{nl,||}$\": 5.4}\n",
    "\n",
    "alpha, eps = model.get_reverse_alphas(1.0018, 1.0013)\n",
    "truthCVspline = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.0549,\n",
    "                 \"$\\\\Sigma_s$\": 0.0, \"$\\\\Sigma_{nl,\\\\perp}$\": 1.5, \"$\\\\Sigma_{nl,||}$\": 5.4}\n",
    "\n",
    "# c.add_truth(Truth(location=truthspline, color='orange', name='truth for spline model'))\n",
    "# c.add_truth(Truth(location=truthCVspline, color='black', name='truth for CV spline model'))\n",
    "\n",
    "#c.add_truth(Truth(location=truthpoly, color='orange', name='truth for poly model'))\n",
    "#c.add_truth(Truth(location=truthCVpoly, color='black', name='truth for CV poly model'))\n",
    "\n",
    "c.plotter.plot(columns=[\"$\\\\alpha$\", \"$\\\\epsilon$\", \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\"])#,\n",
    "                     #  \"$\\\\Sigma_s$\", \"$\\\\Sigma_{nl,\\\\perp}$\", \"$\\\\Sigma_{nl,||}$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da240d8-9ce7-477f-afcb-9cc741fa8f1a",
   "metadata": {},
   "source": [
    "# looking at fits with 000 fake data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af53ad9-ecff-402b-8289-185a15fd6d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "from chainconsumer import Chain, Truth \n",
    "\n",
    "pfn1 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline_phaseshift/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline_phaseshift.fitter.pkl\"\n",
    "pfn2 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline.fitter.pkl\"\n",
    "\n",
    "pfn3 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly_phaseshift/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly_phaseshift.fitter.pkl\"\n",
    "pfn4 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly.fitter.pkl\"\n",
    "    \n",
    "pfn5 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly-bestmarg/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly-bestmarg.fitter.pkl\"\n",
    "pfn6 = \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline-bestmarg/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline-bestmarg.fitter.pkl\"\n",
    "\n",
    "pfns = [\n",
    "        pfn1, \n",
    "        pfn2,\n",
    "        pfn3,\n",
    "        pfn4,\n",
    "        pfn5,\n",
    "        pfn6\n",
    "]\n",
    "\n",
    "filelocs = [\n",
    "       \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline_phaseshift/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline_phaseshift-\",\n",
    "        \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline-\",\n",
    "\n",
    "        \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly_phaseshift/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly_phaseshift-\",\n",
    "        \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly-\",\n",
    "\n",
    "        \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly-bestmarg/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_poly-bestmarg-\",\n",
    "        \"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline-bestmarg/output/desi_kp4_abacus_cubic_ELG-fitperfect000data_spline-bestmarg-\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "    \n",
    "    # if i < 4:\n",
    "    #     continue \n",
    "    \n",
    "#     if i == 1 or i == 3:\n",
    "#         continue \n",
    "\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        print(extra['name'])\n",
    "        \n",
    "        if 'mean' in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' in extra['name']:\n",
    "            continue \n",
    "        \n",
    "        if 'realisation 0' in extra['name']:\n",
    "            #continue \n",
    "            namedat = '000 model \\n marg nuisance from poly method'\n",
    "            #count+= 1\n",
    "        else:\n",
    "            # continue \n",
    "            namedat = '000 model fit \\n marg nuisance from spline method'\n",
    "        if 'CV' not in extra['name']:\n",
    "            continue \n",
    "        else:\n",
    "            namedat = namedat + ' CV'\n",
    "        \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        # alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        # df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        # df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "\n",
    "        extraname = ''\n",
    "        if i == 0:\n",
    "            extraname = 'spline fit phaseshift'\n",
    "        if i == 1:  \n",
    "            extraname = 'spline fit'\n",
    "        if i == 2: \n",
    "            extraname = 'poly fit phaseshift'\n",
    "        if i == 3:\n",
    "            extraname = 'poly fit'\n",
    "        if i == 4:\n",
    "            extraname = 'poly fit marg only'\n",
    "        if i == 5: \n",
    "            extraname = 'spline fit marg only'\n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        #extra.pop(\"realisation\", namedat)\n",
    "        #extra[\"name\"] = extra['name'] + ', data is ' + namedat\n",
    "        # print(df.columns)\n",
    "        c.add_chain(Chain(samples=df, name=extraname + ', data - ' + namedat))#, weights=weight, **extra, plot_contour=True, plot_point=False, show_as_1d_prior=False)\n",
    "        \n",
    "        df_for_file = df\n",
    "        df['weights'] = weight\n",
    "        df_for_file.to_csv(filelocs[i] + extra['name'] +'.csv')\n",
    "        \n",
    "        \n",
    "truth = {\"$\\\\alpha$\": 1.0, \"$\\\\epsilon$\": 0.0, \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\": 1.0,\n",
    "        \"$b_{0,1}$\": 0.52, '$\\\\beta$': 0.7, '$\\\\Sigma_s$': 0.0, '$\\\\Sigma_{nl,\\\\perp}$': 1.5, '$\\\\Sigma_{nl,||}$': 5.4}\n",
    "\n",
    "#, \"$\\\\alpha_\\\\perp$\": 1.0, \"$\\\\alpha_\\\\parallel$\": 1.0}\n",
    "\n",
    "\n",
    "\n",
    "c.add_truth(Truth(location=truth, color='black', name='truth'))\n",
    "\n",
    "c.plotter.plot()#columns=[\"$\\\\alpha$\", \"$\\\\epsilon$\", \"$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f3784-af23-492b-a344-b74b8f0d3f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c49523-6d61-4b60-986d-25535640d999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barry_env_desiproject_aw",
   "language": "python",
   "name": "barry_env_desiproject_aw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
