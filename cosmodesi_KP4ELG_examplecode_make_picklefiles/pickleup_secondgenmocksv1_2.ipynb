{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75477157-0ff0-4540-bc60-78d1363aac7c",
   "metadata": {},
   "source": [
    "# Pickle Abacus SecondGen Xi files for Barry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8830f37-eee3-4391-92cd-41bbd1f95786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages, set up the fiducial cosmology and save the DESI template\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from astropy.io import ascii\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import splrep, splev\n",
    "from cosmoprimo import PowerSpectrumBAOFilter\n",
    "from cosmoprimo.fiducial import DESI, AbacusSummit\n",
    "from pypower import BaseMatrix, CatalogFFTPower, CatalogFFTCorr, PowerSpectrumMultipoles, PowerSpectrumSmoothWindow, PowerSpectrumSmoothWindowMatrix, PowerSpectrumOddWideAngleMatrix, setup_logging\n",
    "from pycorr import TwoPointCorrelationFunction, project_to_multipoles\n",
    "\n",
    "cosmo = DESI() \n",
    "print(cosmo[\"Omega_b\"]*cosmo[\"h\"]**2, cosmo[\"Omega_cdm\"]*cosmo[\"h\"]**2, cosmo[\"Omega_m\"]*cosmo[\"h\"]**2 - cosmo[\"Omega_b\"]*cosmo[\"h\"]**2)\n",
    "print(cosmo[\"A_s\"], cosmo[\"n_s\"], cosmo[\"tau_reio\"])\n",
    "print(np.sum(cosmo[\"m_ncdm\"]))\n",
    "\n",
    "print(cosmo.sigma8_z)\n",
    "print(cosmo[\"Omega_m\"], \n",
    "      cosmo.Omega_m(0.11), \n",
    "      cosmo.growth_rate(0.0), \n",
    "      cosmo.growth_rate(0.11), \n",
    "      cosmo.growth_rate(0.0)*cosmo.sigma8_z(0.0), \n",
    "      cosmo.growth_rate(0.11)*cosmo.sigma8_z(0.11)\n",
    "     )\n",
    "\n",
    "# Save the default DESI template to a file\n",
    "k_min = 1e-4\n",
    "k_max = 5\n",
    "k_num = 2000\n",
    "kl = np.logspace(np.log(k_min), np.log(k_max), k_num, base=np.e)\n",
    "pkz = cosmo.get_fourier().pk_interpolator()\n",
    "pkz0 = pkz.to_1d(z=0)\n",
    "pkv = pkz0(kl)\n",
    "pknow = PowerSpectrumBAOFilter(pkz0, engine='wallish2018').smooth_pk_interpolator()\n",
    "pksmv = pknow(kl)\n",
    "#np.savetxt(\"./DESI_Pk_template.dat\", np.c_[kl, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g\", header=\"k     pk_smooth     pk_ratio\")\n",
    "#np.savetxt(\"./DESI_Pk_z0p00.dat\", np.c_[kl, pkv, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g %g\", header=\"k     pk         pk_smooth     pk_ratio\")\n",
    "\n",
    "#pkz011 = pkz.to_1d(z=0.11)\n",
    "#pkv = pkz011(kl)\n",
    "#pknow = PowerSpectrumBAOFilter(pkz011, engine='wallish2018').smooth_pk_interpolator()\n",
    "#pksmv = pknow(kl)\n",
    "#np.savetxt(\"./DESI_Pk_z0p11.dat\", np.c_[kl, pkv, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g %g\", header=\"k     pk   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c671b9d-3244-4fd7-a48c-5fdbc5664091",
   "metadata": {},
   "source": [
    "# Correlation function routines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f301a-1703-430a-8076-942707c1ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful utility function to collate some Xi data\n",
    "def collect_xi_data(pre_files, post_files, pre_cov_files, post_cov_files, pre_files_name, post_files_name, pre_cov_name, post_cov_name, zs, reconsmooth, mocks, rpcut, imaging):\n",
    "\n",
    "    pre_data, post_data = None, None\n",
    "    \n",
    "    pre_mocks = get_xi2(pre_files, pre_files_name, mocks, rpcut, imaging) if pre_files_name is not None else None\n",
    "    post_mocks = get_xi2(post_files, post_files_name, mocks, rpcut, imaging) if post_files_name is not None else None\n",
    "    \n",
    "    pre_cov = get_xi_cov(pre_cov_files, pre_cov_name, rpcut, imaging) if pre_cov_name is not None else None\n",
    "    post_cov = get_xi_cov(post_cov_files, post_cov_name, rpcut, imaging) if post_cov_name is not None else None\n",
    "    \n",
    "    rp = f\" {imaging} rpcut2.5\" if rpcut else f\" {imaging}\" \n",
    "    \n",
    "    split = {\n",
    "        \"n_data\": 1,\n",
    "        \"pre-recon data\": pre_data,\n",
    "        \"pre-recon cov\": pre_cov,\n",
    "        \"post-recon data\": post_data,\n",
    "        \"post-recon cov\": post_cov,\n",
    "        \"pre-recon mocks\": pre_mocks,\n",
    "        \"post-recon mocks\": post_mocks,\n",
    "        \"cosmology\": {\n",
    "            \"om\": cosmo[\"Omega_m\"],\n",
    "            \"h0\": cosmo[\"h\"],\n",
    "            \"z\": (zs[1]+zs[0])/2.0,\n",
    "            \"ob\": cosmo[\"Omega_b\"],\n",
    "            \"ns\": cosmo[\"n_s\"],\n",
    "            \"mnu\": np.sum(cosmo[\"m_ncdm\"]),\n",
    "            \"reconsmoothscale\": reconsmooth,\n",
    "        },\n",
    "        \"name\": \"DESI SecondGen \" + f\"sm{reconsmooth} \" +  (\"_\").join(pre_files_name.split(\"_\")[1:]) + rp\n",
    "    }\n",
    "    \n",
    "    with open(f\"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/DESI_SecondGen_sm{reconsmooth}_\" + (\"_\").join(pre_files_name.split(\"_\")[1:]).lower() + (\"_\").join(rp.split(\" \")) + \"_xi.pkl\", \"wb\") as f:\n",
    "        pickle.dump(split, f)\n",
    "        \n",
    "    return split\n",
    "\n",
    "# Correlation function\n",
    "# def get_xi(loc, name, mocks, rpcut, imaging):\n",
    "    \n",
    "#     rp = \"_rpcut2.5\" if rpcut else \"\" \n",
    "    \n",
    "#     xis = []\n",
    "#     for mock in mocks:\n",
    "#         if 'BGS_BRIGHT-21.5' in name and mock == 13:\n",
    "#             continue\n",
    "#         infile = loc + f\"/mock{mock}/\" + name + f\"_{imaging}_lin4_njack0_nran4_split20{rp}.txt\"\n",
    "\n",
    "#         xi = pd.read_csv(infile, comment=\"#\", skiprows=0, delim_whitespace=True, header=None, names=[\"s\", \"savg\",\"xi0\",\"xi2\",\"xi4\"])\n",
    "#         xi = xi.drop(xi[xi[\"s\"] < 20.0].index)\n",
    "#         xis.append(xi)\n",
    "\n",
    "#     return xis\n",
    "\n",
    "def get_xi2(loc, name, nmocks, rpcut, imaging):\n",
    "    \n",
    "    xis = []\n",
    "    print(nmocks)\n",
    "    for mock in nmocks: \n",
    "\n",
    "        infile = loc + 'mock' + str(mock) + name + '.npy' \n",
    "        result = TwoPointCorrelationFunction.load(infile)\n",
    "        factor = 4\n",
    "        rebinned = result[:(result.shape[0] // factor) * factor:factor]\n",
    "        sep, xi = rebinned(ells=(0, 2, 4), return_sep=True, return_std=False)\n",
    "        xi = pd.DataFrame({'s': sep, 'xi0': xi[0], 'xi2': xi[1], 'xi4': xi[2]})\n",
    "        xi = xi.drop(xi[xi[\"s\"] < 20.0].index)\n",
    "        xis.append(xi)\n",
    "        \n",
    "    return xis# [xis[[\"s\",\"xi0\",\"xi2\",\"xi4\"]]]\n",
    "\n",
    "    # Correlation function covariance matrix.\n",
    "def get_xi_cov(loc, name, rpcut, imaging):\n",
    "\n",
    "    # s = \"rescaled\"\n",
    "    # infile = loc + \"xi024_\" + name.replace(\"sm30\",\"sm20\") + f\"_{imaging}_lin4_s20-200_cov_RascalC_{s}.txt\"    # No recon_sm30 cov for QSO yet\n",
    "    infile = loc + name \n",
    "    \n",
    "    cov = pd.read_csv(infile, comment=\"#\", delim_whitespace=True, header=None).to_numpy()\n",
    "    #print(cov.shape)\n",
    "    #plt.imshow(cov/np.sqrt(np.outer(np.diag(cov), np.diag(cov))))\n",
    "    #plt.show()\n",
    "    \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "\n",
    "    return cov\n",
    "    \n",
    "# Plot the correlation function, for sanity checking\n",
    "def plot_xi(split, pre=True, post=True):\n",
    "\n",
    "    color = [\"r\", \"b\", \"g\"]\n",
    "    ss = split[\"pre-recon mocks\"][0][\"s\"]\n",
    "    nmocks = len(split[\"pre-recon mocks\"])\n",
    "    label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "    \n",
    "    if pre:\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"pre-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * np.mean([split[\"pre-recon mocks\"][i][xi] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ss, ss ** 2 * split[\"pre-recon mocks\"][i][xi], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Prerecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "    if post:\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"post-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * np.mean([split[\"post-recon mocks\"][i][xi] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ss, ss ** 2 * split[\"post-recon mocks\"][i][xi], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Postrecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c378af9-7977-4714-b5af-52dbac1dcf6d",
   "metadata": {},
   "source": [
    "# get file paths and pickle everything up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e780d-dec6-4bea-8f23-a32366681797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The catalogue version\n",
    "version = 1.2\n",
    "ffa = \"ffa\"               # Flavour of fibre assignment. Can be \"ffa\" for fast fiber assign, or \"complete\"\n",
    "rpcut = False             # Whether or not to include the rpcut\n",
    "imaging = \"default_FKP\"   # What form of imaging systematics to use. Can be \"default_FKP\", \"default_FKP_addSN\", or \"default_FKP_addRF\"\n",
    "\n",
    "# This is a dictionary of all the combinations of dataset that we have and their redshift bins.\n",
    "tracers = {'BGS_BRIGHT-21.5': [[0.1,0.4]],\n",
    "           'LRG': [[0.4, 0.6], [0.6, 0.8], [0.8, 1.1]], \n",
    "           'ELG_LOP': [[0.8, 1.1], [1.1, 1.6]],\n",
    "           'QSO': [[0.8, 2.1]]}\n",
    "\n",
    "# How many complete mocks are available for each tracer? \n",
    "# While the mocks are still being processed, this allows us to skip over the missing entries\n",
    "nmocks = {'BGS_BRIGHT-21.5': [0,25], 'LRG': [0,25], 'ELG_LOP': [0,25], 'QSO': [0,25]}\n",
    "\n",
    "# This dictionary specifies the particulars of how reconstruction was run on each tracer. First entry is smoothing scale, second is type of recon. \n",
    "# QSO has no recon, so set to None so it can be skipped over later.\n",
    "recon = {'BGS_BRIGHT-21.5': [15, \"IFTrecsym\"],\n",
    "         'LRG': [10, \"IFTrecsym\"], \n",
    "         'ELG_LOP': [10, \"IFTrecsym\"],\n",
    "         'QSO': [30, \"IFTrecsym\"]}\n",
    "\n",
    "# The different sky areas\n",
    "caps = [\"NGC\", \"SGC\", \"GCcomb\"]\n",
    "\n",
    "basepath = f\"/global/cfs/cdirs/desi/survey/catalogs/Y1/mocks/SecondGenMocks/\"\n",
    "pre_cov_files = f\"/global/cfs/cdirs/desi/users/mrash/RascalC/Y1/unblinded/v{version}/\"     # At the minute GCcomb uses rescaled, but NGC and SGC just no-rescaling as it's not clear to me which to use.\n",
    "post_cov_files = f\"/global/cfs/cdirs/desi/users/mrash/RascalC/Y1/unblinded/v{version}/\"    # At the minute GCcomb uses rescaled, but NGC and SGC just no-rescaling as it's not clear to me which to use.\n",
    "\n",
    "\n",
    "for t in tracers:\n",
    "    for i, zs in enumerate(tracers[t]):\n",
    "        for cap in caps:\n",
    "                    \n",
    "            pre_files = basepath + \"AbacusSummitBGS/desipipe/v1/ffa/2pt/\" if t == \"BGS_BRIGHT-21.5\" else basepath + \"AbacusSummit/\"\n",
    "            post_files = basepath + \"AbacusSummitBGS/desipipe/v1/ffa/2pt/\" if t == \"BGS_BRIGHT-21.5\" else basepath + \"AbacusSummit/\"\n",
    "            \n",
    "            pre_name =  f\"/xi/smu/allcounts_{t}_{cap}_z{zs[0]}-{zs[1]}_{imaging}_lin_nran1_njack0_split20\" if t == \"BGS_BRIGHT-21.5\" else f\"/xi/smu/allcounts_{t}_{ffa}_{cap}_{zs[0]}_{zs[1]}_{imaging}_lin_njack0_nran4_split20\" \n",
    "            \n",
    "            if t == 'BGS_BRIGHT-21.5':\n",
    "                post_name = f\"/recon_sm{recon[t][0]}_IFFT_recsym/xi/smu/allcounts_{t}_{cap}_z{zs[0]}-{zs[1]}_{imaging}_lin_nran1_njack0_split20\" # if recon[t][1] is not None else None\n",
    "            else:\n",
    "                post_name = f\"/recon_sm{recon[t][0]}/xi/smu/allcounts_{t}_{ffa}_{recon[t][1]}_{cap}_{zs[0]}_{zs[1]}_{imaging}_lin_njack0_nran4_split20\" # if recon[t][1] is not None else None 0,4,20 or 60,4,20 \n",
    "            \n",
    "            tcov = \"ELG_LOPnotqso\" if \"ELG\" in t else t\n",
    "            pre_cov_name = f\"xi024_{tcov}_{cap}_{zs[0]}_{zs[1]}_{imaging}_lin4_s20-200_cov_RascalC_rescaled.txt\"\n",
    "            if cap in ['NGC', 'SGC']:\n",
    "                pre_cov_name = f\"xi024_{tcov}_{cap}_{zs[0]}_{zs[1]}_{imaging}_lin4_s20-200_cov_RascalC_Gaussian.txt\"\n",
    "            #post_cov_name = f\"{tcov}_{recon[t][1]}_sm{recon[t][0]}_{cap}_{zs[0]}_{zs[1]}\" if recon[t][1] is not None else None\n",
    "            post_cov_name = pre_cov_name # if recon[t][1] # is not None else None\n",
    "            \n",
    "            print(os.path.exists(pre_files + 'mock0' + pre_name + '.npy'))\n",
    "            print(pre_files + 'mock0' + pre_name)\n",
    "            print(os.path.exists(post_files + 'mock0' + post_name + '.npy'))\n",
    "            print(post_files + 'mock0' + post_name)\n",
    "            # print(os.path.exists(pre_cov_files + pre_cov_name))\n",
    "            # print(pre_cov_files + pre_cov_name)\n",
    "           \n",
    "            data = collect_xi_data(pre_files, post_files, pre_cov_files, post_cov_files, pre_name, post_name, pre_cov_name, post_cov_name, zs, recon[t][0], range(nmocks[t][0], nmocks[t][1]), rpcut, imaging)\n",
    "            plot_xi(data, post=False if post_name is None else True) # Plot the data to check things\n",
    "#\n",
    "#allcounts_BGS_BRIGHT-21.5_NGC_z0.1-0.4_default_FKP_nran1_njack0_split20\n",
    "#allcounts_BGS_BRIGHT-21.5_GCcomb_z0.1-0.4_default_FKP_lin_nran1_njack0_split20.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072f689-0cf6-4609-8fa0-cb415f3939d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601bf85-866f-41b0-8c6b-403b2d5d3476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01497024-f6f6-4ed5-99e1-a49128e70523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb014513-5236-49d2-8fda-47d3a369aade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17fa0ad4-7163-4e29-aa00-06251b11d729",
   "metadata": {},
   "source": [
    "# Pickle AbacusSummit Pk mocks for Barry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14140722-6a07-40b1-95a3-c9c0f0cc0ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages, set up the fiducial cosmology and save the DESI template\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from astropy.io import ascii\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import splrep, splev\n",
    "from cosmoprimo import PowerSpectrumBAOFilter\n",
    "from cosmoprimo.fiducial import DESI\n",
    "from pypower import BaseMatrix, CatalogFFTPower, CatalogFFTCorr, PowerSpectrumMultipoles, PowerSpectrumSmoothWindow, PowerSpectrumSmoothWindowMatrix, PowerSpectrumOddWideAngleMatrix, setup_logging\n",
    "from pycorr import TwoPointCorrelationFunction, project_to_multipoles\n",
    "\n",
    "cosmo = DESI()\n",
    "print(cosmo[\"Omega_b\"]*cosmo[\"h\"]**2, cosmo[\"Omega_cdm\"]*cosmo[\"h\"]**2, cosmo[\"Omega_m\"]*cosmo[\"h\"]**2 - cosmo[\"Omega_b\"]*cosmo[\"h\"]**2)\n",
    "print(cosmo[\"A_s\"], cosmo[\"n_s\"], cosmo[\"tau_reio\"])\n",
    "print(np.sum(cosmo[\"m_ncdm\"]))\n",
    "\n",
    "# Save the default DESI template to a file\n",
    "k_min = 1e-4\n",
    "k_max = 5\n",
    "k_num = 2000\n",
    "kl = np.logspace(np.log(k_min), np.log(k_max), k_num, base=np.e)\n",
    "pkz = cosmo.get_fourier().pk_interpolator()\n",
    "pk = pkz.to_1d(z=0)\n",
    "pkv = pk(kl)\n",
    "pknow = PowerSpectrumBAOFilter(pk, engine='wallish2018').smooth_pk_interpolator()\n",
    "pksmv = pknow(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad39fba6-7c5b-41ed-914a-037abcffa77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful utility function to collate some Xi data\n",
    "def collect_pk_data(pre_files, post_files, pre_cov_files, post_cov_files, pre_files_name, post_files_name, pre_cov_name, post_cov_name, zs, reconsmooth, mocks, rpcut, imaging):\n",
    "\n",
    "    pre_data, post_data = None, None\n",
    "    \n",
    "    pre_mocks = get_pk(pre_files, pre_name, mocks, rpcut, imaging) if pre_files_name is not None else None\n",
    "    post_mocks = get_pk(post_files, post_name, mocks, rpcut, imaging) if post_files_name is not None else None\n",
    "    \n",
    "    pre_cov = get_pk_cov(pre_cov_files, pre_cov_name, rpcut, imaging) if pre_cov_files is not None else None\n",
    "    post_cov = get_pk_cov(post_cov_files, post_cov_name, rpcut, imaging) if post_cov_files is not None else None\n",
    "    \n",
    "    if pre_files is not None:\n",
    "        winmat, wam_reshape = getwin(pre_mocks[0][\"k\"].to_numpy(), post_cov_files, post_name, rpcut, imaging)\n",
    "    else:\n",
    "        winmat, wam_reshape = getwin_dummy(pre_mocks[0][\"k\"].to_numpy())\n",
    "        \n",
    "    rp = f\" {imaging} rpcut2.5\" if rpcut else f\" {imaging}\" \n",
    "        \n",
    "    split = {\n",
    "        \"n_data\": 1,\n",
    "        \"pre-recon data\": pre_data,\n",
    "        \"pre-recon cov\": pre_cov,\n",
    "        \"post-recon data\": post_data,\n",
    "        \"post-recon cov\": post_cov,\n",
    "        \"pre-recon mocks\": pre_mocks,\n",
    "        \"post-recon mocks\": post_mocks,\n",
    "        \"cosmology\": {\n",
    "            \"om\": cosmo[\"Omega_m\"],\n",
    "            \"h0\": cosmo[\"h\"],\n",
    "            \"z\": (zs[1]+zs[0])/2.0,\n",
    "            \"ob\": cosmo[\"Omega_b\"],\n",
    "            \"ns\": cosmo[\"n_s\"],\n",
    "            \"mnu\": np.sum(cosmo[\"m_ncdm\"]),\n",
    "            \"reconsmoothscale\": reconsmooth,\n",
    "        },\n",
    "        \"name\": \"DESI SecondGen \" + f\"sm{reconsmooth} \" +  (\"_\").join(pre_files_name.split(\"_\")[1:]) + rp,\n",
    "        \"winfit\": winmat,\n",
    "        \"winpk\": None,  # We can set this to None; Barry will set it to zeroes given the length of the data vector.\n",
    "        \"m_mat\": wam_reshape,\n",
    "    }\n",
    "    \n",
    "    with open(f\"/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/DESI_SecondGen_sm{reconsmooth}_\" + (\"_\").join(pre_files_name.split(\"_\")[1:]).lower() + (\"_\").join(rp.split(\" \")) + \"_pk.pkl\", \"wb\") as f:\n",
    "        pickle.dump(split, f)\n",
    "        \n",
    "    return split\n",
    "\n",
    "# Power Spectrum\n",
    "def get_pk(loc, name, mocks, rpcut, imaging):\n",
    "    \n",
    "    rp = \"_rpcut2.5\" if rpcut else \"\" \n",
    "    \n",
    "    # Overwrite the <k> with the bin centres as we now use a binning matrix to correct to <P(k)>\n",
    "    ks = np.linspace(0.0, 0.4, 80, endpoint=False) + 0.0025\n",
    "    #ks = None\n",
    "    \n",
    "    pks = []\n",
    "    for mock in mocks:\n",
    "        if 'BGS_BRIGHT-21.5' in name and mock == 13:\n",
    "            continue\n",
    "        infile = loc + \"mock\" + str(mock) + name + \".npy\"\n",
    "\n",
    "        data = PowerSpectrumMultipoles.load(infile)\n",
    "        data.slice(slice(0,400,5))\n",
    "        df = pd.DataFrame(np.vstack(data(ell=[0,2,4], return_k=True)).T.real, columns=[\"k\", \"pk0\", \"pk2\", \"pk4\"])\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"nk\"] = data.nmodes\n",
    "        if ks is not None:\n",
    "            df[\"k\"] = ks\n",
    "        pks.append(df[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "    \n",
    "    return pks\n",
    "\n",
    "# Power Spectrum covariance matrix.\n",
    "def get_pk_cov(loc, name, rpcut, imaging):\n",
    "\n",
    "    rp = \"_rpcut2.5\" if rpcut else \"\" \n",
    "    infile = loc + name + \".txt\"\n",
    "    \n",
    "    cov_input = pd.read_csv(infile, comment=\"#\", delim_whitespace=True, header=None).to_numpy()\n",
    "    nks = int(np.shape(cov_input)[0]/3)\n",
    "    nin = nks\n",
    "    cov = np.eye(5 * nks)\n",
    "    cov[:nks, :nks] = cov_input[:nks, :nks]\n",
    "    cov[:nks, 2 * nks : 3 * nks] = cov_input[:nks, nin : nin + nks]\n",
    "    cov[:nks, 4 * nks : 5 * nks] = cov_input[:nks, 2 * nin : 2 * nin + nks]\n",
    "    cov[2 * nks : 3 * nks, :nks] = cov_input[nin : nin + nks, :nks]\n",
    "    cov[2 * nks : 3 * nks, 2 * nks : 3 * nks] = cov_input[nin : nin + nks, nin : nin + nks]\n",
    "    cov[2 * nks : 3 * nks, 4 * nks : 5 * nks] = cov_input[nin : nin + nks, 2 * nin : 2 * nin + nks]\n",
    "    cov[4 * nks : 5 * nks, :nks] = cov_input[2 * nin : 2 * nin + nks, :nks]\n",
    "    cov[4 * nks : 5 * nks, 2 * nks : 3 * nks] = cov_input[2 * nin : 2 * nin + nks, nin : nin + nks]\n",
    "    cov[4 * nks : 5 * nks, 4 * nks : 5 * nks] = cov_input[2 * nin : 2 * nin + nks, 2 * nin : 2 * nin + nks]\n",
    "    \n",
    "    #plt.imshow(cov/np.sqrt(np.outer(np.diag(cov), np.diag(cov))))\n",
    "    #plt.show()\n",
    "    \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "\n",
    "    return cov\n",
    "\n",
    "# Read's in window and wideangle matrices\n",
    "def getwin(ks, loc, name, rpcut, imaging):\n",
    "\n",
    "    rp = \"_rpcut2.5\" if rpcut else \"\" \n",
    "\n",
    "    #wam_data = BaseMatrix.load(\"/global/cfs/cdirs/desi/survey/catalogs/Y1/LSS/iron/LSScats/v0.6/blinded/pk/wmatrix_smooth_\" + (\"_\").join([name.split(\"/\")[-1].split(\"_\")[1]]+name.split(\"/\")[-1].split(\"_\")[4:]) + f\"_{imaging}_lin{rp}.npy\")\n",
    "    loc = '/'.join(loc.split('/')[:-2]) \n",
    "    if 'BGS' in name:\n",
    "        winname = \"/wmatrix_smooth_\" + '_'.join(name.split(\"/\")[-1].split(\"_\")[1:-6])\n",
    "    else:\n",
    "        winname = \"/wmatrix_smooth_\" + '_'.join(name.split(\"/\")[-1].split(\"_\")[1:-3])\n",
    "        \n",
    "    print(winname)\n",
    "    if 'recsym' in winname:\n",
    "        winname = winname.split('_')# .remove('IFTrecsym')\n",
    "        winname.remove('IFTrecsym')\n",
    "        winname.remove('ffa')\n",
    "        if 'LOP' in winname:\n",
    "            winname[winname.index('LOP')] = 'LOPnotqso'\n",
    "        winname = '_'.join(winname)\n",
    "    if winname[-4] == '-':\n",
    "        winname = winname[:-8] + winname[-7:-4] + '_' + winname[-3:]\n",
    "    infile = loc + winname + f\"_{imaging}_lin{rp}.npy\"\n",
    "    wam = BaseMatrix.load(infile)\n",
    "    \n",
    "    # BGS_BRIGHT-21.5_NGC_z0.1-0.4_default_FKP_lin_nran18_cellsize6_boxsize4000_default_FKP_lin.npy\n",
    "    #plt.imshow(np.log10(np.fabs(wam.value)), aspect='auto')\n",
    "    #plt.show()\n",
    "    \n",
    "    wam = wam[:,:len(wam.xout[0])// 5 * 5]\n",
    "    #print(wam.xout[0], np.shape(wam.value))\n",
    "    old_wam = wam[:, :len(wam.xout[0]) // 5 * 5:5]\n",
    "    #print(np.shape(wam[:, :len(wam.xout[0]) // 5 * 5:5]))\n",
    "    wam.rebin_x(factorout=5)\n",
    "    #print(old_wam.value/wam.value)\n",
    "    kout = wam.xout[0] if ks is None else ks\n",
    "        \n",
    "    # This window function only has even multipoles as outputs and includes wide angle effects, so let's pad it with \n",
    "    # some zeros where the output odd multipoles would be so Barry is happy and then create a dummy wide angle matrix.\n",
    "    w_transform = np.zeros((5 * len(kout), 6 * len(wam.xin[0])))\n",
    "    wam_reshape = np.hsplit(wam.value, 3)\n",
    "    for j in range(3):\n",
    "        for i in range(3):\n",
    "            w_transform[2*j*len(kout): (2*j+1)*len(kout) , 2*i*len(wam.xin[0]) : (2*i+1)*len(wam.xin[0])] = wam_reshape[j][i*len(wam.xin[0]) : (i+1)*len(wam.xin[0])].T\n",
    "    \n",
    "    matrix = np.zeros((6 * len(wam.xin[0]), 3 * len(wam.xin[0])))\n",
    "    matrix[: len(wam.xin[0]), : len(wam.xin[0])] = np.diag(np.ones(len(wam.xin[0])))\n",
    "    matrix[2 * len(wam.xin[0]) : 3 * len(wam.xin[0]), len(wam.xin[0]) : 2 * len(wam.xin[0])] = np.diag(np.ones(len(wam.xin[0])))\n",
    "    matrix[4 * len(wam.xin[0]) : 5 * len(wam.xin[0]), 2 * len(wam.xin[0]) :] = np.diag(np.ones(len(wam.xin[0])))\n",
    "            \n",
    "    #plt.imshow(np.log10(np.fabs(w_transform)), aspect='auto')\n",
    "    #plt.show()\n",
    "\n",
    "    #plt.imshow((w_transform @ matrix).T, aspect='auto')\n",
    "    #plt.show()\n",
    "    \n",
    "    # The conversion matrix M from Beutler 2019. Used to compute the odd multipole models given the even multipoles. In the absence of wide angle effects, or if we don't care about\n",
    "    # the odd multipoles, we can set this to a block matrix with identity matrices in the appropriate places, as is done here.\n",
    "\n",
    "    res = {\"w_ks_input\": wam.xin[0], \"w_k0_scale\": np.zeros(len(wam.xin[0])), \"w_transform\": w_transform, \"w_ks_output\": kout}\n",
    "    winmat = {1: res}   # Step size is one, but we could modify this to contain other stepsizes too.\n",
    "    \n",
    "    # Wideangle matrix already included in window matrix, so pass None for wide-angle matrix so that Barry knows\n",
    "    return winmat, matrix\n",
    "\n",
    "# Window function matrix. The window functions are stored in a dictionary of 'step sizes' i.e., how many bins get stuck together relative to the \n",
    "# pk measurements so that we can rebin the P(k) at run time if required. Each step size is a dictionary with:\n",
    "#    the input and output k binning (w_ks_input, w_ks_output), the window function matrix (w_transform) and integral constraint (w_k0_scale).\n",
    "# The window function assumes 6 input and 5 output multipoles. For cubic sims, we can set the integral constraint to zero and window matrix to a binning matrix, as is done here.\n",
    "def getwin_dummy(ks):\n",
    "    \n",
    "    dk = ks[1] - ks[0]\n",
    "    ks_input = np.logspace(-3.0, np.log10(0.5), 500)\n",
    "\n",
    "    binmat = np.zeros((len(ks), len(ks_input)))\n",
    "    for ii in range(len(ks_input)):\n",
    "\n",
    "        # Define basis vector\n",
    "        pkvec = np.zeros_like(ks_input)\n",
    "        pkvec[ii] = 1\n",
    "\n",
    "        # Define the spline:\n",
    "        pkvec_spline = splrep(ks_input, pkvec)\n",
    "\n",
    "        # Now compute binned basis vector:\n",
    "        tmp = np.zeros_like(ks)\n",
    "        for i, kk in enumerate(ks):\n",
    "            kl = kk - dk / 2\n",
    "            kr = kk + dk / 2\n",
    "            kin = np.linspace(kl, kr, 100)\n",
    "            tmp[i] = np.trapz(kin**2 * splev(kin, pkvec_spline, ext=3), x=kin) * 3 / (kr**3 - kl**3)\n",
    "\n",
    "        binmat[:, ii] = tmp\n",
    "\n",
    "    w_transform = np.zeros((5 * ks.size, 6 * ks_input.size))\n",
    "    for i in range(5):\n",
    "        w_transform[i*ks.size: (i+1)*ks.size , i*ks_input.size : (i+1)*ks_input.size] = binmat\n",
    "    \n",
    "    # The conversion matrix M from Beutler 2019. Used to compute the odd multipole models given the even multipoles. In the absence of wide angle effects, or if we don't care about\n",
    "    # the odd multipoles, we can set this to a block matrix with identity matrices in the appropriate places, as is done here.\n",
    "    matrix = np.zeros((6 * ks_input.size, 3 * ks_input.size))\n",
    "    matrix[: ks_input.size, : ks_input.size] = np.diag(np.ones(ks_input.size))\n",
    "    matrix[2 * ks_input.size : 3 * ks_input.size, ks_input.size : 2 * ks_input.size] = np.diag(np.ones(ks_input.size))\n",
    "    matrix[4 * ks_input.size : 5 * ks_input.size, 2 * ks_input.size :] = np.diag(np.ones(ks_input.size))\n",
    "    \n",
    "    res = {\"w_ks_input\": ks_input, \"w_k0_scale\": np.zeros(ks.size), \"w_transform\": w_transform, \"w_ks_output\": ks}\n",
    "    return {1: res}, matrix  # Step size is one  \n",
    "\n",
    "# Plot the correlation function, for sanity checking\n",
    "def plot_pk(split, pre=True, post=True):\n",
    "        \n",
    "    color = [\"r\", \"b\", \"g\"]\n",
    "    k = split[\"post-recon mocks\"][0][\"k\"]\n",
    "    nmocks = len(split[\"pre-recon mocks\"])\n",
    "    label = [r\"$P_{0}(k)$\", r\"$P_{2}(k)$\", r\"$P_{4}(k)$\"]\n",
    "        \n",
    "    if pre:\n",
    "        for m, pk in enumerate([\"pk0\", \"pk2\", \"pk4\"]):\n",
    "            yerr = k * np.sqrt(np.diag(split[\"pre-recon cov\"]))[m * len(k) : (m + 1) * len(k)]\n",
    "            plt.errorbar(\n",
    "                k,\n",
    "                k * np.mean([split[\"pre-recon mocks\"][i][pk] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(k, k * split[\"pre-recon mocks\"][i][pk], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$k$\")\n",
    "        plt.ylabel(r\"$k\\,\\times pk(k)$\")\n",
    "        plt.title(split[\"name\"] + \" Prerecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "        \n",
    "    if post:\n",
    "        for m, pk in enumerate([\"pk0\", \"pk2\", \"pk4\"]):\n",
    "            yerr = k * np.sqrt(np.diag(split[\"post-recon cov\"]))[m * len(k) : (m + 1) * len(k)]\n",
    "            plt.errorbar(\n",
    "                k,\n",
    "                k * np.mean([split[\"post-recon mocks\"][i][pk] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(k, k * split[\"post-recon mocks\"][i][pk], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.ylabel(r\"$k\\,\\times pk(k)$\")\n",
    "        plt.title(split[\"name\"] + \" Postrecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c685e3-11a9-4125-946d-8caa52928ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The catalogue version\n",
    "import os \n",
    "version = 1.2\n",
    "ffa = \"ffa\"               # Flavour of fibre assignment. Can be \"ffa\" for fast fiber assign, or \"complete\"\n",
    "rpcut = False             # Whether or not to include the rpcut\n",
    "imaging = \"default_FKP\"   # What form of imaging systematics to use. Can be \"default_FKP\", \"default_FKP_addSN\", or \"default_FKP_addRF\"\n",
    "\n",
    "# This is a dictionary of all the combinations of dataset that we have and their redshift bins.\n",
    "tracers = {'BGS_BRIGHT-21.5': [[0.1,0.4]],\n",
    "           'LRG': [[0.4, 0.6], [0.6, 0.8], [0.8, 1.1]], \n",
    "           'ELG_LOP': [[0.8, 1.1], [1.1, 1.6]],\n",
    "           'QSO': [[0.8, 2.1]]}\n",
    "\n",
    "# How many complete mocks are available for each tracer? \n",
    "# While the mocks are still being processed, this allows us to skip over the missing entries\n",
    "nmocks = {'BGS_BRIGHT-21.5': [0,25], 'LRG': [0,25], 'ELG_LOP': [0,25], 'QSO': [0,25]}\n",
    "\n",
    "# This dictionary specifies the particulars of how reconstruction was run on each tracer. First entry is smoothing scale, second is type of recon. \n",
    "# QSO has no recon, so set to None so it can be skipped over later.\n",
    "recon = {'BGS_BRIGHT-21.5': [15, \"IFTrecsym\"],\n",
    "         'LRG': [10, \"IFTrecsym\"], \n",
    "         'ELG_LOP': [10, \"IFTrecsym\"],\n",
    "         'QSO': [30, \"IFTrecsym\"]}\n",
    "\n",
    "# The different sky areas\n",
    "caps = [\"NGC\", \"SGC\", \"GCcomb\"]\n",
    "\n",
    "basepath = f\"/global/cfs/cdirs/desi/survey/catalogs/Y1/mocks/SecondGenMocks/\"\n",
    "pre_cov_files = f\"/global/cfs/cdirs/desi/survey/catalogs/Y1/LSS/iron/LSScats/v0.6/blinded/pk/covariances/\"\n",
    "post_cov_files = f\"/global/cfs/cdirs/desi/survey/catalogs/Y1/LSS/iron/LSScats/v0.6/blinded/pk/covariances/\"    # No post recon covariances yet?\n",
    "\n",
    "\n",
    "for t in tracers:\n",
    "    for i, zs in enumerate(tracers[t]):\n",
    "        for cap in caps:\n",
    "                    \n",
    "            pre_files = basepath + \"AbacusSummitBGS/desipipe/v1/ffa/2pt/\" if t == \"BGS_BRIGHT-21.5\" else basepath + \"AbacusSummit/\"\n",
    "            post_files = basepath + \"AbacusSummitBGS/desipipe/v1/ffa/2pt/\" if t == \"BGS_BRIGHT-21.5\" else basepath + \"AbacusSummit/\"\n",
    "            \n",
    "            pre_name =  f\"/pk/pkpoles_{t}_{cap}_z{zs[0]}-{zs[1]}_{imaging}_lin_nran18_cellsize6_boxsize4000\" if t == \"BGS_BRIGHT-21.5\" else f\"/pk/pkpoles_{t}_{ffa}_{cap}_{zs[0]}_{zs[1]}_{imaging}_lin\" \n",
    "            \n",
    "            if t == 'BGS_BRIGHT-21.5':\n",
    "                post_name = f\"/recon_sm{recon[t][0]}_IFFT_recsym/pk/pkpoles_{t}_{cap}_z{zs[0]}-{zs[1]}_{imaging}_lin_nran18_cellsize6_boxsize4000\" # if recon[t][1] is not None else None\n",
    "            else:\n",
    "                post_name = f\"/recon_sm{recon[t][0]}/pk/recon_sm{recon[t][0]}/pk/pkpoles_{t}_{ffa}_{recon[t][1]}_{cap}_{zs[0]}_{zs[1]}_{imaging}_lin\" # if recon[t][1] is not None else None\n",
    "            \n",
    "            tcov = \"ELG_LOPnotqso\" if \"ELG\" in t else t\n",
    "            pre_cov_name = f\"cov_gaussian_pre_{tcov}_{cap}_{zs[0]}_{zs[1]}_{imaging}_lin\"\n",
    "            #post_cov_name = f\"{tcov}_{recon[t][1]}_sm{recon[t][0]}_{cap}_{zs[0]}_{zs[1]}\" if recon[t][1] is not None else None\n",
    "            post_cov_name = pre_cov_name #if recon[t][1] is not None else None\n",
    "            \n",
    "            data = collect_pk_data(pre_files, post_files, pre_cov_files, post_cov_files, pre_name, post_name, pre_cov_name, post_cov_name, zs, recon[t][0], range(nmocks[t][0], nmocks[t][1]), rpcut, imaging)\n",
    "            plot_pk(data, post=False if post_name is None else True) # Plot the data to check things\n",
    "            #print(pre_name)\n",
    "            # print(post_name)\n",
    "            \n",
    "            # print(os.path.exists(pre_files + 'mock0' + pre_name + '.npy'))\n",
    "            # print(pre_files + 'mock0' + pre_name)\n",
    "            # print(os.path.exists(post_files + 'mock0' + post_name + '.npy'))\n",
    "            # print(post_files + 'mock0' + post_name)\n",
    "            \n",
    "            #print(os.path.exists(pre_cov_files + pre_cov_name))\n",
    "            #print(pre_cov_files + pre_cov_name)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586b457-ce60-4690-8b07-026044db6ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-main",
   "language": "python",
   "name": "cosmodesi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
