{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea5783-8fe9-49cb-a38b-6448ed0e3b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# test \n",
    "# this is Cullan's code to run and plot the second gen mocks with all appropriate settings \n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../Barry/\")\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from barry.models.model import Correction\n",
    "from barry.utils import weighted_avg_and_cov\n",
    "import matplotlib.colors as mplc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from chainconsumer import ChainConsumer, Chain, Truth, PlotConfig\n",
    "colors = [mplc.cnames[color] for color in [\"orange\", \"orangered\", \"firebrick\", \"lightskyblue\", \"steelblue\", \"seagreen\", \"black\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf254cf-0b69-41bd-8cdb-9cb8b0698b40",
   "metadata": {},
   "source": [
    "# read in Barry fitter object  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0b78a-2d6b-45ae-8d60-f780d558679a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = 'LRGs'\n",
    "z = [0.4, 0.6] \n",
    "mocks = 'LRGs_z04_06_pk'\n",
    "main = '/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/desi_kp4_SecondGen_'\n",
    "pfn = main + mocks + '-reducedcov/output/desi_kp4_SecondGen_' + mocks + '-reducedcov.fitter.pkl'\n",
    "\n",
    "with open(pfn, 'rb') as pickle_file:\n",
    "    fitter = pickle.load(pickle_file)\n",
    "\n",
    "tracers = {\n",
    "       \"LRG\": [[0.4, 0.6], [0.6, 0.8], [0.8, 1.1]],\n",
    "       \"ELG_LOPnotqso\": [[0.8, 1.1], [1.1, 1.6]],\n",
    "       \"QSO\": [[0.8, 2.1]],\n",
    "       \"BGS_BRIGHT-21.5\": [[0.1, 0.4]],\n",
    "        \"ELGsLRGscombined\": [[0.8, 1.1]]\n",
    "    }\n",
    "reconsmooth = {\"LRG\": 15, \"ELG_LOPnotqso\": 15, \"QSO\": 30, \"BGS_BRIGHT-21.5\": 15}\n",
    "sigma_nl_par = {\n",
    "    \"LRG\": [\n",
    "        [9.0, 6.0],\n",
    "        [9.0, 6.0],\n",
    "        [9.0, 6.0],\n",
    "    ],\n",
    "    \"ELG_LOPnotqso\": [[8.5, 6.0], [8.5, 6.0]],\n",
    "    \"QSO\": [[9.0, 6.0]],\n",
    "    \"BGS_BRIGHT-21.5\": [[10.0, 8.0]],\n",
    "    \"ELGsLRGscombined\": [[9.0, 6.0]]\n",
    "}\n",
    "sigma_nl_perp = {\n",
    "    \"LRG\": [\n",
    "        [4.5, 3.0],\n",
    "        [4.5, 3.0],\n",
    "        [4.5, 3.0],\n",
    "    ],\n",
    "    \"ELG_LOPnotqso\": [[4.5, 3.0], [4.5, 3.0]],\n",
    "    \"QSO\": [[3.5, 3.0]],\n",
    "    \"BGS_BRIGHT-21.5\": [[6.5, 3.0]],\n",
    "    \"ELGsLRGscombined\": [[4.5, 3.0]]\n",
    "    \n",
    "}\n",
    "sigma_s = {\n",
    "    \"LRG\": [[2.0, 2.0], [2.0, 2.0], [2.0, 2.0]],\n",
    "    \"ELG_LOPnotqso\": [[2.0, 2.0], [2.0, 2.0]],\n",
    "    \"QSO\": [[2.0, 2.0]],\n",
    "    \"BGS_BRIGHT-21.5\": [[2.0, 2.0]],\n",
    "    \"ELGsLRGscombined\": [[2.0, 2.0]]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60014423-40b6-45f3-9817-85a43cba8b48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# function for plotting error histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00fc69b-d192-4664-82cd-5b3bdfd13b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_errors(stats, figname, varybetaphaseshift=False, anisotropic=True):\n",
    "\n",
    "    covs = np.cov(stats, rowvar=False)    \n",
    "    nstats = len(stats)\n",
    "    means = np.mean(stats, axis=0)\n",
    "\n",
    "    labels, colors, fig, axes, zipp = None, None, None, None, None \n",
    "    \n",
    "    if anisotropic: \n",
    "        labels = [r\"$\\sigma_{\\alpha}$\", r\"$\\sigma_{\\alpha_{ap}}$\", r\"$\\chi^{2}$\"]\n",
    "        colors = [\"r\", \"b\", \"g\"]\n",
    "        fig, axes = plt.subplots(figsize=(7, 2), nrows=1, ncols=3, sharey=True, squeeze=False)\n",
    "        plt.subplots_adjust(left=0.1, top=0.95, bottom=0.05, right=0.95, hspace=0.3)\n",
    "        zipp = zip(\n",
    "                axes.T,\n",
    "                np.array(stats).T[[4, 5, 10]],\n",
    "                means[[4,5,10]],\n",
    "                [np.sqrt(covs[0, 0]), np.sqrt(covs[1, 1]), 0.0],\n",
    "                labels,\n",
    "                colors,\n",
    "            )\n",
    "    if not anisotropic: \n",
    "        labels = [r\"$\\sigma_{\\alpha}$\", r\"$\\chi^{2}$\"]\n",
    "        colors = [\"r\", \"g\"]\n",
    "        fig, axes = plt.subplots(figsize=(7, 2), nrows=1, ncols=2, sharey=True, squeeze=False)\n",
    "        plt.subplots_adjust(left=0.1, top=0.95, bottom=0.05, right=0.95, hspace=0.3)\n",
    "        zipp = zip(\n",
    "                axes.T,\n",
    "                np.array(stats).T[[1, 2]],\n",
    "                means[[1,2]],\n",
    "                [np.sqrt(covs[0, 0]), 0.0],\n",
    "                labels,\n",
    "                colors,\n",
    "            )\n",
    "    \n",
    "    if varybetaphaseshift:\n",
    "        if anisotropic: \n",
    "            labels = [r\"$\\sigma_{\\alpha}$\", r\"$\\sigma_{\\alpha_{ap}}$\",  r\"$\\sigma_{\\beta_{\\phi}}$\", r\"$\\chi^{2}$\"]\n",
    "            colors = [\"r\", \"b\", \"orange\", \"g\"]\n",
    "            fig, axes = plt.subplots(figsize=(7, 2), nrows=1, ncols=4, sharey=True, squeeze=False)\n",
    "            plt.subplots_adjust(left=0.1, top=0.95, bottom=0.05, right=0.95, hspace=0.3)\n",
    "            zipp = zip(\n",
    "                axes.T,\n",
    "                np.array(stats).T[[5, 6, 9, 13]],\n",
    "                means[[5, 6, 9, 13]],\n",
    "                [np.sqrt(covs[0, 0]), np.sqrt(covs[1, 1]), np.sqrt(covs[4, 4]), 0.0],\n",
    "                labels,\n",
    "                colors,\n",
    "            )\n",
    "        if not anisotropic:\n",
    "            labels = [r\"$\\sigma_{\\alpha}$\", r\"$\\sigma_{\\beta_{\\phi}}$\", r\"$\\chi^{2}$\"]\n",
    "            colors = [\"r\", \"orange\", \"g\" ]\n",
    "            fig, axes = plt.subplots(figsize=(7, 2), nrows=1, ncols=3, sharey=True, squeeze=False)\n",
    "            plt.subplots_adjust(left=0.1, top=0.95, bottom=0.05, right=0.95, hspace=0.3)\n",
    "            zipp = zip(\n",
    "                axes.T,\n",
    "                np.array(stats).T[[2, 3, 5]],\n",
    "                means[[2, 3, 5]],\n",
    "                [np.sqrt(covs[0, 0]), np.sqrt(covs[1, 1]), 0.0],\n",
    "                labels,\n",
    "                colors,\n",
    "            )\n",
    "    \n",
    "    for i, (ax, vals, avgs, stds, l, c) in enumerate(zipp):\n",
    "\n",
    "        ax[0].hist(vals, 10, color=c, histtype=\"stepfilled\", alpha=0.2, density=False, zorder=0)\n",
    "        ax[0].hist(vals, 10, color=c, histtype=\"step\", alpha=1.0, lw=1.3, density=False, zorder=1)\n",
    "        \n",
    "        # ax[0].axvline(data_sig[i], color=\"k\", ls=\"-\", zorder=2)\n",
    "        if l != r\"$\\chi^{2}$\":\n",
    "            ax[0].axvline(avgs, color=\"k\", ls=\"--\", zorder=2)\n",
    "            ax[0].axvline(stds, color=\"k\", ls=\":\", zorder=2)\n",
    "        ax[0].set_xlabel(l)\n",
    "        \n",
    "        axes[0, 0].set_ylabel(r\"$N_{\\mathrm{mocks}}$\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(figname, bbox_inches=\"tight\", transparent=True, dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7bbc7-9c41-4f51-a7f5-162bf7bea3f5",
   "metadata": {},
   "source": [
    "# plot the finished chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b924970-098e-49b7-beea-07faec0b03af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Everything below here is for plotting the chains once they have been run. The should_plot()\n",
    "# function will check for the presence of chains and plot if it finds them on your laptop. On the HPC you can\n",
    "# also force this by passing in \"plot\" as the second argument when calling this code from the command line.\n",
    "datanames = ['spline', 'poly', 'spline phaseshift', 'poly phaseshift']\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.info(\"Creating plots\")\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "for dataname in datanames:\n",
    "    for recon in [\"prerecon\", \"postrecon\"]:\n",
    "        plotname = f\"{dataname}_{recon}\"\n",
    "        dir_name = \"/\".join(pfn.split(\"/\")[:-1]) + \"/\" + plotname\n",
    "        try:\n",
    "            if not os.path.exists(dir_name):\n",
    "                os.makedirs(dir_name, exist_ok=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "\n",
    "# Loop over all the fitters\n",
    "c = [ChainConsumer() for i in range(2 * len(datanames))]\n",
    "stats = [[[], []] for _ in range(len(datanames))]\n",
    "\n",
    "for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "    # continue \n",
    "    \n",
    "    datname = extra['name'] \n",
    "    if '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$' in model.get_labels():\n",
    "        datname = datname + ' phaseshift'\n",
    "        \n",
    "    if 'poly' == model.broadband_type: \n",
    "        datname = datname + ' poly'\n",
    "\n",
    "    else:\n",
    "        datname = datname + ' spline'\n",
    "\n",
    "    data_bin = 0\n",
    "    if model.broadband_type == 'poly':\n",
    "        data_bin = 1\n",
    "    if '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$' in model.get_labels():\n",
    "        data_bin += 2\n",
    "        \n",
    "    recon_bin = 0 if \"Prerecon\" in extra[\"name\"] else 1\n",
    "    stats_bin = recon_bin * len(datanames) + data_bin\n",
    "    realisation = str(extra[\"name\"].split()[-1]) if \"realisation\" in extra[\"name\"] else \"mean\"\n",
    "    # print(extra[\"name\"], data_bin, recon_bin, stats_bin, realisation)\n",
    "\n",
    "    # Store the chain in a dictionary with parameter names\n",
    "    df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "\n",
    "    if \"$\\\\epsilon$\" in model.get_labels(): \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "        alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "        df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "        df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        df[\"$\\\\alpha_{ap}$\"] = (1.0 + df[\"$\\\\epsilon$\"].to_numpy()) ** 3\n",
    "        newweight = np.where(\n",
    "            np.logical_and(\n",
    "                np.logical_and(df[\"$\\\\alpha_\\\\parallel$\"] >= 0.6, df[\"$\\\\alpha_\\\\parallel$\"] <= 1.4),\n",
    "                np.logical_and(df[\"$\\\\alpha_\\\\perp$\"] >= 0.6, df[\"$\\\\alpha_\\\\perp$\"] <= 1.4),\n",
    "            ),\n",
    "            weight,\n",
    "            0.0,\n",
    "        )\n",
    "    else:\n",
    "        newweight = np.where(\n",
    "            np.logical_and(df[\"$\\\\alpha$\"] >= 0.8, df[\"$\\\\alpha$\"] <= 1.2),\n",
    "            weight,\n",
    "            0.0,\n",
    "        )\n",
    "    # Get the MAP point and set the model up at this point\n",
    "    model.set_data(data)\n",
    "    r_s = model.camb.get_data()[\"r_s\"]\n",
    "    max_post = posterior[newweight > 0].argmax()\n",
    "    params = df[newweight > 0].iloc[max_post]\n",
    "    params_dict = model.get_param_dict(chain[newweight > 0][max_post])\n",
    "    for name, val in params_dict.items():\n",
    "        model.set_default(name, val)\n",
    "    \n",
    "\n",
    "    paramscov = [\n",
    "                \"$\\\\alpha$\",\n",
    "                \"$\\\\alpha_{ap}$\",\n",
    "                \"$\\\\alpha_\\\\parallel$\",\n",
    "                \"$\\\\alpha_\\\\perp$\",\n",
    "            ]\n",
    "    if \"$\\\\epsilon$\" not in model.get_labels(): \n",
    "        paramscov = [\n",
    "                \"$\\\\alpha$\",\n",
    "            ]\n",
    "    if '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$' in model.get_labels():\n",
    "        paramscov.append(\n",
    "                '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$'\n",
    "        ) \n",
    "        \n",
    "    # Compute some summary statistics and add them to a dictionary\n",
    "    mean, cov = weighted_avg_and_cov(\n",
    "        df[\n",
    "            paramscov\n",
    "        ],\n",
    "        newweight,\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    # Add the chain or MAP to the Chainconsumer plots\n",
    "    extra.pop(\"realisation\", None)\n",
    "    #print(extra)\n",
    "    if realisation == \"mean\":\n",
    "        extra.pop(\"color\", None)\n",
    "        c[stats_bin].add_chain(\n",
    "            Chain(\n",
    "            samples=df, name=datname, weights=newweight, \n",
    "            color=\"k\", realisation=None, plot_contour=True, \n",
    "            plot_point=False, show_as_1d_prior=False\n",
    "            )\n",
    "        )\n",
    "        figname = None\n",
    "        mean_mean, cov_mean = mean, cov\n",
    "        \n",
    "    else:\n",
    "        #continue \n",
    "        # print(params)\n",
    "        c[stats_bin].add_marker(location=params.to_dict(), marker_size=50, name=datname)\n",
    "        # Get some useful properties of the fit, and plot the MAP model against the data if the bestfit alpha or alpha_ap are outliers compared to the mean fit\n",
    "#         if '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$' in model.get_labels():\n",
    "#             if \"\\\\epsilon\" in model.get_labels():\n",
    "#                 diff = np.c_[params[\"$\\\\alpha_\\\\parallel$\"], params[\"$\\\\alpha_\\\\perp$\"], params['$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$']] - mean_mean[2:]\n",
    "#             else:\n",
    "#                 diff = np.c_[params[\"$\\\\alpha$\"], params['$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$']] - mean_mean\n",
    "                \n",
    "#         else:\n",
    "#             if \"$\\\\epsilon$\" in model.get_labels():\n",
    "#                 diff = np.c_[params[\"$\\\\alpha_\\\\parallel$\"], params[\"$\\\\alpha_\\\\perp$\"]] - mean_mean[2:]\n",
    "#             else:\n",
    "#                 diff = np.c_[params[\"$\\\\alpha$\"]] - mean_mean\n",
    "                \n",
    "#         outlier = diff @ np.linalg.inv(cov_mean[2:, 2:]) @ diff.T\n",
    "        # if outlier > sp.stats.chi2.ppf(0.9545, 2, loc=0, scale=1):\n",
    "        # dataname = extra[\"name\"].split(\" \")[3].lower()\n",
    "        # plotname = f\"{datanames[data_bin]}_prerecon\" if recon_bin == 0 else f\"{datanames[data_bin]}_postrecon\"\n",
    "        # figname = \"/\".join(pfn.split(\"/\")[:-1]) + \"/\" + plotname + \"/\" + extra[\"name\"].replace(\" \", \"_\") + \"_contour.png\"\n",
    "        # # continue \n",
    "        # if not os.path.isfile(figname):\n",
    "        #     extra.pop(\"color\", None)\n",
    "        #     cc = ChainConsumer()\n",
    "        #     cc.add_chain(Chain(samples=df, name=datname, weights=newweight, color=colors[data_bin]))\n",
    "        #     cc.add_marker(location=df.iloc[max_post].to_dict(), **extra)\n",
    "        #     cc.plotter.plot(filename=figname)\n",
    "        #     figname = \"/\".join(pfn.split(\"/\")[:-1]) + \"/\" + plotname + \"/\" + extra[\"name\"].replace(\" \", \"_\") + \"_bestfit.png\"\n",
    "        # else:\n",
    "        #     figname = None\n",
    "\n",
    "    new_chi_squared, dof, bband, mods, smooths = model.simple_plot(\n",
    "        params_dict, display=False, figname=figname, title=datname, c=colors[data_bin]\n",
    "    )\n",
    "    if realisation == \"mean\":\n",
    "        print(25.0 * new_chi_squared, dof)\n",
    "\n",
    "#     if data_bin == 0 and (realisation == \"2\" or realisation == \"21\" or realisation == \"22\"):\n",
    "#         df[\"weight\"] = newweight\n",
    "#         df.to_csv(\"/\".join(pfn.split(\"/\")[:-1]) + \"/\" + plotname + f\"_BOSSpoly.dat\", index=False, sep=\" \")\n",
    "\n",
    "    if '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$' in model.get_labels(): \n",
    "        \n",
    "        if \"$\\\\epsilon$\" in model.get_labels(): \n",
    "            stats[data_bin][recon_bin].append(\n",
    "                [\n",
    "                    mean[0], # mean alpha \n",
    "                    mean[1], # mean alpha aps \n",
    "                    mean[2], # mean alpha para \n",
    "                    mean[3], # mean alpha perp \n",
    "                    mean[4], # beta phase shift \n",
    "                    np.sqrt(cov[0, 0]), \n",
    "                    np.sqrt(cov[1, 1]),\n",
    "                    np.sqrt(cov[2, 2]),\n",
    "                    np.sqrt(cov[3, 3]),\n",
    "                    np.sqrt(cov[4, 4]),\n",
    "                    cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1]), # cov alpha/alpha_AP\n",
    "                    cov[2, 3] / np.sqrt(cov[2, 2] * cov[3, 3]), # cov alpha para/perp \n",
    "                    cov[0, 4] / np.sqrt(cov[0, 0] * cov[4, 4]), # cov alpha/beta phaseshift \n",
    "                    new_chi_squared,\n",
    "                    params_dict[\"alpha\"],\n",
    "                    params_dict[\"epsilon\"],\n",
    "                    params_dict[\"beta_phase_shift\"],\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            stats[data_bin][recon_bin].append(\n",
    "                [\n",
    "                    mean[0], # mean alpha \n",
    "                    mean[1], # beta phase shift \n",
    "                    np.sqrt(cov[0, 0]), \n",
    "                    np.sqrt(cov[1, 1]),\n",
    "                    cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1]), # cov alpha/ beta phase shift \n",
    "                    new_chi_squared,\n",
    "                    params_dict[\"alpha\"],\n",
    "                    params_dict[\"beta_phase_shift\"],\n",
    "                ]\n",
    "            )\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if \"$\\\\epsilon$\" in model.get_labels(): \n",
    "        \n",
    "            stats[data_bin][recon_bin].append(\n",
    "                [\n",
    "                    mean[0], # mean alpha \n",
    "                    mean[1], # mean alpha aps \n",
    "                    mean[2], # mean alpha para \n",
    "                    mean[3], # mean alpha perp \n",
    "                    np.sqrt(cov[0, 0]), \n",
    "                    np.sqrt(cov[1, 1]),\n",
    "                    np.sqrt(cov[2, 2]),\n",
    "                    np.sqrt(cov[3, 3]),\n",
    "                    cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1]), # cov alpha/alpha_AP\n",
    "                    cov[2, 3] / np.sqrt(cov[2, 2] * cov[3, 3]), # cov alpha para/perp \n",
    "                    new_chi_squared,\n",
    "                    params_dict[\"alpha\"],\n",
    "                    params_dict[\"epsilon\"],\n",
    "                ]\n",
    "            ) \n",
    "        else: \n",
    "            stats[data_bin][recon_bin].append(\n",
    "                [\n",
    "                    mean[0], # mean alpha \n",
    "                    np.sqrt(cov), \n",
    "                    new_chi_squared,\n",
    "                    params_dict[\"alpha\"],\n",
    "                ]\n",
    "            ) \n",
    "print('done')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc61591-663e-4e48-84f6-eb39828543ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# write the best fits to a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d843a5-9678-4b50-bb24-a288141d231a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loc = '/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/secondgenv1_2_'\n",
    "\n",
    "for i, name in enumerate(datanames):\n",
    "    if i < 2:\n",
    "        continue \n",
    "    for j, recon in enumerate(['pre', 'post']):\n",
    "        \n",
    "        #print(name, recon)\n",
    "        dat = stats[i][j]\n",
    "        #print(dat)\n",
    "        if mocks[:-3] in ['ELGs_z08_11', 'QSOs_z08_21', 'BGS_z01_04']: # no epsilon \n",
    "            \n",
    "            if i > 1: \n",
    "                \n",
    "                colnames = ['<alpha>', '<beta_phi>', 'sigma_alpha', 'sigma_beta_phi', 'rho_alpha-beta_phi', 'chisquare', \n",
    "                            'max posterior alpha', 'max posterior beta_phi']\n",
    "  \n",
    "            else:\n",
    "                \n",
    "                colnames = ['<alpha>', 'sigma_alpha', 'chisquare', 'max posterior alpha']\n",
    "                \n",
    "                \n",
    "        else: # there is epsilon\n",
    "            \n",
    "            if i > 1: \n",
    "                  \n",
    "                colnames = ['<alpha>', '<alpha_AP>', '<alpha_para>', '<alpha_perp>', '<beta_phi>', \n",
    "                            'sigma_alpha', 'sigma_alpha_AP', 'sigma_alpha_para', 'sigma_alpha_perp', 'sigma_beta_phi', \n",
    "                            'rho_alpha-alpha_AP', 'rho_alpha_para-alpha_perp', 'rho_alpha-beta_phi', \n",
    "                            'chisquare', \n",
    "                            'max posterior alpha', 'max posterior epsilon', 'max posterior beta_phi']\n",
    "            else:\n",
    "                \n",
    "                colnames = ['<alpha>', '<alpha_AP>', '<alpha_para>', '<alpha_perp>',\n",
    "                            'sigma_alpha', 'sigma_alpha_AP', 'sigma_alpha_para', 'sigma_alpha_perp',\n",
    "                            'rho_alpha-alpha_AP', 'rho_alpha_para-alpha_perp',\n",
    "                            'chisquare', \n",
    "                            'max posterior alpha', 'max posterior epsilon']\n",
    "                \n",
    "        dat = pd.DataFrame(dat)\n",
    "        dat.columns = colnames\n",
    "        #print(dat)\n",
    "        \n",
    "        dat['mock'] = ['mean', '0', '1', '2', '3', '4', '5', '6','7', '8', '9', '10', '11', '12', '13', '14', '15', '16','17', '18', \n",
    "                      '19', '20', '21', '22', '23', '24']\n",
    "\n",
    "        dat.to_csv(loc + name + '_' + recon + '_' + mocks + '.csv', index=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1c6da-51e2-49de-abec-6e7eac6c7f1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# plot mean of the mocks fits + markers for other fits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa160c4e-84c1-45dc-a63c-5192357b1513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for j in np.arange(2,4):#range(4):\n",
    "    for k in range(2):\n",
    "        stats_bin = k*4 + j \n",
    "        \n",
    "        # if j > 1:\n",
    "        #     continue \n",
    "        rec = ''\n",
    "        if k == 0:\n",
    "            rec = 'prerecon'\n",
    "        else:\n",
    "            rec = 'postrecon'\n",
    "            \n",
    "        print('mock mean' + mocks + datanames[j] + rec)\n",
    "\n",
    "        c[stats_bin].set_plot_config(PlotConfig(show_legend=False))\n",
    "        cols = ['$\\\\alpha$','$\\\\alpha_{ap}$']\n",
    "        if mocks[:-3] in ['BGS_z01_04', 'ELGs_z08_11', 'QSOs_z08_21']: \n",
    "            cols = ['$\\\\alpha$']\n",
    "        if j > 1: \n",
    "            cols = ['$\\\\alpha$','$\\\\alpha_{ap}$', '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$']\n",
    "            if mocks[:-3] in ['BGS_z01_04', 'ELGs_z08_11', 'QSOs_z08_21']: \n",
    "                cols = ['$\\\\alpha$', '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$']\n",
    "        c[stats_bin].plotter.plot(columns=cols, \n",
    "        filename=\"/\".join(pfn.split(\"/\")[:-1]) + \"/\" +'mock mean' + mocks + datanames[j] + rec,\n",
    "        )\n",
    "        if j <= 1:\n",
    "            print('-------------------------------------')\n",
    "            print(c[stats_bin].analysis.get_latex_table(columns=cols))\n",
    "            print('-------------------------------------')\n",
    "            \n",
    "        else:\n",
    "            print('-------------------------------------')\n",
    "            print(c[stats_bin].analysis.get_latex_table(columns=cols))\n",
    "            print('-------------------------------------')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d23d7-4446-4dd6-a743-6125d44d2269",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# plot errors on fits histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35c6b5-d52a-4aba-9ac9-375ef4e0e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for recon_bin in range(2):\n",
    "    for data_bin in range(4):\n",
    "        # continue \n",
    "        dataname = datanames[data_bin]\n",
    "        stats_bin = recon_bin * len(datanames) + data_bin\n",
    "        i = tracers[t].index(z)\n",
    "\n",
    "        mean = np.mean(stats[data_bin][recon_bin][1:], axis=0)\n",
    "        cov = np.cov(stats[data_bin][recon_bin][1:], rowvar=False)\n",
    "\n",
    "#         c[stats_bin].from_covariance(\n",
    "#             mean[:4],\n",
    "#             cov[:4, :4],\n",
    "#             parameters=[\"$\\\\alpha$\", \"$\\\\alpha_{ap}$\", \"$\\\\alpha_\\\\parallel$\", \"$\\\\alpha_\\\\perp$\"],\n",
    "#             color=colors[data_bin],\n",
    "#             plot_contour=True,\n",
    "#             plot_point=False,\n",
    "#             show_as_1d_prior=False,\n",
    "#         )\n",
    "\n",
    "#         truth = {\n",
    "#             \"$\\\\alpha$\": 1.0,\n",
    "#             \"$\\\\alpha_{ap}$\": 1.0,\n",
    "#             \"$\\\\alpha_\\\\perp$\": 1.0,\n",
    "#             \"$\\\\alpha_\\\\parallel$\": 1.0,\n",
    "#             \"$\\\\Sigma_{nl,||}$\": sigma_nl_par[t][i][recon_bin],\n",
    "#             \"$\\\\Sigma_{nl,\\\\perp}$\": sigma_nl_perp[t][i][recon_bin],\n",
    "#             \"$\\\\Sigma_s$\": sigma_s[t][i][recon_bin],\n",
    "#         }\n",
    "\n",
    "#         plotname = f\"{dataname}_prerecon\" if recon_bin == 0 else f\"{dataname}_postrecon\"\n",
    "#         c[stats_bin].plotter.plot(\n",
    "#             filename=[\"/\".join(pfn.split(\"/\")[:-1]) + \"/\" + plotname + f\"_contour.png\"],\n",
    "#             truth=truth,\n",
    "#             parameters=[\n",
    "#                 \"$\\\\alpha_\\\\parallel$\",\n",
    "#                 \"$\\\\alpha_\\\\perp$\",\n",
    "#             ],\n",
    "#             legend=False,\n",
    "#         )\n",
    "#         c[stats_bin].plotter.plot(\n",
    "#             filename=[\"/\".join(pfn.split(\"/\")[:-1]) + \"/\" + plotname + f\"_contour2.png\"],\n",
    "#             truth=truth,\n",
    "#             parameters=[\n",
    "#                 \"$\\\\alpha$\",\n",
    "#                 \"$\\\\alpha_{ap}$\",\n",
    "#             ],\n",
    "#             legend=False,\n",
    "#         )\n",
    "\n",
    "        # Plot histograms of the chi squared values and uncertainties for comparison to the data\n",
    "\n",
    "        # data_sig = data_sigmas_prerecon[t][i] if recon_bin == 0 else data_sigmas_postrecon[t][i]\n",
    "        \n",
    "        plotname = f\"{dataname}_prerecon\" if recon_bin == 0 else f\"{dataname}_postrecon\"\n",
    "        plot_errors(stats[data_bin][recon_bin], \"/\".join(pfn.split(\"/\")[:-1]) + \"/\" + plotname + f\"_errors.png\",\n",
    "            varybetaphaseshift=True if data_bin > 1 else False, \n",
    "            anisotropic=False if mocks[:-3] in ['BGS_z01_04', 'ELGs_z08_11', 'QSOs_z08_21'] else True)\n",
    "        np.save(\"/\".join(pfn.split(\"/\")[:-1]) + \"/Summary_\" + plotname + f\".npy\", stats[data_bin][recon_bin])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bbf176-57e0-4e58-b709-e023099aa066",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# plotting combinations of the mocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07c81e-ab97-4822-bbf2-9a4763438f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chainconsumer import ChainConsumer, Chain, Truth, PlotConfig     \n",
    "\n",
    "sys.path.append(\"../../Barry/\")     # Change this so that it points to where you have Barry installed\n",
    "\n",
    "#from barry.samplers import DynestySampler\n",
    "from barry.samplers import NautilusSampler\n",
    "from barry.config import setup\n",
    "from barry.models import PowerBeutler2017, CorrBeutler2017\n",
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "from barry.fitter import Fitter\n",
    "from barry.models.model import Correction # class for applying corrections to the likelihood function \n",
    "from barry.utils import weighted_avg_and_cov # function for getting avg and covariance \n",
    "\n",
    "\n",
    "path_p1 = '/global/u1/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/plots/'\n",
    "\n",
    "dat = '_pk' \n",
    "\n",
    "pfns = []\n",
    "# listnames = ['BGS_z01_04', 'LRGs_z04_06', 'LRGs_z06_08', 'ELGsLRGscombined_z08_11', 'ELGs_z11_16', 'QSOs_z08_21', 'LRGs_z08_11', 'ELGs_z08_11']#,\n",
    "listnames = ['BGS_z01_04', 'LRGs_z04_06', 'LRGs_z06_08', 'ELGs_z11_16', 'QSOs_z08_21', 'LRGs_z08_11', 'ELGs_z08_11']#,\n",
    "\n",
    "for i in listnames:\n",
    "    pfns.append(path_p1 + 'desi_kp4_SecondGen_' + i + dat + '/output/desi_kp4_SecondGen_' + i + dat + '.fitter.pkl')\n",
    "\n",
    "\n",
    "c = ChainConsumer() \n",
    "\n",
    "for i,p in enumerate(pfns): \n",
    "    #print(i)\n",
    "    with open(p, 'rb') as pickle_file:\n",
    "        fitter = pickle.load(pickle_file)\n",
    "\n",
    "    count = 0\n",
    "    for posterior, weight, chain, evidence, model, data, extra in fitter.load():\n",
    "        \n",
    "        \n",
    "        if 'mean' not in extra['name']:  # making sure we only get chain for mock mean \n",
    "            continue \n",
    "            \n",
    "        if 'Prerecon' not in extra['name']: # making sure we only get results from recon \n",
    "            continue  \n",
    "                \n",
    "        if '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$' not in model.get_labels():\n",
    "                continue \n",
    "                \n",
    "        df = pd.DataFrame(chain, columns=model.get_labels())\n",
    "    \n",
    "        # Compute alpha_par and alpha_perp for each point in the chain\n",
    "#         alpha_par, alpha_perp = model.get_alphas(df[\"$\\\\alpha$\"].to_numpy(), df[\"$\\\\epsilon$\"].to_numpy())\n",
    "#         df[\"$\\\\alpha_\\\\parallel$\"] = alpha_par\n",
    "#         df[\"$\\\\alpha_\\\\perp$\"] = alpha_perp\n",
    "        \n",
    "        # Add the chain or MAP to the Chainconsumer plots\n",
    "        #print(extra)\n",
    "        extraname = ''\n",
    "        if model.broadband_type == 'spline':\n",
    "            extraname = ' spline' \n",
    "        else:\n",
    "            extraname = 'poly'\n",
    "            \n",
    "        extra.pop(\"realisation\", 'mean' + extraname)\n",
    "        # extra[\"name\"] = names[i] + extraname\n",
    "        extra[\"name\"] = extra['name'] + extraname\n",
    "        \n",
    "       \n",
    "        c.add_chain(Chain(samples=df, weights=weight, name=listnames[i] + extraname, plot_contour=True, plot_point=False, show_as_1d_prior=False))\n",
    "        \n",
    "        # model.set_data(data)\n",
    "        # r_s = model.camb.get_data()[\"r_s\"]\n",
    "        # max_post = posterior.argmax()\n",
    "        # params = df.loc[max_post]\n",
    "        # params_dict = model.get_param_dict(chain[max_post])\n",
    "        # for name, val in params_dict.items():\n",
    "        #     model.set_default(name, val)\n",
    "\n",
    "        # new_chi_squared, dof, bband, mods, smooths = model.plot(params_dict, display=False)\n",
    "        # k = model.data[0][\"ks\"]\n",
    "        # axes[i][count].scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        # axes[i][count].plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # axes[i][count].legend()\n",
    "        \n",
    "        #plt.scatter(k, (model.data[0]['pk0'][0]- smooths[0][0])*k, label= extraname + ' data')\n",
    "        # plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # plt.legend()\n",
    "        # count += 1\n",
    "\n",
    "        \n",
    "        # if i == 0:\n",
    "        #     default = smooths[0][0]\n",
    "        # # plt.plot(k, (mods[0][0] - smooths[0][0])*k, label=extraname)\n",
    "        # plt.plot(k, (smooths[0][0]/default)*k, label=extraname)\n",
    "        \n",
    "        \n",
    "    \n",
    "# alpha_para, alpha_perp, beta = 0.97912566, 0.98881584, 1.0\n",
    "\n",
    "alpha_para, alpha_perp = 1.0, 1.0 # 1.00093140, 1.01083738\n",
    "#couplingterm = 1.0/0.22710731766023898\n",
    "#beta = (3.044/(3.044+couplingterm)) / (3.7/(3.7+couplingterm))  \n",
    "beta = 1.0\n",
    "\n",
    "alpha, eps = 1.0, 0.0 #model.get_reverse_alphas(alpha_para, alpha_perp)\n",
    "   \n",
    "truth = {\"$\\\\alpha$\": alpha, \"$\\\\epsilon$\": eps, \n",
    "        #  \"$\\\\alpha_\\\\parallel$\": alpha_para, \"$\\\\alpha_\\\\perp$\": alpha_perp, \n",
    "         '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$': 1.0\n",
    "        }\n",
    "\n",
    "parameters = [names for names in truth]\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel(r'$k$ $\\mathrm{Mpc}^{-1} h$')\n",
    "# plt.ylabel(r'$k P_0(k)$ $\\mathrm{Mpc}^2 h^{-2}$')\n",
    "c.set_plot_config(PlotConfig(label_font_size=10))\n",
    "c.add_truth(Truth(location=truth)) \n",
    "c.plotter.plot(columns=['$\\\\alpha$', '$\\\\epsilon$', '$\\\\beta_{\\\\phi(N_{\\\\mathrm{eff}})}$'])\n",
    "#     truth=truth,\n",
    "#         parameters = parameters[:2]+parameters[4:], \n",
    "#         legend=True,\n",
    "#         display=False,\n",
    "#         figsize=(13, 13), \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7099f-c6e0-4c6a-abd5-5a10d29f345d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barry_env_desiproject_aw",
   "language": "python",
   "name": "barry_env_desiproject_aw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
