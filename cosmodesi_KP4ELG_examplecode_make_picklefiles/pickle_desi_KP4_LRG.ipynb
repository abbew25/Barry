{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d12a836-51f0-44d8-a85b-426188145ad1",
   "metadata": {},
   "source": [
    "# NOTEBOOK FOR DEFAULT LRG - PICKLE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8117d9-b291-411b-9fc0-b4c3ba3af981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages and set up the fiducial cosmology\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from astropy.io import ascii\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import splrep, splev\n",
    "from cosmoprimo import PowerSpectrumBAOFilter\n",
    "from cosmoprimo.fiducial import DESI\n",
    "from pypower import BaseMatrix, CatalogFFTPower, CatalogFFTCorr, PowerSpectrumMultipoles, PowerSpectrumSmoothWindow, PowerSpectrumSmoothWindowMatrix, PowerSpectrumOddWideAngleMatrix, setup_logging\n",
    "from pycorr import TwoPointCorrelationFunction, project_to_multipoles\n",
    "cosmo = DESI()\n",
    "print(cosmo[\"Omega_b\"]*cosmo[\"h\"]**2, cosmo[\"Omega_cdm\"]*cosmo[\"h\"]**2, cosmo[\"Omega_m\"]*cosmo[\"h\"]**2 - cosmo[\"Omega_b\"]*cosmo[\"h\"]**2)\n",
    "print(cosmo[\"ln10^10A_s\"], cosmo[\"n_s\"], cosmo[\"tau_reio\"])\n",
    "print(np.sum(cosmo[\"m_ncdm\"]))\n",
    "\n",
    "# Save the default DESI template to a file\n",
    "k_min = 1e-4\n",
    "k_max = 5\n",
    "k_num = 2000\n",
    "kl = np.logspace(np.log(k_min), np.log(k_max), k_num, base=np.e)\n",
    "pkz = cosmo.get_fourier().pk_interpolator()\n",
    "pk = pkz.to_1d(z=0)\n",
    "pkv = pk(kl)\n",
    "pknow = PowerSpectrumBAOFilter(pk, engine='wallish2018').smooth_pk_interpolator()\n",
    "pksmv = pknow(kl)\n",
    "# np.savetxt(\"./DESI_Pk_template.dat\", np.c_[kl, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g\", header=\"k     pk_smooth     pk_ratio\")\n",
    "\n",
    "# A useful sort function for Christoph's files.\n",
    "def sortfunc_cs(item):\n",
    "    if \"EZmock\" in item:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[1][4:-4])\n",
    "        else:\n",
    "            return int(item.split(\"_\")[3][:-4])\n",
    "    else:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[3][:-4])\n",
    "        else:\n",
    "            return int(item.split(\"_\")[1][-3:])\n",
    "\n",
    "# A useful sort function for Sesh's files.\n",
    "def sortfunc_sn(item):\n",
    "    if \"EZmock\" in item:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[1][4:-4])\n",
    "    else:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[3][2:5])\n",
    "        else:\n",
    "            return int(item.split(\"_\")[4][2:5])\n",
    "        \n",
    "# A useful sort function for Daniel's files.\n",
    "def sortfunc_dfs(item):\n",
    "    if \"EZmock\" in item:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[4][4:-4])\n",
    "    else:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[3][2:5])\n",
    "        else:\n",
    "            return int(item.split(\"_\")[4][2:5])\n",
    "        \n",
    "# A useful sort function for Daniel's files.\n",
    "def sortfunc_dfs(item):\n",
    "    if \"EZmock\" in item:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[4][4:-4])\n",
    "    else:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[3][2:5])\n",
    "        else:\n",
    "            return int(item.split(\"_\")[4][2:5])\n",
    "        \n",
    "# A useful sort function for Boryana's files.\n",
    "def sortfunc_bh(item):\n",
    "    if \"EZmock\" in item:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[4][4:-4])\n",
    "    else:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[3][2:5])\n",
    "        else:\n",
    "            return int(item.split(\"_\")[4][2:5])\n",
    "        \n",
    "# A useful sort function for Cristhian's files.\n",
    "def sortfunc_cgq(item):\n",
    "    if \"EZmock\" in item:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[4][4:-4])\n",
    "    else:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[2][2:5])\n",
    "        else:\n",
    "            return int(item.split(\"_\")[4][2:5])\n",
    "        \n",
    "# A useful sort function for Cristhian's files.\n",
    "def sortfunc_x(item):\n",
    "    if \"EZmock\" in item:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[4][4:-4])\n",
    "    else:\n",
    "        if \"CubicBox\" in item:\n",
    "            return int(item.split(\"_\")[9][5:8])\n",
    "        else:\n",
    "            return int(item.split(\"_\")[4][2:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e5227-7693-45c7-aa68-b88a40cc4d4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Power spectrum routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a9dbf2-d720-4504-8168-d86d00601b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Spectrum. Juan Mena Fern√°ndez style where everything is put into single files per multipole. Barry needs 5 even+odd multipoles, but the odd ones can be filled with zeros if these haven't been measured, as is done here.\n",
    "def getpk(loc, zname):\n",
    "    kin = pd.read_csv(loc+\"/k.txt\", comment=\"#\", skiprows=0, delim_whitespace=True, header=None).to_numpy().T[0]\n",
    "    pkmat = [pd.read_csv(loc+f\"/Pk_{ell}\"+zname+\".txt\", comment=\"#\", skiprows=0, delim_whitespace=True, header=None).to_numpy().T for ell in [0,2,4]]\n",
    "\n",
    "    # Overwrite the <k> with the bin centres as we now use a binning matrix to correct to <P(k)>\n",
    "    kin = np.linspace(0.0, 0.5, 100, endpoint=False) + 0.0025\n",
    "    \n",
    "    res = []\n",
    "    nmocks = np.shape(pkmat[0])[0]\n",
    "    for i in range(nmocks):\n",
    "        df = {}\n",
    "        df[\"k\"] = kin\n",
    "        for l, ell in enumerate([0, 2, 4]):\n",
    "            df[f\"pk{ell}\"] = pkmat[l][i]\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        res.append(pd.DataFrame(df)[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "# Power Spectrum, Sesh Nadathur style where we read in the .npy files. Barry needs 5 even+odd multipoles, but the odd ones can be filled with zeros if these haven't been measured, as is done here.\n",
    "# Forces the k-values to be the same between pre- and post-recon if they are available as this is needed to align the window function.\n",
    "def getpk_sn(loc, zname, ks=None):\n",
    "\n",
    "    rebinfactor = 1\n",
    "    \n",
    "    files = [loc + f for f in os.listdir(loc) if zname in f and \".npy\" in f]\n",
    "    if \"CubicBox\" in files[0] and \"LRG\" in files[0]:\n",
    "         files = [f for f in files if \"b2.35\" in f]\n",
    "    files.sort(key=sortfunc_sn)\n",
    "        \n",
    "    # Overwrite the <k> with the bin centres as we now use a binning matrix to correct to <P(k)>\n",
    "    ks = np.linspace(0.0, 0.5, 100, endpoint=False) + 0.0025\n",
    "    \n",
    "    res = []\n",
    "    for f in files:\n",
    "        data = PowerSpectrumMultipoles.load(f)\n",
    "        data.slice(slice(0,100,1))\n",
    "        data.rebin(rebinfactor)\n",
    "        df = pd.DataFrame(np.vstack(data(ell=[0,2,4], return_k=True)).T.real, columns=[\"k\", \"pk0\", \"pk2\", \"pk4\"])\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"nk\"] = data.nmodes\n",
    "        if ks is not None:\n",
    "            df[\"k\"] = ks\n",
    "        res.append(df[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "    return res\n",
    "     \n",
    "# Power Spectrum, Cristhian Garcia-Quintero style where we read in the .npy files. Barry needs 5 even+odd multipoles, but the odd ones can be filled with zeros if these haven't been measured, as is done here.\n",
    "# Forces the k-values to be the same between pre- and post-recon if they are available as this is needed to align the window function.\n",
    "def getpk_cgq(loc, zname, ks=None):\n",
    "\n",
    "    rebinfactor = 1\n",
    "    \n",
    "    files = [loc + f for f in os.listdir(loc) if zname in f and \".npy\" in f]\n",
    "    files.sort(key=sortfunc_cgq)\n",
    "                \n",
    "    # Overwrite the <k> with the bin centres as we now use a binning matrix to correct to <P(k)>\n",
    "    ks = np.linspace(0.0, 0.5, 100, endpoint=False) + 0.0025\n",
    "        \n",
    "    res = []\n",
    "    for f in files:\n",
    "        data = CatalogFFTPower.load(f).poles\n",
    "        data.slice(slice(0,100,1))\n",
    "        data.rebin(rebinfactor)\n",
    "        df = pd.DataFrame(np.vstack(data(ell=[0,2,4], return_k=True)).T.real, columns=[\"k\", \"pk0\", \"pk2\", \"pk4\"])\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"nk\"] = data.nmodes\n",
    "        if ks is not None:\n",
    "            df[\"k\"] = ks\n",
    "        res.append(df[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "    return res\n",
    "\n",
    "# Power Spectrum, Xinyi style where we read in the .npy files. Barry needs 5 even+odd multipoles, but the odd ones can be filled with zeros if these haven't been measured, as is done here.\n",
    "# Forces the k-values to be the same between pre- and post-recon if they are available as this is needed to align the window function.\n",
    "def getpk_x(loc, zname, ks=None):\n",
    "\n",
    "    rebinfactor = 1\n",
    "    \n",
    "    files = [loc + f for f in os.listdir(loc) if zname in f and \".npy\" in f]\n",
    "    files.sort(key=sortfunc_x)\n",
    "                \n",
    "    # Overwrite the <k> with the bin centres as we now use a binning matrix to correct to <P(k)>\n",
    "    ks = np.linspace(0.0, 0.5, 100, endpoint=False) + 0.0025\n",
    "        \n",
    "    res = []\n",
    "    for f in files:\n",
    "        data = CatalogFFTPower.load(f).poles\n",
    "        data.slice(slice(0,100,1))\n",
    "        data.rebin(rebinfactor)\n",
    "        df = pd.DataFrame(np.vstack(data(ell=[0,2,4], return_k=True)).T.real, columns=[\"k\", \"pk0\", \"pk2\", \"pk4\"])\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"nk\"] = data.nmodes\n",
    "        if ks is not None:\n",
    "            df[\"k\"] = ks\n",
    "        res.append(df[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "    return res\n",
    "\n",
    "# Power Spectrum. Pat Macdonald ICs style, where we have already written a new file combining the dd, de and ee terms given a value for bias and f\n",
    "def getpk_pm(loc, zname):\n",
    "        \n",
    "    kin = np.load(loc + '/ks_for_P_576.npy')\n",
    "    pkmat = np.load('./ic_LRG_pk_25.npy').T\n",
    "    print(np.shape(pkmat))\n",
    "    \n",
    "    # Overwrite the <k> with the bin centres as we now use a binning matrix to correct to <P(k)>\n",
    "    kin = np.linspace(0.0, 0.5, 100, endpoint=False) + 0.0025\n",
    "    \n",
    "    res = []\n",
    "    nmocks = np.shape(pkmat[0])[0]\n",
    "    print(nmocks)\n",
    "    for i in range(nmocks):\n",
    "        df = {}\n",
    "        df[\"k\"] = kin\n",
    "        index = np.where(df[\"k\"] < 0.5)\n",
    "        df[\"k\"] = df[\"k\"][index]\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        for l, ell in enumerate([0, 2, 4]):\n",
    "            df[f\"pk{ell}\"] = pkmat[i][l][index]\n",
    "        print(pd.DataFrame(df))\n",
    "        res.append(pd.DataFrame(df)[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "        \n",
    "    return res\n",
    "\n",
    "# Power Spectrum, Daniel Forero-Sanchez style where each power spectrum file is in it's own directory. Barry needs 5 even+odd multipoles, but the odd ones can be filled with zeros if these haven't been measured, as is done here.\n",
    "# Forces the k-values to be the same between pre- and post-recon if they are available as this is needed to align the window function.\n",
    "def getpk_dfs(loc, zname, ks=None):\n",
    "\n",
    "    rebinfactor = 1\n",
    "    \n",
    "    files = [loc + f + \"/sym_pk.pkl.npy\" for f in os.listdir(loc)]\n",
    "    files.sort(key=sortfunc_dfs)\n",
    "\n",
    "    # Overwrite the <k> with the bin centres as we now use a binning matrix to correct to <P(k)>\n",
    "    kin = np.linspace(0.0, 0.5, 100, endpoint=False) + 0.0025\n",
    "                \n",
    "    res = []\n",
    "    for f in files:\n",
    "        data = CatalogFFTPower.load(f).poles\n",
    "        data.slice(slice(0,100,1))\n",
    "        data.rebin(rebinfactor)\n",
    "        df = pd.DataFrame(np.vstack(data(ell=[0,2,4], return_k=True)).T.real, columns=[\"k\", \"pk0\", \"pk2\", \"pk4\"])\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"nk\"] = data.nmodes\n",
    "        if ks is not None:\n",
    "            df[\"k\"] = ks\n",
    "        res.append(df[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "    return res\n",
    "\n",
    "# Power Spectrum, Boryana Hadzhiyska style where each power spectrum file is a csv to be read in using astropy and both pre- and post-recon are in teh directory. Barry needs 5 even+odd multipoles, but the odd ones can be filled with zeros if these haven't been measured, as is done here.\n",
    "# Forces the k-values to be the same between pre- and post-recon if they are available as this is needed to align the window function.\n",
    "def getpk_bh(loc, zname, ks=None):\n",
    "    \n",
    "    files = [loc + f for f in os.listdir(loc) if 'snap' in f]\n",
    "    print(files)\n",
    "    files.sort(key=sortfunc_bh)\n",
    "\n",
    "    # Overwrite the <k> with the bin centres as we now use a binning matrix to correct to <P(k)>\n",
    "    kin = np.linspace(0.0, 0.5, 100, endpoint=False) + 0.0025\n",
    "    \n",
    "    res = []\n",
    "    for f in files:\n",
    "        data = ascii.read(f)\n",
    "        df = pd.DataFrame(data['kmid'])\n",
    "        df[\"k\"] = df[\"kmid\"]\n",
    "        df[\"pk0\"] = data[\"P0(k)_CV\"]\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"pk2\"] = data[\"P2(k)_CV\"]\n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        df[\"pk4\"] = data[\"P4(k)_CV\"]\n",
    "        df[\"nk\"] = data[\"nmodes\"]\n",
    "        df = df.drop(df[df[\"k\"] >= 0.5].index)\n",
    "        if ks is not None:\n",
    "            df[\"k\"] = ks\n",
    "        res.append(df[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "    return res\n",
    "\n",
    "# Window function matrix. The window functions are stored in a dictionary of 'step sizes' i.e., how many bins get stuck together relative to the \n",
    "# pk measurements so that we can rebin the P(k) at run time if required. Each step size is a dictionary with:\n",
    "#    the input and output k binning (w_ks_input, w_ks_output), the window function matrix (w_transform) and integral constraint (w_k0_scale).\n",
    "# The window function assumes 6 input and 5 output multipoles. For cubic sims, we can set the integral constraint to zero and window matrix to a binning matrix, as is done here.\n",
    "def getwin_dummy(ks):\n",
    "    \n",
    "    dk = ks[1] - ks[0]\n",
    "    ks_input = np.logspace(-3.0, np.log10(0.5), 500)\n",
    "\n",
    "    binmat = np.zeros((len(ks), len(ks_input)))\n",
    "    for ii in range(len(ks_input)):\n",
    "\n",
    "        # Define basis vector\n",
    "        pkvec = np.zeros_like(ks_input)\n",
    "        pkvec[ii] = 1\n",
    "\n",
    "        # Define the spline:\n",
    "        pkvec_spline = splrep(ks_input, pkvec)\n",
    "\n",
    "        # Now compute binned basis vector:\n",
    "        tmp = np.zeros_like(ks)\n",
    "        for i, kk in enumerate(ks):\n",
    "            kl = kk - dk / 2\n",
    "            kr = kk + dk / 2\n",
    "            kin = np.linspace(kl, kr, 100)\n",
    "            tmp[i] = np.trapz(kin**2 * splev(kin, pkvec_spline, ext=3), x=kin) * 3 / (kr**3 - kl**3)\n",
    "\n",
    "        binmat[:, ii] = tmp\n",
    "\n",
    "    plt.imshow(binmat)\n",
    "    plt.show()\n",
    "\n",
    "    w_transform = np.zeros((5 * ks.size, 6 * ks_input.size))\n",
    "    for i in range(5):\n",
    "        w_transform[i*ks.size: (i+1)*ks.size , i*ks_input.size : (i+1)*ks_input.size] = binmat\n",
    "    \n",
    "    # The conversion matrix M from Beutler 2019. Used to compute the odd multipole models given the even multipoles. In the absence of wide angle effects, or if we don't care about\n",
    "    # the odd multipoles, we can set this to a block matrix with identity matrices in the appropriate places, as is done here.\n",
    "    matrix = np.zeros((6 * ks_input.size, 3 * ks_input.size))\n",
    "    matrix[: ks_input.size, : ks_input.size] = np.diag(np.ones(ks_input.size))\n",
    "    matrix[2 * ks_input.size : 3 * ks_input.size, ks_input.size : 2 * ks_input.size] = np.diag(np.ones(ks_input.size))\n",
    "    matrix[4 * ks_input.size : 5 * ks_input.size, 2 * ks_input.size :] = np.diag(np.ones(ks_input.size))\n",
    "    \n",
    "    res = {\"w_ks_input\": ks_input, \"w_k0_scale\": np.zeros(ks.size), \"w_transform\": w_transform, \"w_ks_output\": ks}\n",
    "    return {1: res}, matrix  # Step size is one\n",
    "\n",
    "\n",
    "# Read's in Juan's k-space window multipoles and use the routines in pypower to convert these to window and wideangle matrices\n",
    "def getwin(ks, winfile):\n",
    "    \n",
    "    wa_orders = 1 # wide-angle order\n",
    "    ellsin = [0, 2, 4] # input (theory) multipoles\n",
    "    ellsout = [0, 1, 2, 3, 4] # output multipoles\n",
    "    \n",
    "    # Check for the presence of window and wide angle matrix files already. If we find both, just load them in\n",
    "    winmatname = winfile + \"_matrix.npy\"\n",
    "    wideanglename = winfile + \"_wideangle.npy\"\n",
    "    if os.path.exists(winmatname) and os.path.exists(wideanglename):\n",
    "    \n",
    "        wm = BaseMatrix.load(winmatname)\n",
    "        wam = BaseMatrix.load(wideanglename)\n",
    "        \n",
    "    else:\n",
    "\n",
    "        window = PowerSpectrumSmoothWindow.load(winfile + \".npy\")\n",
    "\n",
    "        sep = np.geomspace(1e-4, 1e4, 1024*16) # configuration space separation for FFTlog\n",
    "        kin_rebin = 8 # rebin input theory to save memory, and run time when fitting.\n",
    "        kin_lim = (1e-4, 0.4) # pre-cut input (theory) ks to save some memory\n",
    "        projsin = ellsin + PowerSpectrumOddWideAngleMatrix.propose_out(ellsin, wa_orders=wa_orders)\n",
    "        wm = PowerSpectrumSmoothWindowMatrix(ks, projsin=projsin, projsout=ellsout, window=window, sep=sep, kin_rebin=kin_rebin, kin_lim=kin_lim, default_zero=True)\n",
    "        wam = PowerSpectrumOddWideAngleMatrix(wm.xin[0], projsin=ellsin, projsout=wm.projsin, d=1., wa_orders=wa_orders, los=window.attrs['los_type'])\n",
    "        \n",
    "        # Save the matrices\n",
    "        wm.save(winmatname)\n",
    "        wam.save(wideanglename)\n",
    "        # The pypower functions store the inner chunks in the order 0, 2, 4, 1, 3, 5, \n",
    "        # but Barry expects 0, 1, 2, 3, 4, 5. So let's break the matrices apart and reorder them.\n",
    "        wm_reshape = np.vsplit(wm.value, 6)\n",
    "        wm_reshape = np.concatenate([wm_reshape[0],wm_reshape[3],wm_reshape[1],wm_reshape[4],wm_reshape[2],wm_reshape[5]]).T    \n",
    "        wam_reshape = np.hsplit(wam.value, 6)\n",
    "        wam_reshape = np.concatenate([wam_reshape[0],wam_reshape[3],wam_reshape[1],wam_reshape[4],wam_reshape[2],wam_reshape[5]], axis=1).T\n",
    "\n",
    "        res = {\"w_ks_input\": wm.xin[0], \"w_k0_scale\": np.zeros(ks.size), \"w_transform\": wm_reshape, \"w_ks_output\": wm.xout[0]}\n",
    "        winmat = {1: res}   # Step size is one, but we could modify this to contain other stepsizes too.\n",
    "\n",
    "        return winmat, wam_reshape\n",
    "    \n",
    "# Power spectrum covariance matrix. Needs to have 6 multipoles, but if the some of them haven't been measured, we can set the covariance matrix elements to the identity matrix, as is done here.\n",
    "def format_pk_cov(nks, covfile, covformat=\"jmf\", zname=None):\n",
    "\n",
    "    if covformat == \"jmf\":\n",
    "        cov_input = pd.read_csv(covfile, comment=\"#\", delim_whitespace=True, header=None).to_numpy()        \n",
    "        nin = nks\n",
    "        cov = np.eye(5 * nks)\n",
    "        cov[:nks, :nks] = cov_input[:nks, :nks]\n",
    "        cov[:nks, 2 * nks : 3 * nks] = cov_input[:nks, nin : nin + nks]\n",
    "        cov[:nks, 4 * nks : 5 * nks] = cov_input[:nks, 2 * nin : 2 * nin + nks]\n",
    "        cov[2 * nks : 3 * nks, :nks] = cov_input[nin : nin + nks, :nks]\n",
    "        cov[2 * nks : 3 * nks, 2 * nks : 3 * nks] = cov_input[nin : nin + nks, nin : nin + nks]\n",
    "        cov[2 * nks : 3 * nks, 4 * nks : 5 * nks] = cov_input[nin : nin + nks, 2 * nin : 2 * nin + nks]\n",
    "        cov[4 * nks : 5 * nks, :nks] = cov_input[2 * nin : 2 * nin + nks, :nks]\n",
    "        cov[4 * nks : 5 * nks, 2 * nks : 3 * nks] = cov_input[2 * nin : 2 * nin + nks, nin : nin + nks]\n",
    "        cov[4 * nks : 5 * nks, 4 * nks : 5 * nks] = cov_input[2 * nin : 2 * nin + nks, 2 * nin : 2 * nin + nks]\n",
    "    else:\n",
    "        pks = getpk_dfs(covfile, zname)\n",
    "        cov = np.cov(np.array([np.concatenate([df[\"pk0\"], df[\"pk1\"], df[\"pk2\"], df[\"pk3\"], df[\"pk4\"]]) for df in pks]).T)\n",
    "        cov[nks:2*nks, nks:2*nks] = np.eye(nks)\n",
    "        cov[3*nks:4*nks, 3*nks:4*nks] = np.eye(nks)\n",
    "            \n",
    "    plt.imshow(cov/np.sqrt(np.outer(np.diag(cov), np.diag(cov))))\n",
    "    plt.show()\n",
    "            \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "        #print(f\"These should all be 1: {v}\")\n",
    "    \n",
    "    return cov\n",
    "\n",
    "# Pat's analytic covariance matrix\n",
    "def format_pk_analytic(nks, covfile):\n",
    "\n",
    "    cov_input = np.load(covfile)\n",
    "    nin = np.shape(cov_input)[2]\n",
    "    cov = np.eye(5 * nks)\n",
    "    cov[:nin, :nin] = cov_input[0,0]\n",
    "    cov[:nin, 2 * nks : 2 * nks + nin] = cov_input[0,1]\n",
    "    cov[:nin, 4 * nks : 4 * nks + nin] = cov_input[0,2]\n",
    "    cov[2 * nks : 2 * nks + nin, :nin] = cov_input[1,0]\n",
    "    cov[2 * nks : 2 * nks + nin, 2 * nks : 2 * nks + nin] = cov_input[1,1]\n",
    "    cov[2 * nks : 2 * nks + nin, 4 * nks : 4 * nks + nin] = cov_input[1,2]\n",
    "    cov[4 * nks : 4 * nks + nin, :nin] = cov_input[2,0]\n",
    "    cov[4 * nks : 4 * nks + nin, 2 * nks : 2 * nks + nin] = cov_input[2,1]\n",
    "    cov[4 * nks : 4 * nks + nin, 4 * nks : 4 * nks + nin] = cov_input[2,2]\n",
    "    \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "        #print(f\"These should all be 1: {v}\")\n",
    "    \n",
    "    return cov\n",
    "\n",
    "# Useful utility function to collate some Pk data\n",
    "def collect_pk_data(pre_files, post_files, pre_cov_files, post_cov_files, winfile, zeff, prezname, postzname, name, preformat=\"jmf\", postformat=\"jmf\", precovformat=\"jmf\", postcovformat=\"jmf\"):\n",
    "    \n",
    "    ks = None\n",
    "    pre_cov, post_cov = None, None\n",
    "    pre_data, post_data = None, None\n",
    "    pre_mocks, post_mocks = None, None\n",
    "    if pre_files is not None:\n",
    "        if preformat==\"jmf\": \n",
    "            pre_res = getpk(pre_files, prezname) \n",
    "        elif preformat==\"pm\":\n",
    "            pre_res = getpk_pm(pre_files, prezname) \n",
    "        elif preformat == \"bh\":\n",
    "            pre_res = getpk_bh(pre_files, prezname)\n",
    "        elif preformat == \"cgq\":\n",
    "            pre_res = getpk_cgq(pre_files, prezname)\n",
    "        elif preformat == \"x\":\n",
    "            pre_res = getpk_x(pre_files, prezname)\n",
    "        else:\n",
    "            pre_res = getpk_sn(pre_files, prezname)\n",
    "        ks = pre_res[0][\"k\"].to_numpy()\n",
    "        pre_cov = format_pk_cov(len(ks), pre_cov_file) if precovformat==\"jmf\" else format_pk_analytic(len(ks), pre_cov_file)\n",
    "        pre_mocks = [v for v in pre_res]\n",
    "    if post_files is not None:\n",
    "        if postformat==\"jmf\": \n",
    "            post_res = getpk(post_files, postzname, ks=ks)\n",
    "        elif postformat==\"pm\":\n",
    "            post_res = getpk_pm(post_files, postzname, ks=ks)\n",
    "        elif postformat == \"bh\":\n",
    "            post_res = getpk_bh(post_files, postzname, ks=ks)\n",
    "        elif postformat == \"cgq\":\n",
    "            post_res = getpk_cgq(post_files, postzname, ks=ks)\n",
    "        elif postformat == \"x\":\n",
    "            post_res = getpk_x(post_files, postzname, ks=ks)\n",
    "        else:\n",
    "            post_res = getpk_sn(post_files, postzname, ks=ks)\n",
    "        ks = post_res[0][\"k\"].to_numpy()\n",
    "        post_cov = format_pk_cov(len(ks), post_cov_file, postcovformat, zname=postzname) if postcovformat==\"jmf\" or postcovformat==\"dfs\" else format_pk_analytic(len(ks), pre_cov_file)\n",
    "        post_mocks = [v for v in post_res]\n",
    "        \n",
    "        print(ks)\n",
    "\n",
    "        if winfile is not None:\n",
    "            winmat, wideangle = getwin(ks, winfile)\n",
    "        else:\n",
    "            winmat, wideangle = getwin_dummy(ks)\n",
    "\n",
    "        split = {\n",
    "            \"n_data\": 1,\n",
    "            \"pre-recon data\": pre_data,\n",
    "            \"pre-recon cov\": pre_cov,\n",
    "            \"post-recon data\": post_data,\n",
    "            \"post-recon cov\": post_cov,\n",
    "            \"pre-recon mocks\": pre_mocks,\n",
    "            \"post-recon mocks\": post_mocks,\n",
    "            \"cosmology\": {\n",
    "                \"om\": cosmo[\"Omega_m\"],\n",
    "                \"h0\": cosmo[\"h\"],\n",
    "                \"z\": zeff,\n",
    "                \"ob\": cosmo[\"Omega_b\"],\n",
    "                \"ns\": cosmo[\"n_s\"],\n",
    "                \"mnu\": np.sum(cosmo[\"m_ncdm\"]),\n",
    "                \"reconsmoothscale\": 10,\n",
    "            },\n",
    "            \"name\": name,\n",
    "            \"winfit\": winmat,\n",
    "            \"winpk\": None,  # We can set this to None; Barry will set it to zeroes given the length of the data vector.\n",
    "            \"m_mat\": wideangle,\n",
    "        }\n",
    "\n",
    "        with open(f\"../\" + name.lower().replace(\" \", \"_\")+\".pkl\", \"wb\") as f:\n",
    "            pickle.dump(split, f)\n",
    "            print(f)\n",
    "        return split\n",
    "    \n",
    "    \n",
    "# Plot the power spectra, for sanity checking\n",
    "def plot_pk(split, pre=True, post=True):\n",
    "    \n",
    "    if pre:\n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ks = split[\"pre-recon mocks\"][0][\"k\"]\n",
    "        nmocks = len(split[\"pre-recon mocks\"])\n",
    "        label = [r\"$P_{0}(k)$\", r\"$P_{2}(k)$\", r\"$P_{4}(k)$\"]\n",
    "        for m, pk in enumerate([\"pk0\", \"pk2\", \"pk4\"]):\n",
    "            yerr = ks * np.sqrt(np.diag(split[\"pre-recon cov\"]))[2 * m * len(ks) : (2 * m + 1) * len(ks)]\n",
    "            plt.errorbar(\n",
    "                ks,\n",
    "                ks * np.mean([split[\"pre-recon mocks\"][i][pk] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ks, ks * split[\"pre-recon mocks\"][i][pk], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$k$\")\n",
    "        plt.ylabel(r\"$k\\,P(k)$\")\n",
    "        plt.title(split[\"name\"] + \" Prerecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()   \n",
    "    if post:\n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ks = split[\"post-recon mocks\"][0][\"k\"]\n",
    "        nmocks = len(split[\"post-recon mocks\"])\n",
    "        label = [r\"$P_{0}(k)$\", r\"$P_{2}(k)$\", r\"$P_{4}(k)$\"]\n",
    "        for m, pk in enumerate([\"pk0\", \"pk2\", \"pk4\"]):\n",
    "            yerr = ks * np.sqrt(np.diag(split[\"post-recon cov\"]))[2 * m * len(ks) : (2 * m + 1) * len(ks)]\n",
    "            plt.errorbar(\n",
    "                ks,\n",
    "                ks * np.mean([split[\"post-recon mocks\"][i][pk] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ks, ks * split[\"post-recon mocks\"][i][pk], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$k$\")\n",
    "        plt.ylabel(r\"$k\\,P(k)$\")\n",
    "        plt.title(split[\"name\"] + \" Postrecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7e3ed-99b5-4282-91e0-6ccad1252732",
   "metadata": {},
   "source": [
    "# Correlation function routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb61de-ca0c-4945-80dd-ee9c1b52f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation function. Juan Mena Fern√°ndez style where everything is put into single files per multipole\n",
    "def getxi(loc, zname):\n",
    "    sin = pd.read_csv(loc+\"/s.txt\", comment=\"#\", skiprows=0, delim_whitespace=True, header=None).to_numpy().T[0]\n",
    "    ximat = [pd.read_csv(loc+f\"/Xi_{ell}\"+zname+\".txt\", comment=\"#\", skiprows=0, delim_whitespace=True, header=None).to_numpy().T for ell in [0,2,4]]\n",
    "        \n",
    "    res = []\n",
    "    nmocks = np.shape(ximat[0])[0]\n",
    "    for i in range(nmocks):\n",
    "        df = {}\n",
    "        df[\"s\"] = sin\n",
    "        for l, ell in enumerate([0, 2, 4]):\n",
    "            df[f\"xi{ell}\"] = ximat[l][i]\n",
    "        res.append(pd.DataFrame(df))\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Correlation function. Christoph Saulder style, where we read in the .npy files and rebin with 4Mpc/h binning\n",
    "def getxi_cs(loc, zname):\n",
    "    \n",
    "    rebinfactor = 4\n",
    "    \n",
    "    files = [loc + f for f in os.listdir(loc) if zname in f and \".npy\" in f and \"poles\" not in f]\n",
    "    files.sort(key=sortfunc_cs)\n",
    "        \n",
    "    res = []\n",
    "    for f in files:\n",
    "        data = TwoPointCorrelationFunction.load(f)\n",
    "        data.rebin((rebinfactor, 1))\n",
    "        df = pd.DataFrame(np.vstack(project_to_multipoles(data)).T, columns=[\"s\", \"xi0\", \"xi2\", \"xi4\"])\n",
    "        res.append(df)\n",
    "    return res\n",
    "\n",
    "# Correlation function. Pat Macdonald ICs style, where we have already written a new file combining the dd, de and ee terms given a value for bias and f\n",
    "def getxi_pm(loc, zname):\n",
    "        \n",
    "    sin = np.load(loc + 'rs_for_xi_576_4.0_0.npy')\n",
    "    ximat = np.load('./ic_LRG_xi_25.npy').T\n",
    "    print(np.shape(ximat))\n",
    "    \n",
    "    res = []\n",
    "    nmocks = np.shape(ximat[0])[0]\n",
    "    print(nmocks)\n",
    "    for i in range(nmocks):\n",
    "        df = {}\n",
    "        df[\"s\"] = sin\n",
    "        index = np.where(df[\"s\"] < 202)\n",
    "        df[\"s\"] = df[\"s\"][index]\n",
    "        for l, ell in enumerate([0, 2, 4]):\n",
    "            df[f\"xi{ell}\"] = ximat[i][l][index]\n",
    "        print(pd.DataFrame(df))\n",
    "        res.append(pd.DataFrame(df))\n",
    "        \n",
    "    return res\n",
    "\n",
    "# Correlation function. Daniel Forero-Sanchez style, where we read in the .npy files and rebin with 4Mpc/h binning\n",
    "def getxi_dfs(loc, zname):\n",
    "    \n",
    "    rebinfactor = 4\n",
    "    \n",
    "    files = [loc + f + \"/sym_fft_tpcf.pkl.npy\" for f in os.listdir(loc)]\n",
    "    files.sort(key=sortfunc_dfs)\n",
    "        \n",
    "    res = []\n",
    "    for f in files:\n",
    "        data = CatalogFFTCorr.load(f).poles\n",
    "        data.rebin(rebinfactor)\n",
    "        df = pd.DataFrame(np.vstack(data(ell=[0,2,4], return_s=True)).T.real, columns=[\"s\", \"xi0\", \"xi2\", \"xi4\"])\n",
    "        res.append(df)\n",
    "    return res\n",
    "\n",
    "# Correlation function covariance matrix.\n",
    "def format_xi_cov(nss, covfile, covformat=\"jmf\", zname=None):\n",
    "\n",
    "    if covformat == \"jmf\":\n",
    "        cov_input = pd.read_csv(covfile, comment=\"#\", delim_whitespace=True, header=None).to_numpy()\n",
    "        nin = nss\n",
    "        cov = np.zeros((3 * nss, 3 * nss))\n",
    "        cov[:nss, :nss] = cov_input[:nss, :nss]\n",
    "        cov[:nss, nss : 2 * nss] = cov_input[:nss, nin : nin + nss]\n",
    "        cov[:nss, 2 * nss :] = cov_input[:nss, 2 * nin : 2 * nin + nss]\n",
    "        cov[nss : 2 * nss, :nss] = cov_input[nin : nin + nss, :nss]\n",
    "        cov[nss : 2 * nss, nss : 2 * nss] = cov_input[nin : nin + nss, nin : nin + nss]\n",
    "        cov[nss : 2 * nss, 2 * nss :] = cov_input[nin : nin + nss, 2 * nin : 2 * nin + nss]\n",
    "        cov[2 * nss :, :nss] = cov_input[2 * nin : 2 * nin + nss, :nss]\n",
    "        cov[2 * nss :, nss : 2 * nss] = cov_input[2 * nin : 2 * nin + nss, nin : nin + nss]\n",
    "        cov[2 * nss :, 2 * nss :] = cov_input[2 * nin : 2 * nin + nss, 2 * nin : 2 * nin + nss]\n",
    "    else:\n",
    "        xis = getxi_dfs(covfile, zname)\n",
    "        cov = np.cov(np.array([np.concatenate([df[\"xi0\"], df[\"xi2\"], df[\"xi4\"]]) for df in xis]).T)\n",
    "    \n",
    "    plt.imshow(cov/np.sqrt(np.outer(np.diag(cov), np.diag(cov))))\n",
    "    plt.show()\n",
    "    \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "        #print(f\"These should all be 1: {v}\")\n",
    "\n",
    "    return cov\n",
    "\n",
    "# Useful utility function to collate some Xi data\n",
    "def collect_xi_data(pre_files, post_files, pre_cov_file, post_cov_file, zeff, prezname, postzname, name, preformat=\"jmf\", postformat=\"jmf\", precovformat=\"jmf\", postcovformat=\"jmf\"):\n",
    "\n",
    "    pre_cov, post_cov = None, None\n",
    "    pre_data, post_data = None, None\n",
    "    pre_mocks, post_mocks = None, None\n",
    "    if pre_files is not None:\n",
    "        if preformat==\"jmf\":\n",
    "            pre_res = getxi(pre_files, prezname) \n",
    "        elif preformat==\"pm\":\n",
    "            pre_res = getxi_pm(pre_files, prezname) \n",
    "        else:\n",
    "            pre_res = getxi_cs(pre_files, prezname)\n",
    "        ss = pre_res[0][\"s\"].to_numpy()\n",
    "        pre_cov = format_xi_cov(len(ss), pre_cov_file)\n",
    "        pre_mocks = [v for v in pre_res]\n",
    "    if post_files is not None:\n",
    "        post_res = getxi(post_files, postzname) if postformat==\"jmf\" else getxi_cs(post_files, postzname)\n",
    "        ss = post_res[0][\"s\"].to_numpy()\n",
    "        post_cov = format_xi_cov(len(ss), post_cov_file, covformat=postcovformat)\n",
    "        post_mocks = [v for v in post_res]   \n",
    "    \n",
    "    split = {\n",
    "        \"n_data\": 1,\n",
    "        \"pre-recon data\": pre_data,\n",
    "        \"pre-recon cov\": pre_cov,\n",
    "        \"post-recon data\": post_data,\n",
    "        \"post-recon cov\": post_cov,\n",
    "        \"pre-recon mocks\": pre_mocks,\n",
    "        \"post-recon mocks\": post_mocks,\n",
    "        \"cosmology\": {\n",
    "            \"om\": cosmo[\"Omega_m\"],\n",
    "            \"h0\": cosmo[\"h\"],\n",
    "            \"z\": zeff,\n",
    "            \"ob\": cosmo[\"Omega_b\"],\n",
    "            \"ns\": cosmo[\"n_s\"],\n",
    "            \"mnu\": np.sum(cosmo[\"m_ncdm\"]),\n",
    "            \"reconsmoothscale\": 15,\n",
    "        },\n",
    "        \"name\": name,\n",
    "        }\n",
    "    \n",
    "    with open(f\"../\" + name.lower().replace(\" \", \"_\")+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(split, f)\n",
    "        \n",
    "    return split\n",
    "    \n",
    "# Plot the power spectra, for sanity checking\n",
    "def plot_xi(split, pre=True, post=True):\n",
    "    \n",
    "    if pre:\n",
    "    \n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ss = split[\"pre-recon mocks\"][0][\"s\"]\n",
    "        nmocks = len(split[\"pre-recon mocks\"])\n",
    "        label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"pre-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * np.mean([split[\"pre-recon mocks\"][i][xi] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ss, ss ** 2 * split[\"pre-recon mocks\"][i][xi], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Prerecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "        \n",
    "    if post:\n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ss = split[\"post-recon mocks\"][0][\"s\"]\n",
    "        nmocks = len(split[\"post-recon mocks\"])\n",
    "        label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"pre-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * np.mean([split[\"post-recon mocks\"][i][xi] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ss, ss ** 2 * split[\"post-recon mocks\"][i][xi], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Postrecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ee333-a428-42ac-a257-55cee20df49d",
   "metadata": {},
   "source": [
    "# Produce Pickles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54aa38-1742-4b54-a6c0-39bc02ac7204",
   "metadata": {},
   "source": [
    "Default HOD (Pk and Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0573716-655b-4a45-a6bd-438b65ce9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over tracers\n",
    "path_abacus = \"/global/cfs/cdirs/desi/cosmosim/KP45/MC/Clustering/AbacusSummit/CubicBox/\"\n",
    "path_ezmock = \"/global/cfs/cdirs/desi/cosmosim/KP45/MC/Clustering/EZmock/CubicBox/\"\n",
    "\n",
    "# Dictionary containing z for the tracers\n",
    "reds = {\"LRG\": [0.8]}\n",
    "\n",
    "tracer = \"LRG\"\n",
    "for i, z in enumerate(reds[tracer]):\n",
    "    \n",
    "    # Power Spectrum\n",
    "    pre_file = path_abacus + tracer + \"/Pk/Pre/jmena/nmesh_512/dk0.005/\"\n",
    "    pre_cov_file = path_ezmock + tracer + \"/Pk/jmena/nmesh_512/dk0.005/cov.txt\"  # Uses the EZmock covariance\n",
    "    post_file = path_abacus + tracer + \"/Pk/Post/nadathur/fiducial_settings/dk0.005/\"\n",
    "    post_cov_file = path_ezmock + tracer + \"/Pk/Post/forero/fiducial_settings/dk0.005/z0.800/\"  # Uses the Postrecon EZmock covariance\n",
    "    name = f\"DESI KP4 Abacus CubicBox Pk \" + tracer\n",
    "    data = collect_pk_data(pre_file, post_file, pre_cov_file, post_cov_file, None, z, \"\", \"\", name, postformat=\"sn\", postcovformat=\"dfs\")\n",
    "    plot_pk(data) # Plot the data to check things\n",
    "\n",
    "    # Correlation Function\n",
    "    pre_file = path_abacus + tracer + f\"/Xi/Pre/jmena/\"\n",
    "    pre_cov_file = path_ezmock + tracer + f\"/Xi/jmena/cov.txt\"  # Uses the EZmock covariance\n",
    "    post_file = path_abacus + tracer + \"/Xi/Post/jmena/\"\n",
    "    post_cov_file = path_ezmock + tracer + \"/Xi/Post/forero/fiducial_settings/z0.800/\"  # Uses the Postrecon EZmock covariance\n",
    "    name = f\"DESI KP4 Abacus CubicBox Xi \" + tracer\n",
    "    data = collect_xi_data(pre_file, post_file, pre_cov_file, post_cov_file, z, \"\", \"\", name, postcovformat=\"dfs\")\n",
    "    plot_xi(data) # Plot the data to check things\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f57c8-e74f-4c7a-924f-0364ec5d778c",
   "metadata": {},
   "source": [
    "# CV mocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896b650f-944b-4927-806f-69701fd5c652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Boryana's control variate simulations\n",
    "path_abacus = \"/global/cfs/cdirs/desi/cosmosim/KP45/MC/Clustering/AbacusSummit/CubicBox/\"\n",
    "path_ezmock = \"/global/cfs/cdirs/desi/cosmosim/KP45/MC/Clustering/EZmock/CubicBox/\"\n",
    "\n",
    "# Dictionary containing z for the tracers\n",
    "reds = {\"LRG\": [0.8]}\n",
    "\n",
    "for tracer in [\"LRG\"]:\n",
    "    for i, z in enumerate(reds[tracer]):\n",
    "    \n",
    "        # Power Spectrum\n",
    "        pre_file = path_abacus + tracer + \"/Pk_CV/Pre/boryanah/\"\n",
    "        pre_cov_file = path_ezmock + tracer + \"/Pk/jmena/nmesh_512/dk0.005/cov.txt\"  # Uses the normal (not CV) EZmock covariance\n",
    "        post_file = path_abacus + tracer + \"/Pk_CV/Post/boryanah/\"\n",
    "        post_cov_file = path_ezmock + tracer + \"/Pk/Post/forero/fiducial_settings/dk0.005/z0.800/\"  # Uses the Postrecon EZmock covariance\n",
    "        name = f\"DESI KP4 Abacus CubicBox CV Pk \" + tracer\n",
    "        data = collect_pk_data(pre_file, post_file, pre_cov_file, post_cov_file, None, z, \"\", \"\", name, preformat=\"bh\", postformat=\"bh\", postcovformat=\"dfs\")\n",
    "        plot_pk(data) # Plot the data to check things\n",
    "\n",
    "        # Correlation Function\n",
    "        # pre_file = path_abacus + tracer + f\"/Xi_CV/Pre/jmena/\"\n",
    "        # pre_cov_file = path_ezmock + tracer + f\"/Xi/jmena/cov.txt\"  # Uses the EZmock covariance\n",
    "        # post_file = path_abacus + tracer + \"/Xi_CV/Post/jmena/\"\n",
    "        # post_cov_file = path_ezmock + tracer + \"/Xi/Post/forero/fiducial_settings/z0.800/\"  # Uses the Postrecon EZmock covariance\n",
    "        # name = f\"DESI KP4 Abacus CubicBox CV Xi \" + tracer\n",
    "        # data = collect_xi_data(pre_file, post_file, pre_cov_file, post_cov_file, z, \"\", \"\", name, postcovformat=\"dfs\")\n",
    "        # plot_xi(data) # Plot the data to check things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97075a6-ce44-4224-ab9e-4af1735514ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barry_env_desiproject_aw",
   "language": "python",
   "name": "barry_env_desiproject_aw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
