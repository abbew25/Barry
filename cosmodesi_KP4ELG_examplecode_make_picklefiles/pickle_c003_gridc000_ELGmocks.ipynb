{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81706a4-7f79-4166-84c5-3de329e95a23",
   "metadata": {},
   "source": [
    "## pickling the ELG c003 cosmology clustering measurements for doing constraints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d55b1-d4ae-4418-bd37-05b0f4a92cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages and set up the fiducial cosmology\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from cosmoprimo.fiducial import DESI, AbacusSummit # package interface for CLASS and CAMB \n",
    "from scipy.interpolate import splrep, splev\n",
    "from cosmoprimo import PowerSpectrumBAOFilter\n",
    "from pypower import BaseMatrix, PowerSpectrumMultipoles, PowerSpectrumSmoothWindow, PowerSpectrumSmoothWindowMatrix, PowerSpectrumOddWideAngleMatrix, setup_logging\n",
    "from pycorr import TwoPointCorrelationFunction, project_to_multipoles\n",
    "cosmo = DESI() # initialize CLASS/CAMB like object for doing calculations of power spectrum etc. \n",
    "\n",
    "print(dir(cosmo))\n",
    "\n",
    "\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "plt.style.use('default')\n",
    "from statsmodels.stats.moment_helpers import cov2corr\n",
    "\n",
    "# commenting out code that produces template - we already have this because we will analyse assuming the 000 model? \n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(cosmo.A_s, cosmo.H0, cosmo.Omega0_b, cosmo.n_s, cosmo.N_eff, cosmo.Omega0_m, cosmo.tau_reio, cosmo.sigma8_m)\n",
    "print(dir(cosmo))\n",
    "# Save the default DESI template to a file - added in code here to make sure the template is prepared properly \n",
    "k_min = 1e-4\n",
    "k_max = 5\n",
    "k_num = 2000\n",
    "kl = np.logspace(np.log(k_min), np.log(k_max), k_num, base=np.e)\n",
    "pkz = cosmo.get_fourier().pk_interpolator() # object to get power spectrum from interpolator \n",
    "pk = pkz.to_1d(z=0) # get power spectrum at z = 0 \n",
    "pkv = pk(kl) \n",
    "# plt.loglog(kl, pkv, label='power spectrum') # full broadband power spectrum + wiggles\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "pknow = PowerSpectrumBAOFilter(pk, engine='wallish2018').smooth_pk_interpolator()\n",
    "pksmv = pknow(kl) # interpolate smoothed power spectrum at desired k values \n",
    "# plt.loglog(kl, pksmv, label='smoothed power spectrum') # smoothed broadband power spectrum without the wiggles (smoothed out) \n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "np.savetxt(\"DESI_Pk_template.dat\", np.c_[kl, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g\", header=\"k     pk_smooth     pk_ratio\") # saving \n",
    "# the smoothed power spectrum and the ratio of the smooth to original to get the wiggles only - gets used later \n",
    "\n",
    "# preparing template for cosmology 003 \n",
    "# cosmo.N_eff = 3.7#044\n",
    "# cosmo.A_s = 2.2438e-9\n",
    "# cosmo.H0 = 71.60\n",
    "# cosmo.Omega0_b = 0.0226 / (0.716**2)\n",
    "# cosmo.n_s = 0.9876\n",
    "# cosmo.Omega0_m = (0.0226 + 0.1291) / (0.716**2)\n",
    "# print(cosmo.A_s, cosmo.H0, cosmo.Omega0_b, cosmo.n_s, cosmo.N_eff, cosmo.Omega0_m, cosmo.tau_reio)\n",
    "cosmo = AbacusSummit(name='003')\n",
    "\n",
    "pkz3 = cosmo.get_fourier().pk_interpolator() # object to get power spectrum from interpolator \n",
    "pk3 = pkz3.to_1d(z=0) # get power spectrum at z = 0 \n",
    "pkv3 = pk3(kl) \n",
    "pknow3 = PowerSpectrumBAOFilter(pk3, engine='wallish2018').smooth_pk_interpolator()\n",
    "pksmv3 = pknow3(kl)\n",
    "np.savetxt(\"DESI_Pk_template_c003.dat\", np.c_[kl, pksmv3, pkv3/pksmv3 - 1.0],  fmt=\"%g %g %g\", header=\"k     pk_smooth     pk_ratio\") # saving \n",
    "\n",
    "\n",
    "\n",
    "plt.loglog(kl, pkv, label='power spectrum 000') # full broadband power spectrum + wiggles\n",
    "plt.loglog(kl, pkv3, label='power spectrum 003') # full broadband power spectrum + wiggles\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.loglog(kl, pksmv, label='smoothed power spectrum 000') # smoothed broadband power spectrum without the wiggles (smoothed out)\n",
    "plt.loglog(kl, pksmv3, label='smoothed power spectrum 003') # smoothed broadband power spectrum without the wiggles (smoothed out) \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.semilogx(kl, pkv/pksmv - 1.0, label='power spectrum wiggles only 000')\n",
    "plt.semilogx(kl, pkv3/pksmv3 - 1.0, label='power spectrum wiggles only 003')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def plot_cov(matrix):\n",
    "    norm = matplotlib.colors.Normalize(vmin=-1, vmax=1)\n",
    "    ''' Plot the correlation matrix derived from the covariance matrix '''\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.imshow(cov2corr(matrix), cmap=plt.get_cmap('bwr'))\n",
    "    plt.colorbar()\n",
    "    plt.clim(-1,1)\n",
    "    plt.show()\n",
    "    return \n",
    "# -------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d832f-cdf1-4c40-88ea-320937a09d17",
   "metadata": {},
   "source": [
    "## modified power spectrum routines - using others code with some modifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159c38c-44f9-4a54-988a-d5e1001b2468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Power Spectrum. By Cristhian Garcia-Quintero, here we use an already rebinned Pk multipoles .txt file with the k-values and multipoles in a single file. Barry needs 5 even+odd multipoles, but the odd ones can be filled with zeros if these haven't been measured, as is done here.\n",
    "# modifications I have made to old code have been largely just commented out \n",
    "def getpk_cgq(loc, zname, CV, post=False):\n",
    "    seed = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"]#, \"06\", \"07\", \"08\", \"09\", # only have 6 mocks atm \n",
    "           # \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\",\n",
    "           #  \"20\", \"21\", \"22\", \"23\", \"24\"]\n",
    "    res = []\n",
    "    nmocks = len(seed)\n",
    "    for i in range(nmocks): # looping through mocks and opening up - also think we dn't have CV? \n",
    "        # Read data for a single mock\n",
    "        # if (CV == True and post==True):\n",
    "        #     mydata = open(loc + '/' + zname + seed[i] + '.gcat_MultiGrid_mesh1024_smooth15_recsym_b1.2_randoms_20X.Pk_nmesh1152.ecsv', 'r')\n",
    "        # elif (CV == True and post==False):\n",
    "        #     mydata = open(loc + '/' + zname + seed[i] + '.gcat.Pk_nmesh1152.ecsv', 'r')\n",
    "        # else:\n",
    "        #mydata = open(loc + '/' + zname + seed[i] + '.npy', 'r') \n",
    "        \n",
    "        \n",
    "        # unfortunately I can only seem to open the files in a strange kind of way, \n",
    "        #dat = np.load(loc+zname+seed[i]+'.npy', allow_pickle=True)\n",
    "        #d = dat[()] # weird way to read in the files .... but this odd syntax seems to work \n",
    "        \n",
    "        poles = PowerSpectrumMultipoles.load(loc+zname+seed[i]+'.npy')\n",
    "        poles.slice(slice(0, 800))\n",
    "        poles.rebin(5)\n",
    "        k, pkell = poles(ell=(0,2,4), return_k=True, complex=False)\n",
    "        pk0, pk2, pk4 = pkell\n",
    "        \n",
    "        bools = np.logical_not(np.isnan(k))\n",
    "        k = k[bools]\n",
    "\n",
    "        pk0 = pk0[bools]\n",
    "        pk2 = pk2[bools]\n",
    "        pk4 = pk4[bools]\n",
    "\n",
    "        #lines=mydata.readlines()\n",
    "        #k  = []\n",
    "        #P0 = []\n",
    "        \n",
    "        # k = np.array((d['modes'][0]))\n",
    "        # P0 = np.array((d['power_nonorm'][0]))\n",
    "        # P0 = abs(P0[k != np.nan])\n",
    "        # k = k[k != np.nan]\n",
    "        \n",
    "        \n",
    "        #P2 = [] # think we only have monopole atm \n",
    "        #P4 = []\n",
    "        # for line in lines: # looping through lines in file to save k, monopole, quadrupole and hexadecapole \n",
    "        #     if line.startswith('#'):\n",
    "        #         if line[4:17]=='galaxy_number':\n",
    "        #             num_gal = float(line.split()[2])\n",
    "        #             num_ran = num_gal * 20\n",
    "        #             boxsize = 2000\n",
    "        #             nbar_gal = num_gal/boxsize**3\n",
    "        #             nbar_ran = num_ran/boxsize**3\n",
    "        #             shot_noise_gal = 1/nbar_gal\n",
    "        #             shot_noise_ran = 1/nbar_ran\n",
    "        #             shot_noise = shot_noise_gal + shot_noise_ran\n",
    "        #             print(\"num_gal:\", num_gal, \"nbar_gal:\", nbar_gal, \"Shot-Noise:\", shot_noise)\n",
    "        #     else:\n",
    "        #         if (CV == True):\n",
    "        #             k.append(line.split()[0]) \n",
    "        #             P0.append(line.split()[1]) \n",
    "        #             P2.append(line.split()[2]) \n",
    "        #             P4.append(line.split()[3]) \n",
    "        #         elif (post == True):\n",
    "        #             k.append(line.split()[1]) \n",
    "        #             P0.append(line.split()[3]) \n",
    "        #             P2.append(line.split()[5]) \n",
    "        #             P4.append(line.split()[7]) \n",
    "        #         else:\n",
    "        #             k.append(line.split()[1]) \n",
    "        #             P0.append(line.split()[3]) \n",
    "        #             P2.append(line.split()[4]) \n",
    "        #             P4.append(line.split()[5]) \n",
    "        # mydata.close()\n",
    "        # if (CV == True):\n",
    "        #     k=k[1:]\n",
    "        #     P0=P0[1:]\n",
    "        #     P2=P2[1:]\n",
    "        #     P4=P4[1:]\n",
    "        # k  = np.array([float(i) for i in k])    \n",
    "        # P0 = np.array([float(i) for i in P0])    \n",
    "        # P2 = np.array([float(i) for i in P2])    \n",
    "        # P4 = np.array([float(i) for i in P4])   \n",
    "        # Append 5 multipoles to result\n",
    "        df = {}\n",
    "        df[\"k\"] = k\n",
    "        # if (CV == True):\n",
    "        #     df[f\"pk0\"] = P0 - shot_noise\n",
    "        # else:\n",
    "        df[f\"pk0\"] = pk0\n",
    "        df[f\"pk2\"] = pk2\n",
    "        df[f\"pk4\"] = pk4\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"])) # in dataframe save odd multipoles as zeros \n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        res.append(pd.DataFrame(df)[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "         \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "# rest of this code is unmodified from original code -----\n",
    "\n",
    "# Window function matrix. The window functions are stored in a dictionary of 'step sizes' i.e., how many bins get stuck together relative to the \n",
    "# pk measurements so that we can rebin the P(k) at run time if required. Each step size is a dictionary with:\n",
    "#    the input and output k binning (w_ks_input, w_ks_output), the window function matrix (w_transform) and integral constraint (w_k0_scale).\n",
    "# The window function assumes 6 input and 5 output multipoles. For cubic sims, we can set the integral constraint to zero and window matrix to the identity matrix, as is done here.\n",
    "def getwin_dummy(ks):\n",
    "    res = {\"w_ks_input\": ks.copy(), \"w_k0_scale\": np.zeros(ks.size), \"w_transform\": np.eye(5 * ks.size, 6 * ks.size), \"w_ks_output\": ks.copy()}\n",
    "    return {1: res}  # Step size is one\n",
    "\n",
    "# The conversion matrix M from Beutler 2019. Used to compute the odd multipole models given the even multipoles. In the absence of wide angle effects, or if we don't care about\n",
    "# the odd multipoles, we can set this to a block matrix with identity matrices in the appropriate places, as is done here.\n",
    "def getcomp_dummy(ks):\n",
    "    matrix = np.zeros((6 * ks.size, 3 * ks.size))\n",
    "    matrix[: ks.size, : ks.size] = np.diag(np.ones(ks.size))\n",
    "    matrix[2 * ks.size : 3 * ks.size, ks.size : 2 * ks.size] = np.diag(np.ones(ks.size))\n",
    "    matrix[4 * ks.size : 5 * ks.size, 2 * ks.size :] = np.diag(np.ones(ks.size))\n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "# Power spectrum covariance matrix. Needs to have 6 multipoles, but if the some of them haven't been measured, we can set the covariance matrix elements to the identity matrix, as is done here.\n",
    "def format_pk_cov(nks, covfile):#, kvals=None):\n",
    "\n",
    "    cov_input = pd.read_csv(covfile, comment=\"#\", delim_whitespace=True, header=None).to_numpy()\n",
    "    nin = nks\n",
    "    cov = np.eye(5 * nks)\n",
    "    cov[:nks, :nks] = cov_input[:nks, :nks]\n",
    "    cov[:nks, 2 * nks : 3 * nks] = cov_input[:nks, nin : nin + nks]\n",
    "    cov[:nks, 4 * nks : 5 * nks] = cov_input[:nks, 2 * nin : 2 * nin + nks]\n",
    "    cov[2 * nks : 3 * nks, :nks] = cov_input[nin : nin + nks, :nks]\n",
    "    cov[2 * nks : 3 * nks, 2 * nks : 3 * nks] = cov_input[nin : nin + nks, nin : nin + nks]\n",
    "    cov[2 * nks : 3 * nks, 4 * nks : 5 * nks] = cov_input[nin : nin + nks, 2 * nin : 2 * nin + nks]\n",
    "    cov[4 * nks : 5 * nks, :nks] = cov_input[2 * nin : 2 * nin + nks, :nks]\n",
    "    cov[4 * nks : 5 * nks, 2 * nks : 3 * nks] = cov_input[2 * nin : 2 * nin + nks, nin : nin + nks]\n",
    "    cov[4 * nks : 5 * nks, 4 * nks : 5 * nks] = cov_input[2 * nin : 2 * nin + nks, 2 * nin : 2 * nin + nks]\n",
    "    \n",
    "    plt.imshow(cov/np.sqrt(np.outer(np.diag(cov), np.diag(cov))))\n",
    "    plt.imshow(cov[:nks,:nks]/np.sqrt(np.outer(np.diag(cov[:nks,:nks]), np.diag(cov[:nks,:nks]))))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        #print(np.sum(v))\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "        #print(f\"These should all be 1: {v}\")\n",
    "    \n",
    "    return cov\n",
    "\n",
    "\n",
    "# this function is unmodified for now \n",
    "# Useful utility function to collate some Pk data - simple read in data for multipoles for pre and post reconstruction \n",
    "# also read in file for the window function of the data \n",
    "def collect_pk_data(pre_files, post_files, pre_cov_files, post_cov_files, winfile, zeff, prezname, postzname, name, CV=False):\n",
    "    \n",
    "    ks = None\n",
    "    pre_cov, post_cov = None, None\n",
    "    pre_data, post_data = None, None\n",
    "    pre_mocks, post_mocks = None, None\n",
    "    if pre_files is not None:\n",
    "        pre_res = getpk_cgq(pre_files, prezname, CV, post=False) \n",
    "        ks = pre_res[0][\"k\"].to_numpy()\n",
    "        pre_cov = format_pk_cov(len(ks), pre_cov_file)#, kvals=ks)\n",
    "        pre_mocks = [v for v in pre_res]\n",
    "    if post_files is not None:\n",
    "        post_res = getpk_cgq(post_files, postzname, CV, post=True)\n",
    "        ks = post_res[0][\"k\"].to_numpy() \n",
    "        post_cov = format_pk_cov(len(ks), post_cov_file)#, kvals=ks)\n",
    "        post_mocks = [v for v in post_res]\n",
    "\n",
    "    #if winfile is not None:\n",
    "    #    winmat, wideangle = getwin(ks, winfile)\n",
    "    #    wideangle = getcomp_dummy(ks)\n",
    "    #else:\n",
    "    winmat, wideangle = getwin_dummy(ks), getcomp_dummy(ks)\n",
    "    \n",
    "    split = {\n",
    "        \"n_data\": 1,\n",
    "        \"pre-recon data\": pre_data,\n",
    "        \"pre-recon cov\": pre_cov,\n",
    "        \"post-recon data\": post_data,\n",
    "        \"post-recon cov\": post_cov,\n",
    "        \"pre-recon mocks\": pre_mocks,\n",
    "        \"post-recon mocks\": post_mocks,\n",
    "        \"cosmology\": {\n",
    "            \"om\": cosmo[\"Omega_m\"],\n",
    "            \"h0\": cosmo[\"h\"],\n",
    "            \"z\": zeff,\n",
    "            \"ob\": cosmo[\"Omega_b\"],\n",
    "            \"ns\": cosmo[\"n_s\"],\n",
    "            \"mnu\": np.sum(cosmo[\"m_ncdm\"]),\n",
    "            \"reconsmoothscale\": 15,\n",
    "        },\n",
    "        \"name\": name,\n",
    "        \"winfit\": winmat,\n",
    "        \"winpk\": None,  # We can set this to None; Barry will set it to zeroes given the length of the data vector.\n",
    "        \"m_mat\": wideangle,\n",
    "    }\n",
    "    \n",
    "    with open(f\"./\" + name.lower().replace(\" \", \"_\")+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(split, f)\n",
    "        \n",
    "    return split # writing read in file sand other results that are relevant to pickle file and returning \n",
    "\n",
    "\n",
    "\n",
    "# Plot the power spectra, for sanity checking\n",
    "def plot_pk(split, pre=True, post=True):\n",
    "    \n",
    "    if pre:\n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ks = split[\"pre-recon mocks\"][0][\"k\"]\n",
    "        nmocks = len(split[\"pre-recon mocks\"])\n",
    "        label = [r\"$P_{0}(k)$\", r\"$P_{2}(k)$\", r\"$P_{4}(k)$\"]\n",
    "        for m, pk in enumerate([\"pk0\", \"pk2\", \"pk4\"]): # looping and plotting each multipole mean value \n",
    "            yerr = ks * np.sqrt(np.diag(split[\"pre-recon cov\"]))[2 * m * len(ks) : (2 * m + 1) * len(ks)]\n",
    "            plt.errorbar(\n",
    "                ks,\n",
    "                ks * np.mean([split[\"pre-recon mocks\"][i][pk] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks): # each mock plotted multipole x ks array \n",
    "                plt.errorbar(ks, ks * split[\"pre-recon mocks\"][i][pk], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$k$\")\n",
    "        plt.ylabel(r\"$k\\,P(k)$\")\n",
    "        plt.title(split[\"name\"] + \" Prerecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "    \n",
    "    if post:\n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ks = split[\"post-recon mocks\"][0][\"k\"]\n",
    "        nmocks = len(split[\"post-recon mocks\"])\n",
    "        label = [r\"$P_{0}(k)$\", r\"$P_{2}(k)$\", r\"$P_{4}(k)$\"]\n",
    "        for m, pk in enumerate([\"pk0\", \"pk2\", \"pk4\"]):\n",
    "            yerr = ks * np.sqrt(np.diag(split[\"post-recon cov\"]))[2 * m * len(ks) : (2 * m + 1) * len(ks)]\n",
    "            plt.errorbar(\n",
    "                ks,\n",
    "                ks * np.mean([split[\"post-recon mocks\"][i][pk] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ks, ks * split[\"post-recon mocks\"][i][pk], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$k$\")\n",
    "        plt.ylabel(r\"$k\\,P(k)$\")\n",
    "        plt.title(split[\"name\"] + \" Postrecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf6cc34-9172-4f46-a6f5-40cc8e8fee32",
   "metadata": {},
   "source": [
    "## produce pickles - prerecon, Pk only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac7dcdf-b0d2-43f6-8700-fc18c7e28736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over tracers\n",
    "\n",
    "#path_ezmock = \"/global/homes/c/crisjagq/HOD_tests/covariance_matrices/EZMocks/\" # assuming we can apply these covariances for this cosmology also \n",
    "\n",
    "path_cov = '/global/u2/c/crisjagq/HOD_tests/covariance_matrices/CovaPT/low_density/'\n",
    "covfile = 'AnalyticCov_Gaussian_Pk_Abacus_CubicBox_hod_LNHOD.txt'\n",
    "\n",
    "path_files = '/global/cfs/cdirs/desicollab/users/alexpzfz/KP4/fiducial_cosmo/CubicBox/Pk/ELG/AbacusSummit_base_c003_SV3/los_z/' # path to all mocks c003 we got \n",
    "\n",
    "filename_recon = 'Pk_ELG_snap16_multigrid_nmesh512_sm10_f0.888_b1.20_recsym_Grid000_ph00'#0.npy'\n",
    "\n",
    "filename_prerecon = 'Pk_ELG_snap16_Grid000_ph00'#0.npy'\n",
    "\n",
    "\n",
    "# Dictionary containing z for the tracers\n",
    "reds = {\"ELG\": [1.1]}\n",
    "\n",
    "for tracer in [\"ELG\"]:\n",
    "    for i, z in enumerate(reds[tracer]):\n",
    "    \n",
    "        # Power Spectrum\n",
    "        # pre reconstruction file paths \n",
    "        pre_file = path_files #+ filename_prerecon \n",
    "        \n",
    "        pre_cov_file = path_cov + covfile#\"EZmocks_ELG_CubicBox_z1p1_Pk_cov_matrix_reshaped_pk-pre.txt\"  # Uses the EZmock covariance\n",
    "        \n",
    "        # post reconstruction file paths \n",
    "        post_file = path_files #+ filename_recon # was missing recsym directory initially \n",
    "        \n",
    "        post_cov_file = path_cov + covfile# \"EZmocks_ELG_CubicBox_z1p1_Pk_cov_matrix_reshaped_pk-pre.txt\"  # Uses the Prerecon EZmock covariance\n",
    "        \n",
    "        name = f\"DESI KP4 Abacus CubicBox Pk c003 gridc000 \" + tracer\n",
    "        \n",
    "        data = collect_pk_data(pre_file, post_file, pre_cov_file, post_cov_file, None, z, filename_prerecon,\n",
    "                               filename_recon, name, CV=False)\n",
    "        \n",
    "        plot_pk(data) # Plot the data to check things\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    # no correlation function at the moment      \n",
    "    \n",
    "#         # Correlation Function\n",
    "#         pre_file = path_abacus + tracer + f\"/Xi/Pre/lhior/txt_rebinned\"\n",
    "#         pre_cov_file = path_ezmock + \"EZmocks_ELG_CubicBox_z1p1_Xi_cov_matrix_reshaped-pre.txt\"  # Uses the EZmock covariance\n",
    "        \n",
    "#         post_file = path_abacus + tracer + \"/Xi/Post/lhior/RecSym_nmesh1024/txt_rebinned\"\n",
    "#         post_cov_file = path_ezmock + \"EZmocks_ELG_CubicBox_z1p1_Xi_cov_matrix_reshaped-pre.txt\"  # Uses the Prerecon EZmock covariance\n",
    "        \n",
    "#         name = f\"DESI KP4 Abacus CubicBox Xi \" + tracer\n",
    "#         data = collect_xi_data(pre_file, post_file, pre_cov_file, post_cov_file, z, \"Xi_AbacusSummit_base_c000_ph0\",\n",
    "#                                \"Xi_AbacusSummit_base_c000_ph0\", name)\n",
    "#         plot_xi(data) # Plot the data to check things\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c8301-c127-40aa-aebb-3493deeef192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921e9b6-282a-4e36-9733-ed274de85171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barry_env_desiproject_aw",
   "language": "python",
   "name": "barry_env_desiproject_aw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
