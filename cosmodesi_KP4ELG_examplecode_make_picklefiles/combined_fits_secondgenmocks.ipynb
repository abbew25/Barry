{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c76a29-c82b-4748-a57b-dc2b251fc08e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combined fits to alpha, epsilon and beta for second generation mocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc26d38-ccfc-4773-8a01-796b4ef4fe6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ae713-6788-4163-bdfc-e80abb647b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in the chains for the fits\n",
    "# lets first just look at alpha and epsilon\n",
    "# neglecting low z ELGs as they are only weakly constraining and likewise QSO cross-correlations as they are likely small\n",
    "\n",
    "# using post-recon mocks for all except QSOs - too few QSOs to have good reconstruction \n",
    "path = '/global/u1/a/abbew25/files_secondgen_chains/'\n",
    "\n",
    "listt = [r'$\\alpha$', r'$\\epsilon$', 'weights']\n",
    "#chains_ELGs_z_0p8_1p1 = pd.read_csv(path + 'ELG_08_11_recon' + '.csv')[list]\n",
    "chains_ELGs_z_1p1_1p6 = pd.read_csv(path + 'ELG_11_16_recon' + '.csv')[listt]\n",
    "chains_LRGs_z_0p4_0p6 = pd.read_csv(path + 'LRG_04_06_recon' + '.csv')[listt]\n",
    "chains_LRGs_z_0p6_0p8 = pd.read_csv(path + 'LRG_06_08_recon' + '.csv')[listt]\n",
    "chains_LRGs_z_0p8_1p1 = pd.read_csv(path + 'LRG_08_11_recon' + '.csv')[listt]\n",
    "chains_QSOs_z_0p8_2p1 = pd.read_csv(path + 'QSO_08_21_prerecon' + '.csv')[listt]\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598527e-ecb5-410f-a28d-6aa4a5969713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(chains_ELGs_z_1p1_1p6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5fdd7-a6ad-460a-86c1-64919fe39065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now interpolate the arrays with something called a Gaussian kernel density estimate (KDE)\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a1455-729a-4316-bef8-fd621560fbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kde_elg_11_16 = gaussian_kde(np.vstack([\n",
    "    chains_ELGs_z_1p1_1p6[r'$\\alpha$'].to_numpy(),\n",
    "    chains_ELGs_z_1p1_1p6[r'$\\epsilon$'].to_numpy()\n",
    "    ]), \n",
    "    weights=chains_ELGs_z_1p1_1p6['weights'].to_numpy())\n",
    "\n",
    "kde_lrg_04_06 = gaussian_kde(np.vstack([\n",
    "    chains_LRGs_z_0p4_0p6[r'$\\alpha$'].to_numpy(),\n",
    "    chains_LRGs_z_0p4_0p6[r'$\\epsilon$'].to_numpy()\n",
    "    ]), \n",
    "    weights=chains_LRGs_z_0p4_0p6['weights'].to_numpy())\n",
    "\n",
    "kde_lrg_06_08 = gaussian_kde(np.vstack([\n",
    "    chains_LRGs_z_0p6_0p8[r'$\\alpha$'].to_numpy(),\n",
    "    chains_LRGs_z_0p6_0p8[r'$\\epsilon$'].to_numpy()\n",
    "    ]), \n",
    "    weights=chains_LRGs_z_0p6_0p8['weights'].to_numpy())\n",
    "\n",
    "kde_lrg_08_11 = gaussian_kde(np.vstack([\n",
    "    chains_LRGs_z_0p8_1p1[r'$\\alpha$'].to_numpy(),\n",
    "    chains_LRGs_z_0p8_1p1[r'$\\epsilon$'].to_numpy()\n",
    "    ]), \n",
    "    weights=chains_LRGs_z_0p8_1p1['weights'].to_numpy())\n",
    "\n",
    "kde_qso_08_21 = gaussian_kde(np.vstack([\n",
    "    chains_QSOs_z_0p8_2p1[r'$\\alpha$'].to_numpy(),\n",
    "    chains_QSOs_z_0p8_2p1[r'$\\epsilon$'].to_numpy()\n",
    "    ]), \n",
    "    weights=chains_QSOs_z_0p8_2p1['weights'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576078a8-320d-469b-b4fd-8a03eae748e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xmin = np.min(chains_ELGs_z_1p1_1p6[r'$\\alpha$'].to_numpy())\n",
    "xmax = np.max(chains_ELGs_z_1p1_1p6[r'$\\alpha$'].to_numpy())\n",
    "ymin = np.min(chains_ELGs_z_1p1_1p6[r'$\\epsilon$'].to_numpy())\n",
    "ymax = np.max(chains_ELGs_z_1p1_1p6[r'$\\epsilon$'].to_numpy())\n",
    "\n",
    "x, y = np.linspace(xmin, xmax, 100), np.linspace(ymin, ymax, 100)\n",
    "X, Y = np.meshgrid(x, y) # get a 2D grid of points \n",
    "\n",
    "positions = np.vstack([X.ravel(), Y.ravel()]) # unravel the points to have a 2 1D arrays \n",
    "\n",
    "# use those points to interpolate\n",
    "values = np.vstack([chains_ELGs_z_1p1_1p6[r'$\\alpha$'].to_numpy(), chains_ELGs_z_1p1_1p6[r'$\\epsilon$'].to_numpy()])\n",
    "\n",
    "# take the interpolated points and shape the output to be 2D \n",
    "z0 = kde_elg_11_16(positions)\n",
    "Z = np.reshape(z0, X.shape)\n",
    "Z = np.flip(Z, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de377a-dfd1-4ace-9047-065b20b674dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the results \n",
    "import matplotlib as mpl\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# ax.plot(chains_ELGs_z_1p1_1p6[r'$\\alpha$'].to_numpy(), chains_ELGs_z_1p1_1p6[r'$\\epsilon$'].to_numpy(), \n",
    "#     'k.', markersize=0.5, alpha = 0.2)\n",
    "\n",
    "maxxarg, maxyarg = np.unravel_index(np.argmax(np.flip(Z,axis=0).T), shape=X.shape)\n",
    "\n",
    "plt.scatter(x[maxxarg], y[maxyarg], color='red', marker='*', s=26)\n",
    "\n",
    "ax.imshow(Z, cmap=plt.cm.gist_earth_r, extent=[xmin, xmax, ymin, ymax])\n",
    "\n",
    "norm = mpl.colors.Normalize(vmin=np.min(Z.reshape(-1)), vmax=np.max(Z.reshape(-1)))\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.gist_earth_r, norm=norm)\n",
    "plt.colorbar(sm, ax=ax)\n",
    "\n",
    "ax.set_xlim([xmin, xmax])\n",
    "\n",
    "ax.set_ylim([ymin, ymax])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09561a3a-cf30-4ffb-b7ce-97030ebe0a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ok, now lets add the 'likelihoods' from the functions together by taking the log of all of them then summing them \n",
    "\n",
    "kdes_list = [kde_elg_11_16, kde_lrg_04_06, kde_lrg_06_08, kde_lrg_08_11, kde_qso_08_21]\n",
    "dataframes_list = [chains_ELGs_z_1p1_1p6, chains_LRGs_z_0p4_0p6, chains_LRGs_z_0p6_0p8,\n",
    "                   chains_LRGs_z_0p8_1p1, chains_QSOs_z_0p8_2p1] \n",
    "\n",
    "#total = 0.0 \n",
    "Zs_list_max = []\n",
    "\n",
    "xmin = 0.95\n",
    "xmax = 1.05\n",
    "ymin = -0.05\n",
    "ymax = 0.05\n",
    "x = np.linspace(xmin, xmax, 150)\n",
    "y = np.linspace(ymin, ymax, 150)\n",
    "X, Y = np.meshgrid(x, y) # get a 2D grid of points \n",
    "\n",
    "positions = np.vstack([X.ravel(), Y.ravel()]) # unravel the points to have a 2 1D arrays \n",
    "\n",
    "for i, k in enumerate(kdes_list): \n",
    "    \n",
    "    # use those points to interpolate\n",
    "    values = np.vstack([dataframes_list[i][r'$\\alpha$'].to_numpy(), dataframes_list[i][r'$\\epsilon$'].to_numpy()])\n",
    "\n",
    "    # take the interpolated points and shape the output to be 2D \n",
    "    z0 = kdes_list[i](positions)\n",
    "    Z = np.flip(np.reshape(z0, X.shape), axis=0)\n",
    "    \n",
    "    Zs_list_max.append(np.max(z0))\n",
    "    #total = total + Z\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "#     ax.plot(dataframes_list[i][r'$\\alpha$'].to_numpy(), dataframes_list[i][r'$\\epsilon$'].to_numpy(), \n",
    "#     'k.', markersize=0.5, alpha = 0.25)\n",
    "    \n",
    "    maxxarg, maxyarg = np.unravel_index(np.argmax(np.flip(Z, axis=0).T), shape=X.shape)\n",
    "    print(maxxarg, maxyarg, x[maxxarg], y[maxyarg])\n",
    "    ax.scatter(x[maxxarg], y[maxyarg], \n",
    "            color='red', s=30)\n",
    "\n",
    "    ax.imshow(Z, cmap=plt.cm.gist_earth_r,\n",
    "    extent=[xmin, xmax, ymin, ymax])\n",
    "\n",
    "    norm = mpl.colors.Normalize(vmin=np.min(Z.reshape(-1)), vmax=np.max(Z.reshape(-1)))\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.gist_earth_r, norm=norm)\n",
    "    plt.colorbar(sm, ax=ax)\n",
    "\n",
    "    ax.set_xlim([xmin, xmax])\n",
    "\n",
    "    ax.set_ylim([ymin, ymax])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ebe82b-14ce-4a23-8420-a1f73ec979be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(total, cmap=plt.cm.gist_earth_r, extent=[xmin, xmax, ymin, ymax])\n",
    "# ax.vlines(1.00, -0.02, 0.02, linestyle='--', color='k')\n",
    "# ax.hlines(0.00, 0.98, 1.02, linestyle='--', color='k')\n",
    "\n",
    "# maxxarg, maxyarg = np.unravel_index(np.argmax(np.flip(total, axis=0).T), shape=X.shape)\n",
    "    \n",
    "# ax.scatter(x[maxxarg], y[maxyarg], color='red', s=30)\n",
    "\n",
    "# ax.set_xlabel(r'$\\alpha$')\n",
    "# ax.set_ylabel(r'$\\epsilon$')\n",
    "# ax.set_xlim([0.985, 1.015])\n",
    "# ax.set_ylim([-0.015, 0.015])\n",
    "# norm = mpl.colors.Normalize(vmin=np.min(total), vmax=np.max(total))\n",
    "# sm = plt.cm.ScalarMappable(cmap = plt.cm.gist_earth_r, norm=norm)\n",
    "# plt.colorbar(sm, ax=ax, label='Gaussian KDE')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd7d69-a675-4499-89e7-3080f3795f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have a likelihood, and we need to use MCMC to generate the likelihoods with error bars \n",
    "import emcee \n",
    "\n",
    "def log_prob(x):\n",
    "    \n",
    "    # x is a vector with alpha, epsilon x 5 for each dataset - in a given order \n",
    "    # get the likelihood from each KDE \n",
    "    elg = kdes_list[0]([x[0], x[1]])[0] \n",
    "    if elg <= 0.0 or abs(x[0])-1.0 >= 0.2 or abs(x[1]) >= 0.2 or abs(elg) == np.inf:\n",
    "        elg = -np.inf \n",
    "    else:\n",
    "        elg = np.log(elg)\n",
    "        \n",
    "    lrg1 = kdes_list[1]([x[2], x[3]])[0] \n",
    "    if lrg1 <= 0.0 or abs(x[2])-1.0 >= 0.2 or abs(x[3]) >= 0.2 or abs(lrg1) == np.inf:\n",
    "        lrg1 = -np.inf \n",
    "    else:\n",
    "        lrg1 = np.log(lrg1)\n",
    "        \n",
    "    lrg2 = kdes_list[2]([x[4], x[5]])[0] \n",
    "    if lrg2 <= 0.0 or abs(x[4])-1.0 >= 0.2 or abs(x[5]) >= 0.2 or abs(lrg2) == np.inf: \n",
    "        lrg2 = -np.inf \n",
    "    else:\n",
    "        lrg2 = np.log(lrg2)\n",
    "        \n",
    "    lrg3 = kdes_list[3]([x[6], x[7]])[0] \n",
    "    if lrg3 <= 0.0 or abs(x[6])-1.0 >= 0.2 or abs(x[7]) >= 0.2 or abs(lrg3) == np.inf: \n",
    "        lrg3 = -np.inf \n",
    "    else:\n",
    "        lrg3 = np.log(lrg3)\n",
    "    \n",
    "    qso = kdes_list[4]([x[8], x[9]])[0] \n",
    "    if qso <= 0.0 or abs(x[8])-1.0 >= 0.2 or abs(x[9]) >= 0.2 or abs(qso) == np.inf: \n",
    "        qso = -np.inf \n",
    "    else:\n",
    "        qso = np.log(qso)\n",
    "        \n",
    "    if abs(lrg1) == np.inf or abs(lrg2) == np.inf or abs(lrg3) == np.inf or abs(elg) == np.inf or abs(qso) == np.inf:\n",
    "        logl = -np.inf \n",
    "    else: \n",
    "        logl = elg + lrg1 + lrg2 + lrg3 + qso\n",
    "    \n",
    "    #print(elg, lrg1, lrg2, lrg3, qso, logl, x[8], x[9])\n",
    "    \n",
    "    return logl \n",
    "\n",
    "ndim = 10\n",
    "np.random.seed(42)\n",
    "nwalkers = 32                                                                                          \n",
    "p0 = np.array([np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers), \n",
    "               np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers), \n",
    "               np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers),  \n",
    "               np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers), \n",
    "               np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers), \n",
    "                 ]).T\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob)\n",
    "\n",
    "state = sampler.run_mcmc(p0, 1000)\n",
    "sampler.reset()\n",
    "\n",
    "state = sampler.run_mcmc(state, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271e11f-126f-4cd7-8780-bf86c3cccd48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state = sampler.run_mcmc(state, 5000) # run again optionally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c882cb-80dc-408f-b6aa-32468d563877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sampler.get_chain(flat=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f291eb3-e38e-4feb-b47a-1b16ec31a0af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import corner \n",
    "\n",
    "# labels = [r'$\\alpha_{\\mathrm{ELG}}$', r'$\\epsilon_{\\mathrm{ELG}}$',\n",
    "#           r'$\\alpha_{\\mathrm{LRG,1}}$', r'$\\epsilon_{\\mathrm{LRG,1}}$',\n",
    "#           r'$\\alpha_{\\mathrm{LRG,2}}$', r'$\\epsilon_{\\mathrm{LRG,2}}$',\n",
    "#           r'$\\alpha_{\\mathrm{LRG,3}}$', r'$\\epsilon_{\\mathrm{LRG,3}}$',\n",
    "#           r'$\\alpha_{\\mathrm{QSO}}$', r'$\\epsilon_{\\mathrm{QSO}}$',\n",
    "#          ]\n",
    "\n",
    "# #print(sampler.get_chain(flat=True).shape)\n",
    "# figure = corner.corner(sampler.get_chain(flat=True), labels=labels)\n",
    "\n",
    "\n",
    "labels = [r'$\\alpha_{\\mathrm{ELG}}$', \n",
    "          r'$\\epsilon_{\\mathrm{ELG}}$',\n",
    "          r'$\\alpha_{\\mathrm{LRG,1}}$', \n",
    "          r'$\\epsilon_{\\mathrm{LRG,1}}$',\n",
    "          r'$\\alpha_{\\mathrm{LRG,2}}$', \n",
    "          r'$\\epsilon_{\\mathrm{LRG,2}}$',\n",
    "          r'$\\alpha_{\\mathrm{LRG,3}}$', \n",
    "          r'$\\epsilon_{\\mathrm{LRG,3}}$',\n",
    "          r'$\\alpha_{\\mathrm{QSO}}$', \n",
    "          r'$\\epsilon_{\\mathrm{QSO}}$', \n",
    "          #r'$\\beta_{N_{\\mathrm{eff}}}$'\n",
    "         ]\n",
    "\n",
    "truth = {r'$\\alpha_{\\mathrm{ELG}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{ELG}}$': 0.0, \n",
    "          r'$\\alpha_{\\mathrm{LRG,1}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{LRG,1}}$': 0.0,\n",
    "          r'$\\alpha_{\\mathrm{LRG,2}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{LRG,2}}$': 0.0,\n",
    "          r'$\\alpha_{\\mathrm{LRG,3}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{LRG,3}}$': 0.0,\n",
    "          r'$\\alpha_{\\mathrm{QSO}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{QSO}}$': 0.0,\n",
    "          #r'$\\beta_{N_{\\mathrm{eff}}}$': 1.0\n",
    "        } \n",
    "from chainconsumer import ChainConsumer \n",
    "from chainconsumer import Chain, Truth\n",
    "c = ChainConsumer() \n",
    "\n",
    "chains_flat = sampler.get_chain(flat=True)\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "df = pd.DataFrame({labels[i]: chains_flat[:,i] for i in np.arange(len(chains_flat[0,:]))})\n",
    "#print(df)\n",
    "\n",
    "c.add_chain(Chain(samples=df, name='chains'))\n",
    "c.add_truth(Truth(location=truth))\n",
    "c.plotter.plot(\n",
    "    #truth=truth,\n",
    "    #parameters=labels,\n",
    "    #legend=False, \n",
    "    #show_contour_labels=True\n",
    "    )\n",
    "\n",
    "\n",
    "import pickle \n",
    "\n",
    "path = '/global/homes/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/'\n",
    "with open(path+\"datasecondgenmockscombinedchains_anisotropicstandard.txt\", 'wb') as f: \n",
    "    pickle.dump(sampler,f) \n",
    "\n",
    "# with open(path+\"datasecondgenmockscombinedchains.txt\", 'rb') as f: \n",
    "#     sampler = pickle.load(f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616be81-8ca1-4fe0-8cba-707dae7e6ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fc27f2a-4d36-4713-8d0a-8b9f53ed2e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "# now make the same KDEs for the data with beta included in the fit and use it to find the likelihood for the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de76fbe-235b-48c6-be09-cebbe25dcfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in the chains for the fits\n",
    "# lets first just look at alpha and epsilon\n",
    "# neglecting low z ELGs as they are only weakly constraining and likewise QSO cross-correlations as they are likely small\n",
    "\n",
    "# using post-recon mocks for all except QSOs - too few QSOs to have good reconstruction \n",
    "path = '/global/u1/a/abbew25/files_secondgen_chains/'\n",
    "\n",
    "listt = [r'$\\alpha$', r'$\\epsilon$', r'$\\beta_{\\phi(N_{\\mathrm{eff}})}$', 'weights']\n",
    "#chains_ELGs_z_0p8_1p1 = pd.read_csv(path + 'ELG_08_11_recon' + '.csv')[list]\n",
    "chains_ELGs_z_1p1_1p6 = pd.read_csv(path + 'ELG_11_16_recon_phaseshift' + '.csv')[listt]\n",
    "chains_LRGs_z_0p4_0p6 = pd.read_csv(path + 'LRG_04_06_recon_phaseshift' + '.csv')[listt]\n",
    "chains_LRGs_z_0p6_0p8 = pd.read_csv(path + 'LRG_06_08_recon_phaseshift' + '.csv')[listt]\n",
    "chains_LRGs_z_0p8_1p1 = pd.read_csv(path + 'LRG_08_11_recon_phaseshift' + '.csv')[listt]\n",
    "chains_QSOs_z_0p8_2p1 = pd.read_csv(path + 'QSO_08_21_prerecon_phaseshift' + '.csv')[listt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23dbdd-6b9b-4914-8736-a6766944ec58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "kde_elg_11_16 = gaussian_kde(np.vstack([\n",
    "    chains_ELGs_z_1p1_1p6[r'$\\alpha$'].to_numpy(),\n",
    "    chains_ELGs_z_1p1_1p6[r'$\\epsilon$'].to_numpy(), \n",
    "    chains_ELGs_z_1p1_1p6[r'$\\beta_{\\phi(N_{\\mathrm{eff}})}$'].to_numpy(), \n",
    "    ]), \n",
    "    weights=chains_ELGs_z_1p1_1p6['weights'].to_numpy())\n",
    "\n",
    "kde_lrg_04_06 = gaussian_kde(np.vstack([\n",
    "    chains_LRGs_z_0p4_0p6[r'$\\alpha$'].to_numpy(),\n",
    "    chains_LRGs_z_0p4_0p6[r'$\\epsilon$'].to_numpy(),\n",
    "    chains_LRGs_z_0p4_0p6[r'$\\beta_{\\phi(N_{\\mathrm{eff}})}$'].to_numpy(),   \n",
    "    ]), \n",
    "    weights=chains_LRGs_z_0p4_0p6['weights'].to_numpy())\n",
    "\n",
    "kde_lrg_06_08 = gaussian_kde(np.vstack([\n",
    "    chains_LRGs_z_0p6_0p8[r'$\\alpha$'].to_numpy(),\n",
    "    chains_LRGs_z_0p6_0p8[r'$\\epsilon$'].to_numpy(),\n",
    "    chains_LRGs_z_0p6_0p8[r'$\\beta_{\\phi(N_{\\mathrm{eff}})}$'].to_numpy(), \n",
    "    ]), \n",
    "    weights=chains_LRGs_z_0p6_0p8['weights'].to_numpy())\n",
    "\n",
    "kde_lrg_08_11 = gaussian_kde(np.vstack([\n",
    "    chains_LRGs_z_0p8_1p1[r'$\\alpha$'].to_numpy(),\n",
    "    chains_LRGs_z_0p8_1p1[r'$\\epsilon$'].to_numpy(),\n",
    "    chains_LRGs_z_0p8_1p1[r'$\\beta_{\\phi(N_{\\mathrm{eff}})}$'].to_numpy(), \n",
    "    ]), \n",
    "    weights=chains_LRGs_z_0p8_1p1['weights'].to_numpy())\n",
    "\n",
    "kde_qso_08_21 = gaussian_kde(np.vstack([\n",
    "    chains_QSOs_z_0p8_2p1[r'$\\alpha$'].to_numpy(),\n",
    "    chains_QSOs_z_0p8_2p1[r'$\\epsilon$'].to_numpy(),\n",
    "    chains_QSOs_z_0p8_2p1[r'$\\beta_{\\phi(N_{\\mathrm{eff}})}$'].to_numpy(), \n",
    "    ]), \n",
    "    weights=chains_QSOs_z_0p8_2p1['weights'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c59d7-3ba9-4f81-ac5e-e6e3895077af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ok, now lets add the 'likelihoods' from the functions together by taking the log of all of them then summing them \n",
    "\n",
    "kdes_list = [kde_elg_11_16, kde_lrg_04_06, kde_lrg_06_08, kde_lrg_08_11, kde_qso_08_21]\n",
    "dataframes_list = [chains_ELGs_z_1p1_1p6, chains_LRGs_z_0p4_0p6, chains_LRGs_z_0p6_0p8,\n",
    "                   chains_LRGs_z_0p8_1p1, chains_QSOs_z_0p8_2p1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a2b98-1198-43ba-ad05-72373b74a814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we have a likelihood, and we need to use MCMC to generate the likelihoods with error bars \n",
    "import emcee \n",
    "\n",
    "def log_prob(x):\n",
    "    \n",
    "    # x is a vector with alpha, epsilon x 5 for each dataset - in a given order \n",
    "    # get the likelihood from each KDE \n",
    "    elg = kdes_list[0]([x[0], x[1], x[10]])[0] \n",
    "    if elg <= 0.0 or abs(x[0])-1.0 >= 0.2 or abs(x[1]) >= 0.2 or abs(elg) == np.inf:\n",
    "        elg = -np.inf \n",
    "    else:\n",
    "        elg = np.log(elg)\n",
    "        \n",
    "    lrg1 = kdes_list[1]([x[2], x[3], x[10]])[0] \n",
    "    if lrg1 <= 0.0 or abs(x[2])-1.0 >= 0.2 or abs(x[3]) >= 0.2 or abs(lrg1) == np.inf: \n",
    "        lrg1 = -np.inf \n",
    "    else:\n",
    "        lrg1 = np.log(lrg1)\n",
    "        \n",
    "    lrg2 = kdes_list[2]([x[4], x[5], x[10]])[0] \n",
    "    if lrg2 <= 0.0 or abs(x[4])-1.0 >= 0.2 or abs(x[5]) >= 0.2 or abs(lrg2) == np.inf: \n",
    "        lrg2 = -np.inf \n",
    "    else:\n",
    "        lrg2 = np.log(lrg2)\n",
    "        \n",
    "    lrg3 = kdes_list[3]([x[6], x[7], x[10]])[0] \n",
    "    if lrg3 <= 0.0 or abs(x[6])-1.0 >= 0.2 or abs(x[7]) >= 0.2 or abs(lrg3) == np.inf: \n",
    "        lrg3 = -np.inf \n",
    "    else:\n",
    "        lrg3 = np.log(lrg3)\n",
    "    \n",
    "    qso = kdes_list[4]([x[8], x[9], x[10]])[0] \n",
    "    if qso <= 0.0 or abs(x[8])-1.0 >= 0.2 or abs(x[9]) >= 0.2 or abs(qso) == np.inf: \n",
    "        qso = -np.inf \n",
    "    else:\n",
    "        qso = np.log(qso)\n",
    "        \n",
    "    if abs(lrg1) == np.inf or abs(lrg2) == np.inf or abs(lrg3) == np.inf or abs(elg) == np.inf or abs(qso) == np.inf:\n",
    "        logl = -np.inf \n",
    "    elif x[10] > 2.4 or x[10] < -1.0:\n",
    "        logl = -np.inf\n",
    "    else: \n",
    "        logl = elg + lrg1 + lrg2 + lrg3 + qso\n",
    "    \n",
    "    #if np.iscomplex(logl):\n",
    "    #print(logl, x)\n",
    "        \n",
    "    return logl \n",
    "\n",
    "ndim = 11\n",
    "np.random.seed(42)\n",
    "nwalkers = 32                                                                                          \n",
    "p0 = np.array([np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers), \n",
    "               np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers), \n",
    "               np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers), \n",
    "               np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers), \n",
    "               np.random.uniform(0.99, 1.01, nwalkers),  np.random.uniform(-0.01, 0.01, nwalkers), \n",
    "               np.random.uniform(0.99, 1.01, nwalkers)\n",
    "                 ]).T\n",
    "\n",
    "# We'll track how the average autocorrelation time estimate changes\n",
    "\n",
    "max_n = 10000\n",
    "index = 0\n",
    "autocorr = np.empty(max_n)\n",
    "\n",
    "# This will be useful to testing convergence\n",
    "old_tau = np.inf\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob)\n",
    "\n",
    "# state = sampler.run_mcmc(p0, 1000)\n",
    "# sampler.reset()\n",
    "\n",
    "# state = sampler.run_mcmc(state, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c26cf-25f6-4638-8d0e-d8136ad8c988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# state = sampler.run_mcmc(state, 10000) # run again optionally \n",
    "\n",
    "# Now we'll sample for up to max_n steps\n",
    "for sample in sampler.sample(p0, iterations=max_n, progress=True):\n",
    "    # Only check convergence every 100 steps\n",
    "    if sampler.iteration % 100:\n",
    "        continue\n",
    "\n",
    "    # Compute the autocorrelation time so far\n",
    "    # Using tol=0 means that we'll always get an estimate even\n",
    "    # if it isn't trustworthy\n",
    "    tau = sampler.get_autocorr_time(tol=0)\n",
    "    autocorr[index] = np.mean(tau)\n",
    "    index += 1\n",
    "\n",
    "    # Check convergence\n",
    "    converged = np.all(tau * 100 < sampler.iteration)\n",
    "    converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "    if converged:\n",
    "        break\n",
    "    old_tau = tau\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd473d-ee20-45d6-953f-a926d0834303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(sampler.get_chain(flat=True).shape)\n",
    "\n",
    "# import pickle \n",
    "\n",
    "# path = '/global/homes/a/abbew25/barryrepo/Barry/cosmodesi_KP4ELG_examplecode_make_picklefiles/'\n",
    "# # with open(path+\"datasecondgenmockscombinedchains.txt\", 'wb') as f: \n",
    "# #     pickle.dump(sampler,f) \n",
    "\n",
    "with open(path+\"datasecondgenmockscombinedchains.txt\", 'rb') as f: \n",
    "    sampler = pickle.load(f) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50878f-e2fb-47f4-b8f2-5346be50019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import corner \n",
    "# plt.rcParams['font.size'] = 15\n",
    "# labels = [r'$\\alpha_{\\mathrm{ELG}}$', r'$\\epsilon_{\\mathrm{ELG}}$',\n",
    "#           r'$\\alpha_{\\mathrm{LRG,1}}$', r'$\\epsilon_{\\mathrm{LRG,1}}$',\n",
    "#           r'$\\alpha_{\\mathrm{LRG,2}}$', r'$\\epsilon_{\\mathrm{LRG,2}}$',\n",
    "#           r'$\\alpha_{\\mathrm{LRG,3}}$', r'$\\epsilon_{\\mathrm{LRG,3}}$',\n",
    "#           r'$\\alpha_{\\mathrm{QSO}}$', r'$\\epsilon_{\\mathrm{QSO}}$', r'$\\beta_{N_{\\mathrm{eff}}}$'\n",
    "#          ]\n",
    "\n",
    "# #print(sampler.get_chain(flat=True).shape)\n",
    "# figure = corner.corner(sampler.get_chain(flat=True, discard=2000), labels=labels, #quantiles=[0.5-0.341, 0.5, 0.5+0.341], \n",
    "#                        show_titles=True, title_fmt = '.3f',\n",
    "# truths=[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1., 0., 1., 0., 1.], truth_color='blue')\n",
    "\n",
    "\n",
    "#show the samplers\n",
    "# fig, axes = plt.subplots(11)#, figsize=(10, 7), sharex=True)\n",
    "# samples = sampler.get_chain()\n",
    "\n",
    "labels = [r'$\\alpha_{\\mathrm{ELG}}$', \n",
    "          r'$\\epsilon_{\\mathrm{ELG}}$',\n",
    "          r'$\\alpha_{\\mathrm{LRG,1}}$', \n",
    "          r'$\\epsilon_{\\mathrm{LRG,1}}$',\n",
    "          r'$\\alpha_{\\mathrm{LRG,2}}$', \n",
    "          r'$\\epsilon_{\\mathrm{LRG,2}}$',\n",
    "          r'$\\alpha_{\\mathrm{LRG,3}}$', \n",
    "          r'$\\epsilon_{\\mathrm{LRG,3}}$',\n",
    "          r'$\\alpha_{\\mathrm{QSO}}$', \n",
    "          r'$\\epsilon_{\\mathrm{QSO}}$', \n",
    "          r'$\\beta_{N_{\\mathrm{eff}}}$'\n",
    "         ]\n",
    "\n",
    "truth = {r'$\\alpha_{\\mathrm{ELG}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{ELG}}$': 0.0, \n",
    "          r'$\\alpha_{\\mathrm{LRG,1}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{LRG,1}}$': 0.0,\n",
    "          r'$\\alpha_{\\mathrm{LRG,2}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{LRG,2}}$': 0.0,\n",
    "          r'$\\alpha_{\\mathrm{LRG,3}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{LRG,3}}$': 0.0,\n",
    "          r'$\\alpha_{\\mathrm{QSO}}$': 1.0,\n",
    "          r'$\\epsilon_{\\mathrm{QSO}}$': 0.0,\n",
    "          r'$\\beta_{N_{\\mathrm{eff}}}$': 1.0\n",
    "        } \n",
    "from chainconsumer import ChainConsumer \n",
    "from chainconsumer import Chain\n",
    "c = ChainConsumer() \n",
    "\n",
    "chains_flat = sampler.get_chain(flat=True, discard=5000)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({labels[i]: chains_flat[:,i] for i in np.arange(len(chains_flat[0,:]))})\n",
    "\n",
    "c.add_chain(Chain(samples=df, name='chains'))\n",
    "c.add_truth(Truth(location=truth))\n",
    "c.plotter.plot(\n",
    "    #truth=truth,\n",
    "    #parameters=labels,\n",
    "    #legend=False, \n",
    "    #show_contour_labels=True\n",
    "    )\n",
    "\n",
    "# for i in range(ndim):\n",
    "#     ax = axes[i]\n",
    "#     ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "#     #ax.set_xlim(0, len(samples))\n",
    "#     ax.set_ylabel(labels[i])\n",
    "#     ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "# axes[-1].set_xlabel(\"step number\");\n",
    "#discards the firsts\n",
    "# flat_samples = sampler.get_chain(discard=100, thin=15, flat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d88904-eb7e-44fc-b835-cf41352d97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635a42a-d1fe-4f97-8631-a7f11a527ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barry_env_desiproject_aw",
   "language": "python",
   "name": "barry_env_desiproject_aw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
