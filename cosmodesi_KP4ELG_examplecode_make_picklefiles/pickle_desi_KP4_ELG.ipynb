{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d12a836-51f0-44d8-a85b-426188145ad1",
   "metadata": {},
   "source": [
    "# NOTEBOOK FOR DEFAULT ELG - PICKLE FILES\n",
    "Written by Cristhian Garcia-Quintero. See pickle_desi_kp4_LRG.ipynb for more description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8117d9-b291-411b-9fc0-b4c3ba3af981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages and set up the fiducial cosmology\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from cosmoprimo.fiducial import DESI # package interface for CLASS and CAMB \n",
    "from scipy.interpolate import splrep, splev\n",
    "from cosmoprimo import PowerSpectrumBAOFilter\n",
    "from pypower import BaseMatrix, PowerSpectrumMultipoles, PowerSpectrumSmoothWindow, PowerSpectrumSmoothWindowMatrix, PowerSpectrumOddWideAngleMatrix, setup_logging\n",
    "from pycorr import TwoPointCorrelationFunction, project_to_multipoles\n",
    "cosmo = DESI() # initialize CLASS/CAMB like object for doing calculations of power spectrum etc. \n",
    "#print(dir(DESI()))\n",
    "from matplotlib import rc\n",
    "import matplotlib\n",
    "plt.style.use('default')\n",
    "from statsmodels.stats.moment_helpers import cov2corr\n",
    "\n",
    "print(cosmo.A_s, cosmo.H0, cosmo.Omega0_b, cosmo.n_s, cosmo.N_eff, cosmo.Omega0_m, cosmo.tau_reio)\n",
    "exit()\n",
    "#print(dir(cosmo))\n",
    "cosmo.N_eff = 3.044\n",
    "# Save the default DESI template to a file - added in code here to make sure the template is prepared properly \n",
    "k_min = 1e-4\n",
    "k_max = 5\n",
    "k_num = 2000\n",
    "kl = np.logspace(np.log(k_min), np.log(k_max), k_num, base=np.e)\n",
    "pkz = cosmo.get_fourier().pk_interpolator() # object to get power spectrum from interpolator \n",
    "pk = pkz.to_1d(z=0) # get power spectrum at z = 0 \n",
    "pkv = pk(kl) \n",
    "plt.loglog(kl, pkv, label='power spectrum') # full broadband power spectrum + wiggles\n",
    "plt.legend()\n",
    "plt.show()\n",
    "pknow = PowerSpectrumBAOFilter(pk, engine='wallish2018').smooth_pk_interpolator()\n",
    "pksmv = pknow(kl) # interpolate smoothed power spectrum at desired k values \n",
    "plt.loglog(kl, pksmv, label='smoothed power spectrum') # smoothed broadband power spectrum without the wiggles (smoothed out) \n",
    "plt.legend()\n",
    "plt.show()\n",
    "np.savetxt(\"./DESI_Pk_template.dat\", np.c_[kl, pksmv, pkv/pksmv - 1.0],  fmt=\"%g %g %g\", header=\"k     pk_smooth     pk_ratio\") # saving \n",
    "# the smoothed power spectrum and the ratio of the smooth to original to get the wiggles only - gets used later \n",
    "\n",
    "\n",
    "plt.semilogx(kl, pkv/pksmv - 1.0, label='power spectrum wiggles only')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def plot_cov(matrix):\n",
    "    norm = matplotlib.colors.Normalize(vmin=-1, vmax=1)\n",
    "    ''' Plot the correlation matrix derived from the covariance matrix '''\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.imshow(cov2corr(matrix), cmap=plt.get_cmap('bwr'))\n",
    "    plt.colorbar()\n",
    "    plt.clim(-1,1)\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12e5227-7693-45c7-aa68-b88a40cc4d4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Power spectrum routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a9dbf2-d720-4504-8168-d86d00601b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Spectrum. By Cristhian Garcia-Quintero, here we use an already rebinned Pk multipoles .txt file with the k-values and multipoles in a single file. Barry needs 5 even+odd multipoles, but the odd ones can be filled with zeros if these haven't been measured, as is done here.\n",
    "def getpk_cgq(loc, zname, CV, post=False):\n",
    "    seed = [\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\",\n",
    "            \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\",\n",
    "            \"20\", \"21\", \"22\", \"23\", \"24\"]\n",
    "    res = []\n",
    "    nmocks = len(seed)\n",
    "    for i in range(nmocks): # looping through mocks and opening up \n",
    "        # Read data for a single mock\n",
    "        if (CV == True and post==True):\n",
    "            mydata = open(loc + '/' + zname + seed[i] + '.gcat_MultiGrid_mesh1024_smooth15_recsym_b1.2_randoms_20X.Pk_nmesh1152.ecsv', 'r')\n",
    "        elif (CV == True and post==False):\n",
    "            mydata = open(loc + '/' + zname + seed[i] + '.gcat.Pk_nmesh1152.ecsv', 'r')\n",
    "        else:\n",
    "            mydata = open(loc + '/' + zname + seed[i] + '.txt', 'r') \n",
    "        lines=mydata.readlines()\n",
    "        k  = []\n",
    "        P0 = []\n",
    "        P2 = []\n",
    "        P4 = []\n",
    "        for line in lines: # looping through lines in file to save k, monopole, quadrupole and hexadecapole \n",
    "            if line.startswith('#'):\n",
    "                if line[4:17]=='galaxy_number':\n",
    "                    num_gal = float(line.split()[2])\n",
    "                    num_ran = num_gal * 20\n",
    "                    boxsize = 2000\n",
    "                    nbar_gal = num_gal/boxsize**3\n",
    "                    nbar_ran = num_ran/boxsize**3\n",
    "                    shot_noise_gal = 1/nbar_gal\n",
    "                    shot_noise_ran = 1/nbar_ran\n",
    "                    shot_noise = shot_noise_gal + shot_noise_ran\n",
    "                    print(\"num_gal:\", num_gal, \"nbar_gal:\", nbar_gal, \"Shot-Noise:\", shot_noise)\n",
    "            else:\n",
    "                if (CV == True):\n",
    "                    k.append(line.split()[0]) \n",
    "                    P0.append(line.split()[1]) \n",
    "                    P2.append(line.split()[2]) \n",
    "                    P4.append(line.split()[3]) \n",
    "                elif (post == True):\n",
    "                    k.append(line.split()[1]) \n",
    "                    P0.append(line.split()[3]) \n",
    "                    P2.append(line.split()[5]) \n",
    "                    P4.append(line.split()[7]) \n",
    "                else:\n",
    "                    k.append(line.split()[1]) \n",
    "                    P0.append(line.split()[3]) \n",
    "                    P2.append(line.split()[4]) \n",
    "                    P4.append(line.split()[5]) \n",
    "        mydata.close()\n",
    "        if (CV == True):\n",
    "            k=k[1:]\n",
    "            P0=P0[1:]\n",
    "            P2=P2[1:]\n",
    "            P4=P4[1:]\n",
    "        k  = np.array([float(i) for i in k])    \n",
    "        P0 = np.array([float(i) for i in P0])    \n",
    "        P2 = np.array([float(i) for i in P2])    \n",
    "        P4 = np.array([float(i) for i in P4])   \n",
    "        # Append 5 multipoles to result\n",
    "        df = {}\n",
    "        df[\"k\"] = k\n",
    "        if (CV == True):\n",
    "            df[f\"pk0\"] = P0 - shot_noise\n",
    "        else:\n",
    "            df[f\"pk0\"] = P0\n",
    "        df[f\"pk2\"] = P2\n",
    "        df[f\"pk4\"] = P4\n",
    "        df[\"pk1\"] = np.zeros(len(df[\"k\"])) # in dataframe save odd multipoles as zeros \n",
    "        df[\"pk3\"] = np.zeros(len(df[\"k\"]))\n",
    "        res.append(pd.DataFrame(df)[[\"k\", \"pk0\", \"pk1\", \"pk2\", \"pk3\", \"pk4\"]])\n",
    "         \n",
    "    return res\n",
    "    \n",
    "# Window function matrix. The window functions are stored in a dictionary of 'step sizes' i.e., how many bins get stuck together relative to the \n",
    "# pk measurements so that we can rebin the P(k) at run time if required. Each step size is a dictionary with:\n",
    "#    the input and output k binning (w_ks_input, w_ks_output), the window function matrix (w_transform) and integral constraint (w_k0_scale).\n",
    "# The window function assumes 6 input and 5 output multipoles. For cubic sims, we can set the integral constraint to zero and window matrix to the identity matrix, as is done here.\n",
    "def getwin_dummy(ks):\n",
    "    res = {\"w_ks_input\": ks.copy(), \"w_k0_scale\": np.zeros(ks.size), \"w_transform\": np.eye(5 * ks.size, 6 * ks.size), \"w_ks_output\": ks.copy()}\n",
    "    return {1: res}  # Step size is one\n",
    "\n",
    "# The conversion matrix M from Beutler 2019. Used to compute the odd multipole models given the even multipoles. In the absence of wide angle effects, or if we don't care about\n",
    "# the odd multipoles, we can set this to a block matrix with identity matrices in the appropriate places, as is done here.\n",
    "def getcomp_dummy(ks):\n",
    "    matrix = np.zeros((6 * ks.size, 3 * ks.size))\n",
    "    matrix[: ks.size, : ks.size] = np.diag(np.ones(ks.size))\n",
    "    matrix[2 * ks.size : 3 * ks.size, ks.size : 2 * ks.size] = np.diag(np.ones(ks.size))\n",
    "    matrix[4 * ks.size : 5 * ks.size, 2 * ks.size :] = np.diag(np.ones(ks.size))\n",
    "    return matrix\n",
    "\n",
    "# Read's in Juan's k-space window multipoles and use the routines in pypower to convert these to window and wideangle matrices\n",
    "def getwin(ks, winfile):\n",
    "    \n",
    "    wa_orders = 1 # wide-angle order\n",
    "    ellsin = [0, 2, 4] # input (theory) multipoles\n",
    "    ellsout = [0, 1, 2, 3, 4] # output multipoles\n",
    "    \n",
    "    # Check for the presence of window and wide angle matrix files already. If we find both, just load them in\n",
    "    winmatname = winfile + \"_matrix.npy\"\n",
    "    wideanglename = winfile + \"_wideangle.npy\"\n",
    "    if os.path.exists(winmatname) and os.path.exists(wideanglename):\n",
    "    \n",
    "        wm = BaseMatrix.load(winmatname)\n",
    "        wam = BaseMatrix.load(wideanglename)\n",
    "        \n",
    "    else: # need to calculate wide angle matrix, window matrix \n",
    "\n",
    "        window = PowerSpectrumSmoothWindow.load(winfile + \".npy\") # PowerSpectrumSmoothWindow is a python class, \n",
    "        # here just loading window function file multipoles \n",
    "\n",
    "        sep = np.geomspace(1e-4, 1e4, 1024*16) # configuration space separation for FFTlog\n",
    "        kin_rebin = 8 # rebin input theory to save memory, and run time when fitting.\n",
    "        kin_lim = (1e-4, 0.4) # pre-cut input (theory) ks to save some memory\n",
    "        projsin = ellsin + PowerSpectrumOddWideAngleMatrix.propose_out(ellsin, wa_orders=wa_orders)\n",
    "        wm = PowerSpectrumSmoothWindowMatrix(ks, projsin=projsin, projsout=ellsout, window=window, sep=sep, kin_rebin=kin_rebin, kin_lim=kin_lim, default_zero=True)\n",
    "        wam = PowerSpectrumOddWideAngleMatrix(wm.xin[0], projsin=ellsin, projsout=wm.projsin, d=1., wa_orders=wa_orders, los=window.attrs['los_type'])\n",
    "        \n",
    "        # Save the matrices\n",
    "        wm.save(winmatname)\n",
    "        wam.save(wideanglename)\n",
    "    \n",
    "    # The pypower functions store the inner chunks in the order 0, 2, 4, 1, 3, 5, \n",
    "    # but Barry expects 0, 1, 2, 3, 4, 5. So let's break the matrices apart and reorder them.\n",
    "    wm_reshape = np.vsplit(wm.value, 6)\n",
    "    wm_reshape = np.concatenate([wm_reshape[0],wm_reshape[3],wm_reshape[1],wm_reshape[4],wm_reshape[2],wm_reshape[5]]).T    \n",
    "    wam_reshape = np.hsplit(wam.value, 6)\n",
    "    wam_reshape = np.concatenate([wam_reshape[0],wam_reshape[3],wam_reshape[1],wam_reshape[4],wam_reshape[2],wam_reshape[5]], axis=1).T\n",
    "    \n",
    "    res = {\"w_ks_input\": wm.xin[0], \"w_k0_scale\": np.zeros(ks.size), \"w_transform\": wm_reshape, \"w_ks_output\": wm.xout[0]}\n",
    "    winmat = {1: res}   # Step size is one, but we could modify this to contain other stepsizes too.\n",
    "    return winmat, wam_reshape\n",
    "\n",
    "# Power spectrum covariance matrix. Needs to have 6 multipoles, but if the some of them haven't been measured, we can set the covariance matrix elements to the identity matrix, as is done here.\n",
    "def format_pk_cov(nks, covfile):\n",
    "\n",
    "    cov_input = pd.read_csv(covfile, comment=\"#\", delim_whitespace=True, header=None).to_numpy()\n",
    "    nin = nks\n",
    "    cov = np.eye(5 * nks)\n",
    "    cov[:nks, :nks] = cov_input[:nks, :nks]\n",
    "    cov[:nks, 2 * nks : 3 * nks] = cov_input[:nks, nin : nin + nks]\n",
    "    cov[:nks, 4 * nks : 5 * nks] = cov_input[:nks, 2 * nin : 2 * nin + nks]\n",
    "    cov[2 * nks : 3 * nks, :nks] = cov_input[nin : nin + nks, :nks]\n",
    "    cov[2 * nks : 3 * nks, 2 * nks : 3 * nks] = cov_input[nin : nin + nks, nin : nin + nks]\n",
    "    cov[2 * nks : 3 * nks, 4 * nks : 5 * nks] = cov_input[nin : nin + nks, 2 * nin : 2 * nin + nks]\n",
    "    cov[4 * nks : 5 * nks, :nks] = cov_input[2 * nin : 2 * nin + nks, :nks]\n",
    "    cov[4 * nks : 5 * nks, 2 * nks : 3 * nks] = cov_input[2 * nin : 2 * nin + nks, nin : nin + nks]\n",
    "    cov[4 * nks : 5 * nks, 4 * nks : 5 * nks] = cov_input[2 * nin : 2 * nin + nks, 2 * nin : 2 * nin + nks]\n",
    "    \n",
    "    plt.imshow(cov/np.sqrt(np.outer(np.diag(cov), np.diag(cov))))\n",
    "    plt.show()\n",
    "    \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "        #print(f\"These should all be 1: {v}\")\n",
    "    \n",
    "    return cov\n",
    "\n",
    "# Useful utility function to collate some Pk data - simple read in data for multipoles for pre and post reconstruction \n",
    "# also read in file for the window function of the data \n",
    "def collect_pk_data(pre_files, post_files, pre_cov_files, post_cov_files, winfile, zeff, prezname, postzname, name, CV=False):\n",
    "    \n",
    "    ks = None\n",
    "    pre_cov, post_cov = None, None\n",
    "    pre_data, post_data = None, None\n",
    "    pre_mocks, post_mocks = None, None\n",
    "    if pre_files is not None:\n",
    "        pre_res = getpk_cgq(pre_files, prezname, CV, post=False) \n",
    "        ks = pre_res[0][\"k\"].to_numpy()\n",
    "        #print(np.max(ks), np.min(ks), len(ks))\n",
    "        pre_cov = format_pk_cov(len(ks), pre_cov_file)\n",
    "        pre_mocks = [v for v in pre_res]\n",
    "    if post_files is not None:\n",
    "        post_res = getpk_cgq(post_files, postzname, CV, post=True)\n",
    "        ks = post_res[0][\"k\"].to_numpy() \n",
    "        post_cov = format_pk_cov(len(ks), post_cov_file)\n",
    "        post_mocks = [v for v in post_res]\n",
    "\n",
    "    if winfile is not None:\n",
    "        winmat, wideangle = getwin(ks, winfile)\n",
    "        wideangle = getcomp_dummy(ks)\n",
    "    else:\n",
    "        winmat, wideangle = getwin_dummy(ks), getcomp_dummy(ks)\n",
    "    \n",
    "    split = {\n",
    "        \"n_data\": 1,\n",
    "        \"pre-recon data\": pre_data,\n",
    "        \"pre-recon cov\": pre_cov,\n",
    "        \"post-recon data\": post_data,\n",
    "        \"post-recon cov\": post_cov,\n",
    "        \"pre-recon mocks\": pre_mocks,\n",
    "        \"post-recon mocks\": post_mocks,\n",
    "        \"cosmology\": {\n",
    "            \"om\": cosmo[\"Omega_m\"],\n",
    "            \"h0\": cosmo[\"h\"],\n",
    "            \"z\": zeff,\n",
    "            \"ob\": cosmo[\"Omega_b\"],\n",
    "            \"ns\": cosmo[\"n_s\"],\n",
    "            \"mnu\": np.sum(cosmo[\"m_ncdm\"]),\n",
    "            \"reconsmoothscale\": 15,\n",
    "        },\n",
    "        \"name\": name,\n",
    "        \"winfit\": winmat,\n",
    "        \"winpk\": None,  # We can set this to None; Barry will set it to zeroes given the length of the data vector.\n",
    "        \"m_mat\": wideangle,\n",
    "    }\n",
    "    \n",
    "    with open(f\"./\" + name.lower().replace(\" \", \"_\")+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(split, f)\n",
    "        \n",
    "    return split # writing read in file sand other results that are relevant to pickle file and returning \n",
    "\n",
    "# Plot the power spectra, for sanity checking\n",
    "def plot_pk(split, pre=True, post=True):\n",
    "    \n",
    "    if pre:\n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ks = split[\"pre-recon mocks\"][0][\"k\"]\n",
    "        nmocks = len(split[\"pre-recon mocks\"])\n",
    "        label = [r\"$P_{0}(k)$\", r\"$P_{2}(k)$\", r\"$P_{4}(k)$\"]\n",
    "        for m, pk in enumerate([\"pk0\", \"pk2\", \"pk4\"]): # looping and plotting each multipole mean value \n",
    "            yerr = ks * np.sqrt(np.diag(split[\"pre-recon cov\"]))[2 * m * len(ks) : (2 * m + 1) * len(ks)]\n",
    "            plt.errorbar(\n",
    "                ks,\n",
    "                ks * np.mean([split[\"pre-recon mocks\"][i][pk] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks): # each mock plotted multipole x ks array \n",
    "                plt.errorbar(ks, ks * split[\"pre-recon mocks\"][i][pk], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$k$\")\n",
    "        plt.ylabel(r\"$k\\,P(k)$\")\n",
    "        plt.title(split[\"name\"] + \" Prerecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "    \n",
    "    if post:\n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ks = split[\"post-recon mocks\"][0][\"k\"]\n",
    "        nmocks = len(split[\"post-recon mocks\"])\n",
    "        label = [r\"$P_{0}(k)$\", r\"$P_{2}(k)$\", r\"$P_{4}(k)$\"]\n",
    "        for m, pk in enumerate([\"pk0\", \"pk2\", \"pk4\"]):\n",
    "            yerr = ks * np.sqrt(np.diag(split[\"post-recon cov\"]))[2 * m * len(ks) : (2 * m + 1) * len(ks)]\n",
    "            plt.errorbar(\n",
    "                ks,\n",
    "                ks * np.mean([split[\"post-recon mocks\"][i][pk] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ks, ks * split[\"post-recon mocks\"][i][pk], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$k$\")\n",
    "        plt.ylabel(r\"$k\\,P(k)$\")\n",
    "        plt.title(split[\"name\"] + \" Postrecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7e3ed-99b5-4282-91e0-6ccad1252732",
   "metadata": {},
   "source": [
    "# Correlation function routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb61de-ca0c-4945-80dd-ee9c1b52f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Spectrum. By Cristhian Garcia-Quintero, here we use an already rebinned Pk multipoles .txt file with the k-values and multipoles in a single file. Barry needs 5 even+odd multipoles, but the odd ones can be filled with zeros if these haven't been measured, as is done here.\n",
    "def getxi_cgq(loc, zname, recon, RascalC, CV, post):\n",
    "    seed = [\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\",\n",
    "            \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\",\n",
    "            \"20\", \"21\", \"22\", \"23\", \"24\"]\n",
    "    res = []\n",
    "    nmocks = len(seed)\n",
    "    for i in range(nmocks):\n",
    "        # Read data for a single mock\n",
    "        mydata = open(loc + '/' + zname + seed[i] + '.txt', 'r') \n",
    "        lines=mydata.readlines()\n",
    "        s  = []\n",
    "        Xi0 = []\n",
    "        Xi2 = []\n",
    "        Xi4 = []\n",
    "        for line in lines: \n",
    "            if line.startswith('#'):\n",
    "                pass\n",
    "            else:\n",
    "                if (CV == True):\n",
    "                    s.append(line.split()[0]) \n",
    "                    Xi0.append(line.split()[1]) \n",
    "                    Xi2.append(line.split()[2]) \n",
    "                    Xi4.append(line.split()[3]) \n",
    "                else:\n",
    "                    s.append(line.split()[0]) \n",
    "                    Xi0.append(line.split()[2]) \n",
    "                    Xi2.append(line.split()[3]) \n",
    "                    Xi4.append(line.split()[4]) \n",
    "        mydata.close()\n",
    "        s  = np.array([float(i) for i in s])    \n",
    "        Xi0 = np.array([float(i) for i in Xi0])    \n",
    "        Xi2 = np.array([float(i) for i in Xi2])    \n",
    "        Xi4 = np.array([float(i) for i in Xi4])   \n",
    "        if (RascalC == True):\n",
    "            s = s[5:]\n",
    "            Xi0 = Xi0[5:]\n",
    "            Xi2 = Xi2[5:]\n",
    "            Xi4 = Xi4[5:]\n",
    "        # Append 5 multipoles to result ????????? \n",
    "        df = {}\n",
    "        df[\"s\"] = s\n",
    "        df[f\"xi0\"] = Xi0\n",
    "        df[f\"xi2\"] = Xi2\n",
    "        df[f\"xi4\"] = Xi4\n",
    "        res.append(pd.DataFrame(df)[[\"s\", \"xi0\", \"xi2\", \"xi4\"]])\n",
    "         \n",
    "    return res\n",
    "\n",
    "# Correlation function covariance matrix.\n",
    "def format_xi_cov(nss, covfile):\n",
    "\n",
    "    cov_input = pd.read_csv(covfile, comment=\"#\", delim_whitespace=True, header=None).to_numpy()\n",
    "    nin = nss\n",
    "    cov = np.zeros((3 * nss, 3 * nss))\n",
    "    cov[:nss, :nss] = cov_input[:nss, :nss]\n",
    "    cov[:nss, nss : 2 * nss] = cov_input[:nss, nin : nin + nss]\n",
    "    cov[:nss, 2 * nss :] = cov_input[:nss, 2 * nin : 2 * nin + nss]\n",
    "    cov[nss : 2 * nss, :nss] = cov_input[nin : nin + nss, :nss]\n",
    "    cov[nss : 2 * nss, nss : 2 * nss] = cov_input[nin : nin + nss, nin : nin + nss]\n",
    "    cov[nss : 2 * nss, 2 * nss :] = cov_input[nin : nin + nss, 2 * nin : 2 * nin + nss]\n",
    "    cov[2 * nss :, :nss] = cov_input[2 * nin : 2 * nin + nss, :nss]\n",
    "    cov[2 * nss :, nss : 2 * nss] = cov_input[2 * nin : 2 * nin + nss, nin : nin + nss]\n",
    "    cov[2 * nss :, 2 * nss :] = cov_input[2 * nin : 2 * nin + nss, 2 * nin : 2 * nin + nss]\n",
    "    \n",
    "    plt.imshow(cov/np.sqrt(np.outer(np.diag(cov), np.diag(cov))))\n",
    "    plt.show()\n",
    "    \n",
    "    # Check the covariance matrix is invertible\n",
    "    v = np.diag(cov @ np.linalg.inv(cov))\n",
    "    if not np.all(np.isclose(v, 1)):\n",
    "        print(\"ERROR, setting an inappropriate covariance matrix that is almost singular!!!!\")\n",
    "        #print(f\"These should all be 1: {v}\")\n",
    "\n",
    "    return cov\n",
    "\n",
    "# Useful utility function to collate some Xi data\n",
    "def collect_xi_data(pre_files, post_files, pre_cov_file, post_cov_file, zeff, prezname, postzname, name, RascalC=False, CV=False):\n",
    "\n",
    "    pre_cov, post_cov = None, None\n",
    "    pre_data, post_data = None, None\n",
    "    pre_mocks, post_mocks = None, None\n",
    "    if pre_files is not None:\n",
    "        pre_res = getxi_cgq(pre_files, prezname, 'pre', RascalC, CV, post=False)\n",
    "        ss = pre_res[0][\"s\"].to_numpy()\n",
    "        pre_cov = format_xi_cov(len(ss), pre_cov_file)\n",
    "        pre_mocks = [v for v in pre_res]\n",
    "    if post_files is not None:\n",
    "        post_res = getxi_cgq(post_files, postzname, 'post', RascalC, CV, post=True)\n",
    "        ss = post_res[0][\"s\"].to_numpy()\n",
    "        post_cov = format_xi_cov(len(ss), post_cov_file)\n",
    "        post_mocks = [v for v in post_res]   \n",
    "    split = {\n",
    "        \"n_data\": 1,\n",
    "        \"pre-recon data\": pre_data,\n",
    "        \"pre-recon cov\": pre_cov,\n",
    "        \"post-recon data\": post_data,\n",
    "        \"post-recon cov\": post_cov,\n",
    "        \"pre-recon mocks\": pre_mocks,\n",
    "        \"post-recon mocks\": post_mocks,\n",
    "        \"cosmology\": {\n",
    "            \"om\": cosmo[\"Omega_m\"],\n",
    "            \"h0\": cosmo[\"h\"],\n",
    "            \"z\": zeff,\n",
    "            \"ob\": cosmo[\"Omega_b\"],\n",
    "            \"ns\": cosmo[\"n_s\"],\n",
    "            \"mnu\": np.sum(cosmo[\"m_ncdm\"]),\n",
    "            \"reconsmoothscale\": 15,\n",
    "        },\n",
    "        \"name\": name,\n",
    "    }\n",
    "    \n",
    "    with open(f\"./\" + name.lower().replace(\" \", \"_\")+\".pkl\", \"wb\") as f:\n",
    "        pickle.dump(split, f)\n",
    "        \n",
    "    return split\n",
    "    \n",
    "# Plot the power spectra, for sanity checking\n",
    "def plot_xi(split, pre=True, post=True):\n",
    "    \n",
    "    if pre:\n",
    "    \n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ss = split[\"pre-recon mocks\"][0][\"s\"]\n",
    "        nmocks = len(split[\"pre-recon mocks\"])\n",
    "        label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"pre-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * np.mean([split[\"pre-recon mocks\"][i][xi] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ss, ss ** 2 * split[\"pre-recon mocks\"][i][xi], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Prerecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "        \n",
    "    if post:\n",
    "        \n",
    "        color = [\"r\", \"b\", \"g\"]\n",
    "        ss = split[\"post-recon mocks\"][0][\"s\"]\n",
    "        nmocks = len(split[\"post-recon mocks\"])\n",
    "        label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "        for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "            yerr = ss ** 2 * np.sqrt(np.diag(split[\"post-recon cov\"]))[m * len(ss) : (m + 1) * len(ss)]\n",
    "            plt.errorbar(\n",
    "                ss,\n",
    "                ss ** 2 * np.mean([split[\"post-recon mocks\"][i][xi] for i in range(nmocks)], axis=0),\n",
    "                yerr=yerr,\n",
    "                marker=\"o\",\n",
    "                ls=\"None\",\n",
    "                c=color[m],\n",
    "                label=label[m],\n",
    "            )\n",
    "            for i in range(nmocks):\n",
    "                plt.errorbar(ss, ss ** 2 * split[\"post-recon mocks\"][i][xi], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / nmocks**(3.0/4.0))\n",
    "        plt.xlabel(r\"$s$\")\n",
    "        plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "        plt.title(split[\"name\"] + \" Postrecon\")\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ee333-a428-42ac-a257-55cee20df49d",
   "metadata": {},
   "source": [
    "# Produce Pickles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54aa38-1742-4b54-a6c0-39bc02ac7204",
   "metadata": {},
   "source": [
    "Default HOD (Pk and Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0573716-655b-4a45-a6bd-438b65ce9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over tracers\n",
    "path_abacus = '/global/cfs/cdirs/desi/cosmosim/KP45/MC/Clustering/AbacusSummit/CubicBox/' # pre-recon \n",
    "path_ezmock = \"/global/homes/c/crisjagq/HOD_tests/covariance_matrices/EZMocks/\"\n",
    "\n",
    "# Dictionary containing z for the tracers\n",
    "reds = {\"ELG\": [1.1]}\n",
    "\n",
    "for tracer in [\"ELG\"]:\n",
    "    for i, z in enumerate(reds[tracer]):\n",
    "    \n",
    "        # Power Spectrum\n",
    "        # pre reconstruction file paths \n",
    "        pre_file = path_abacus + tracer + \"/Pk/Pre/Cristhian/txt_rebinned/\"\n",
    "        \n",
    "        pre_cov_file = path_ezmock + \"EZmocks_ELG_CubicBox_z1p1_Pk_cov_matrix_reshaped_pk-pre.txt\"  # Uses the EZmock covariance\n",
    "        \n",
    "        # post reconstruction file paths \n",
    "        post_file = path_abacus + tracer + \"/Pk/Post/Cristhian/recsym/txt_rebinned/\" # was missing recsym directory initially \n",
    "        \n",
    "        post_cov_file = path_ezmock + \"EZmocks_ELG_CubicBox_z1p1_Pk_cov_matrix_reshaped_pk-pre.txt\"  # Uses the Prerecon EZmock covariance\n",
    "        name = f\"DESI KP4 Abacus CubicBox Pk \" + tracer\n",
    "        \n",
    "        data = collect_pk_data(pre_file, post_file, pre_cov_file, post_cov_file, None, z, \"Pk_ELGlowDens_Abacus_c000_ph0\",\n",
    "                               \"Pk_ELGlowDens_recsym_Abacus_c000_ph0\", name, CV=False)\n",
    "        plot_pk(data) # Plot the data to check things\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Correlation Function\n",
    "        pre_file = path_abacus + tracer + f\"/Xi/Pre/lhior/txt_rebinned\"\n",
    "        pre_cov_file = path_ezmock + \"EZmocks_ELG_CubicBox_z1p1_Xi_cov_matrix_reshaped-pre.txt\"  # Uses the EZmock covariance\n",
    "        \n",
    "        post_file = path_abacus + tracer + \"/Xi/Post/lhior/RecSym_nmesh1024/txt_rebinned\"\n",
    "        post_cov_file = path_ezmock + \"EZmocks_ELG_CubicBox_z1p1_Xi_cov_matrix_reshaped-pre.txt\"  # Uses the Prerecon EZmock covariance\n",
    "        \n",
    "        name = f\"DESI KP4 Abacus CubicBox Xi \" + tracer\n",
    "        data = collect_xi_data(pre_file, post_file, pre_cov_file, post_cov_file, z, \"Xi_AbacusSummit_base_c000_ph0\",\n",
    "                               \"Xi_AbacusSummit_base_c000_ph0\", name)\n",
    "        plot_xi(data) # Plot the data to check things\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31c031-8cbe-4cdc-aeab-8c77f4722799",
   "metadata": {},
   "source": [
    "Default HOD (Xi) with RascalC covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb54a65-f2ee-4d5c-921f-ce2da7daf0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over tracers\n",
    "path_abacus = \"/global/cfs/cdirs/desi/cosmosim/KP45/MC/Clustering/AbacusSummit/CubicBox/\"\n",
    "path_rascalC = \"/global/cfs/projectdirs/desi/users/mrash/RascalC/AbacusSummit/CubicBox/\"\n",
    "\n",
    "# Dictionary containing z for the tracers\n",
    "reds = {\"ELG\": [1.1]}\n",
    "\n",
    "for tracer in [\"ELG\"]:\n",
    "    for i, z in enumerate(reds[tracer]):\n",
    "\n",
    "        # Correlation Function\n",
    "        pre_file = path_abacus + tracer + f\"/Xi/Pre/lhior/txt_rebinned\"\n",
    "        pre_cov_file = path_rascalC + \"xi024_ELG_EZmocks_lin4_s20-200_cov_RascalC_Gaussian.txt\"\n",
    "        post_file = path_abacus + tracer + \"/Xi/Post/lhior/RecSym_nmesh1024/txt_rebinned\"\n",
    "        post_cov_file = path_rascalC + \"xi024_ELG_EZmocks_lin4_s20-200_cov_RascalC_Gaussian.txt\"\n",
    "        name = f\"DESI KP4 Abacus CubicBox RascalC Xi \" + tracer\n",
    "        data = collect_xi_data(pre_file, post_file, pre_cov_file, post_cov_file, z, \"Xi_AbacusSummit_base_c000_ph0\", \n",
    "                               \"Xi_AbacusSummit_base_c000_ph0\", name, RascalC=True)\n",
    "        plot_xi(data) # Plot the data to check things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc6297-989f-45cd-846d-4095deff21fd",
   "metadata": {},
   "source": [
    "Default HOD (Pk) with Control Variance reduced-noise measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21595a-bbd1-4d23-986a-a83b12a9ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over tracers\n",
    "path_CV = '/global/cfs/cdirs/desi/cosmosim/KP45/MC/Clustering/AbacusSummit/CubicBox/ELG/Pk_CV/'\n",
    "path_ezmock = \"/global/homes/c/crisjagq/HOD_tests/covariance_matrices/EZMocks/\"\n",
    "\n",
    "# Dictionary containing z for the tracers\n",
    "reds = {\"ELG\": [1.1]}\n",
    "\n",
    "for tracer in [\"ELG\"]:\n",
    "    for i, z in enumerate(reds[tracer]):\n",
    "    \n",
    "        # Power Spectrum\n",
    "        pre_file = path_CV + 'Pre/boryanah/'\n",
    "        pre_cov_file = path_ezmock + \"/EZmocks_ELG_CubicBox_z1p1_Pk_cov_matrix_reshaped_pk-pre.txt\"\n",
    "        post_file = path_CV + 'Post/boryanah/'\n",
    "        post_cov_file = path_ezmock + \"/EZmocks_ELG_CubicBox_z1p1_Pk_cov_matrix_reshaped_pk-pre.txt\"\n",
    "        name = f\"DESI KP4 Abacus CubicBox CV Pk \" + tracer\n",
    "        data = collect_pk_data(pre_file, post_file, pre_cov_file, post_cov_file, None, z, \"ELGlowDens_snap16_ph0\",\n",
    "                               \"ELG_snap16_ph0\", name, CV=True)\n",
    "        plot_pk(data) # Plot the data to check things"
   ]
  },
  {
   "cell_type": "raw",
   "id": "206cd138-db31-40e3-86d5-110819dec3b1",
   "metadata": {},
   "source": [
    "Default HOD (Xi) with Control Variance reduced-noise measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871623c-f86c-40ae-b0a5-747477202a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over tracers\n",
    "path_abacus = \"/global/cfs/cdirs/desi/cosmosim/KP45/MC/Clustering/AbacusSummit/CubicBox/\"\n",
    "path_ezmock = \"/global/homes/c/crisjagq/HOD_tests/covariance_matrices/EZMocks/\"\n",
    "\n",
    "# Dictionary containing z for the tracers\n",
    "reds = {\"ELG\": [1.1]}\n",
    "\n",
    "for tracer in [\"ELG\"]:\n",
    "    for i, z in enumerate(reds[tracer]):\n",
    "        # Correlation Function\n",
    "        pre_file = path_abacus + tracer + \"/Xi/Pre/HOD/rebinned_CV/default/\"\n",
    "        pre_cov_file = path_ezmock + \"EZmocks_ELG_CubicBox_z1p1_Xi_cov_matrix_reshaped-pre.txt\"  # Uses the EZmock covariance\n",
    "        post_file = path_abacus + tracer + \"/Xi/Post/HOD/rebinned_CV/default/\"\n",
    "        post_cov_file = path_ezmock + \"EZmocks_ELG_CubicBox_z1p1_Xi_cov_matrix_reshaped-pre.txt\"  # Uses the Prerecon EZmock covariance\n",
    "        name = f\"DESI KP4 Abacus CubicBox CV Xi \" + tracer\n",
    "        data = collect_xi_data(pre_file, post_file, pre_cov_file, post_cov_file, z, \"Xi_Abacus_CubicBox_ph0\", \n",
    "                               \"Xi_Abacus_CubicBox_ph0\", name, CV=True)\n",
    "        plot_xi(data) # Plot the data to check things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c93be-32df-4201-9bba-d44d146853ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barry_env_desiproject_aw",
   "language": "python",
   "name": "barry_env_desiproject_aw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
