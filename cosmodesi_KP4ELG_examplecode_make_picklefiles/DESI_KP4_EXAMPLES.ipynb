{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ded7dad-0a4e-496d-b4fc-e14c69e17725",
   "metadata": {},
   "source": [
    "# Examples of how to run Barry for DESI KP4\n",
    "This notebook demonstrates how to use Barry with the KP4 data. \n",
    "\n",
    "The data gets pre-processed into a set of 'pickle' files that contain everything Barry needs in the notebook `/barry/data/desi_kp4/pickle_desi_kp4.py`. After running this, you should have the following set of 16 files in `/barry/data/`\n",
    "\n",
    "* `desi_kp4_abacus_cubicbox_{xi/pk}_lrg.pkl`\n",
    "* `desi_kp4_ezmock_cubicbox_{xi/pk}_lrg.pkl`\n",
    "* `desi_kp4_abacus_cutsky_{xi/pk}_lrg_zmin{0.4/0.6/0.8}_zmax{0.6/0.8/1.1}.pkl`\n",
    "* `desi_kp4_ezmock_cutsky_{xi/pk}_lrg_zmin{0.4/0.6/0.8}_zmax{0.6/0.8/1.1}.pkl`\n",
    "\n",
    "I anticipate there being more as we introduce more tracers etc., but the code for producing them should be extendable easily enough. This notebook covers the details of how these get read in, how to make some plots with them, and how to run some simple optimisations and sanity checks with different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169fc370-a724-4073-92a5-56251ad5638f",
   "metadata": {},
   "source": [
    "## Reading in the data\n",
    "I've already created classes for the KP4 data. You can find them in `/barry/datasets/dataset_power_spectrum.py` and `/barry/dataset/dataset_correlation_function.py`. These are currently coded up to only read in the LRG samples above, but again can be extended easily enough for other tracers.\n",
    "\n",
    "The way you get the data is by instantiating the class, with an appropriate set of arguments. Some of these arguments determine how the data will be treated. The others tell the code which of the files above to read in. The full set of (accessible) arguments for the power spectrum is:\n",
    "\n",
    "* `min_k`: The minimum k-value to consider. Default is 0.02\n",
    "* `max_k`: The maximum k-value to consider. Default is 0.30\n",
    "* `recon`: Whether to use pre- or post-reconstruction data. Choices are `None`, \"iso\", \"ani\" or \"sym\", but only `None` is currently implemented. Default is `None`\n",
    "* `reduce_cov_factor`: Factor to divide the covariance matrix by. Default is 1.0\n",
    "* `realisation`: The realisation to load. Choices are \"data\", `None` (mock mean), or an integer (mock realisation). Default is `None`.\n",
    "* `fit_poles`: A list of multipoles to consider in the fitting. Default is `(0,)`.\n",
    "* `mocktype`: Which KP4 mocks to load. Choices are \"abacus_cubicbox\", \"abacus_cutsky\", \"ezmock_cubicbox\", \"ezmock_cutsky\". Default is \"abacus_cubicbox\". **All files use the EZmock covariance matrix, but are otherwise separated to give access to the individual realisations for each mock type.**.\n",
    "* `num_mocks`: The number of mocks used to estimate the covariance matrix, for HARTLAP or SELLENTIN corrections. Default is 1000. **This is correct for all mocks, even abacus, as we use the EZmock covariance matrices**.\n",
    "* `fake_diag`: If True, use only the diagonals of the covariance matrix. Default is False.\n",
    "* `tracer`: Which tracer to load. Only \"lrg\" is currently implemented, which is the default.\n",
    "* `redshift_bin`: Which redshift bin to load. Choices change based on `tracer` and `mocktype`. Default is 1.\n",
    "    * `tracer=lrg`.\n",
    "        * 1 for `mocktype=\"abacus_cubicbox\"` or `mocktype=\"ezmock_cubicbox\"`. \n",
    "        * 1, 2 or 3 for `mocktype=\"abacus_cutsky\"` or `mocktype=\"ezmock_cutsky\"`.\n",
    "        \n",
    "The arguments are the same for the correlation function, except for `min_dist` and `max_dist` instead of `min_k` and `max_k`.\n",
    "        \n",
    "The only real relevant functions for the class are:\n",
    "* `get_data()`: Return a list of dictionaries for the data\n",
    "* `set_realisation()`: Useful for changing the realisation you are using without re-initialising the class.\n",
    "\n",
    "Let's try these out and plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2328c8a-3d70-4e85-97cd-c4d6c3604d5d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from barry.datasets.dataset_power_spectrum import PowerSpectrum_DESI_KP4\n",
    "from barry.datasets.dataset_correlation_function import CorrelationFunction_DESI_KP4\n",
    "\n",
    "# Lets read in a single instance of the data and have a look\n",
    "dataset = PowerSpectrum_DESI_KP4(mocktype=\"abacus_cutsky\")\n",
    "data = dataset.get_data()[0]\n",
    "print(data)\n",
    "\n",
    "# Lets read in a single instance of the data and have a look\n",
    "dataset = CorrelationFunction_DESI_KP4(mocktype=\"ezmock_cubicbox\")\n",
    "data = dataset.get_data()[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e2d48-4835-4ff4-9cc7-d389a4c694f3",
   "metadata": {},
   "source": [
    "This prints out a lot of information about the dataset! Most of it is just useful for the fitting (i.e., window functions, inverse covariance matrices, masking the appropriate fitting ranges), but we might want to access some of it directly. For instance, we can plot the data using the \"ks\", \"cov\" and \"pk0\", \"pk2\", \"pk4\" entries. For correlation function we can use \"s\", \"cov\", \"xi0\", \"xi2\" and \"xi4\". The \"num_mocks\" entry and \"cosmology\" (the fiducial cosmology) might be useful too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93707e-9274-4280-85b6-6b59e54cdd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pk(dataset):\n",
    "    \n",
    "    color = [\"r\", \"b\", \"g\"]\n",
    "    label = [r\"$P_{0}(k)$\", r\"$P_{2}(k)$\", r\"$P_{4}(k)$\"]\n",
    "    \n",
    "    # Plot some pk data\n",
    "    for m, pk in enumerate([\"pk0\", \"pk2\", \"pk4\"]):\n",
    "        dataset.set_realisation(None) # Sets the data to the mock mean.\n",
    "        data = dataset.get_data()[0]\n",
    "        ks, err = data[\"ks\"], np.sqrt(np.diag(data[\"cov\"]))\n",
    "        yerr = ks * err[2 * m * len(ks) : (2 * m + 1) * len(ks)]\n",
    "        plt.errorbar(\n",
    "            ks,\n",
    "            ks * data[pk][0],\n",
    "            yerr=yerr,\n",
    "            marker=\"o\",\n",
    "            ls=\"None\",\n",
    "            c=color[m],\n",
    "            label=label[m],\n",
    "        )\n",
    "        for i in range(len(dataset.mock_data)):\n",
    "            dataset.set_realisation(i)  # Changes the realisation to one of the mocks, and plots that.\n",
    "            data = dataset.get_data()[0]\n",
    "            plt.errorbar(ks, ks * data[pk][0], marker=\"None\", ls=\"-\", c=\"k\", alpha=1.0 / len(dataset.mock_data)**(3.0/4.0))\n",
    "    plt.xlabel(r\"$k$\")\n",
    "    plt.ylabel(r\"$k\\,P(k)$\")\n",
    "    plt.title(dataset.name)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_xi(dataset):\n",
    "    \n",
    "    color = [\"r\", \"b\", \"g\"]\n",
    "    label = [r\"$\\xi_{0}(k)$\", r\"$\\xi_{2}(k)$\", r\"$\\xi_{4}(k)$\"]\n",
    "    \n",
    "    # Plot sxome xi data\n",
    "    for m, xi in enumerate([\"xi0\", \"xi2\", \"xi4\"]):\n",
    "        dataset.set_realisation(None) # Sets the data to the mock mean.\n",
    "        data = dataset.get_data()[0]\n",
    "        ss, err = data[\"dist\"], np.sqrt(np.diag(data[\"cov\"]))\n",
    "        yerr = ss ** 2 * err[m * len(ss) : (m + 1) * len(ss)]\n",
    "        plt.errorbar(\n",
    "            ss,\n",
    "            ss ** 2 * data[xi],\n",
    "            yerr=yerr,\n",
    "            marker=\"o\",\n",
    "            ls=\"None\",\n",
    "            c=color[m],\n",
    "            label=label[m],\n",
    "        )\n",
    "        for i in range(len(dataset.mock_data)):\n",
    "            dataset.set_realisation(i)  # Changes the realisation to one of the mocks, and plots that.\n",
    "            data = dataset.get_data()[0]\n",
    "            plt.errorbar(ss, ss ** 2 * data[xi], marker=\"None\", ls=\"-\", c='k', alpha=1.0 / len(dataset.mock_data)**(3.0/4.0))\n",
    "    plt.xlabel(r\"$s$\")\n",
    "    plt.ylabel(r\"$s^{2}\\,\\xi(s)$\")\n",
    "    plt.title(dataset.name)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "dataset = PowerSpectrum_DESI_KP4()\n",
    "plot_pk(dataset)\n",
    "\n",
    "dataset = CorrelationFunction_DESI_KP4()\n",
    "plot_xi(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c477760-eb2e-4c3c-aaa0-2a60a9d1baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a different k-range, mock type and redshift bin\n",
    "dataset = PowerSpectrum_DESI_KP4(mocktype=\"abacus_cutsky\", min_k=0.0, max_k=0.25, redshift_bin=1)\n",
    "plot_pk(dataset)\n",
    "\n",
    "# Let's try a different s-range, mock type and redshift bin\n",
    "dataset = CorrelationFunction_DESI_KP4(mocktype=\"abacus_cutsky\", min_dist=50.0, max_dist=170.0, redshift_bin=3)\n",
    "plot_xi(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7ed3d-98d8-4b35-adab-68bad2b640b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try all the possible tracers, mocktypes and redshift bins\n",
    "tracers = [\"lrg\", \"lrg\", \"lrg\", \"lrg\"]\n",
    "nzbins = [1, 3, 1, 3]\n",
    "mocktypes = [\"abacus_cubicbox\", \"abacus_cutsky\", \"ezmock_cubicbox\", \"ezmock_cutsky\"]\n",
    "for j, (tracer, redshift_bins, mocktype) in enumerate(zip(tracers, nzbins, mocktypes)):\n",
    "    for z in range(redshift_bins):\n",
    "        plot_pk(PowerSpectrum_DESI_KP4(\n",
    "            recon=None,\n",
    "            fit_poles=[0, 2, 4],\n",
    "            min_k=0.02,\n",
    "            max_k=0.30,\n",
    "            mocktype=mocktype,\n",
    "            tracer=tracer,\n",
    "            redshift_bin=z + 1,\n",
    "            realisation=None,\n",
    "        ))\n",
    "        plot_xi(CorrelationFunction_DESI_KP4(\n",
    "            recon=None,\n",
    "            fit_poles=[0, 2, 4],\n",
    "            min_dist=30.0,\n",
    "            max_dist=200.0,\n",
    "            mocktype=mocktype,\n",
    "            tracer=tracer,\n",
    "            redshift_bin=z + 1,\n",
    "            realisation=None,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae0ef8-1158-4e66-8dab-39f6f66b2ff6",
   "metadata": {},
   "source": [
    "# Models\n",
    "Okay. Now we have a handle on the datasets, and how to load them in, let's see about running a fit. The first thing we need to do is choose a model. Barry currently has the following options:\n",
    "* `bao_power_Beutler2017`: Model as in Beutler et. al., 2017 with free damping parameters\n",
    "* `bao_power_Chen2019`: Model as in Chen et. al., 2019 with Zeldovich approximation based BAO damping\n",
    "* `bao_power_Ding2018`: Model as in Ding et. al., 2018 with EFT-based model\n",
    "* `bao_power_Seo2016`: Model as in Seo et. al., 2016 with LPT inspired BAO damping.\n",
    "* `bao_correlation_Beutler2017`: Correlation function transformation applied to Beutler et. al., 2017 power spectrum with free damping parameters\n",
    "* `bao_correlation_Ding2018`: Correlation function transformation applied to Ding et. al., 2018 power spectrum with EFT-based model\n",
    "* `bao_correlation_Seo2016`: Correlation function transformation applied to Seo et. al., 2016 power spectrum with LPT inspired BAO damping.\n",
    "\n",
    "Each of these also has different free parameters that can be allowed to vary or be fixed. Power spectra support 0, 3 or 5 polynomial terms added to each multipole, correlation function is currently just 3. \n",
    "\n",
    "The models work as classes, and have the following (relevant) keyword arguments:\n",
    "* `fix_params`: A list of parameters to fix in the model.\n",
    "* `recon`: A reconstruction convention, same options as for data. Easiest to set as recon=dataset.recon.\n",
    "* `smooth`: Whether to return a model with (`False`) or without (`True`) BAO wiggles. Default is `True`.\n",
    "* `correction:` A correction to use for the likelihood to account for the errors in the covariance matrix. Corrections are also classes, but typically we'll want Correction.NONE, Correction.HARTLAP or Correction.SELLENTIN.\n",
    "* `isotropic`: Whether to fit for only alpha, or for alpha and epsilon.\n",
    "* `poly_poles`: Which multipoles to add polynomial terms to.\n",
    "* `marg`: Whether to speed things up by analytically marginalising over linear order broadband terms. Options are `None`, \"full\" (proper Bayesian marginalisation) or \"partial\" (find the best-fit polynomial terms at each point in the MCMC chain).\n",
    "* `dilate_smooth`: For the Beutler 2017 power spectrum model only, whether to dilate only the wiggles of the model (`False`), or the whole model (`True`), by the BAO dilation parameters. Default is True.\n",
    "* `n_poly`: Only for power spectrum. The number of polynomial terms per multipole. Default is 5.\n",
    "\n",
    "So lets have a look at creating and plotting some models! Useful functions are:\n",
    "* `get_defaults()`: Return a set of default parameter values.\n",
    "* `set_default(param, value)`: Update the default value for a parameter.\n",
    "* `get_param_dict(params)`: Set the values of the parameters to the values in params and return a dictionary.\n",
    "* `set_cosmology(cosmo)`: Set the template cosmology given a dictionary of cosmology parameters.\n",
    "* `compute_power_spectrum(k, param_dict)`: Compute the model for a dictionary of parameter values.\n",
    "* `set_data(dataset)`: Set the model up to return a prediction for some data. Set's up the template cosmology to the fiducial cosmology of the data, organises the k-binning and window function convolution for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e949a-6bc9-4ed5-9fc6-1363d3917b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from barry.models.bao_power_Beutler2017 import PowerBeutler2017\n",
    "\n",
    "# Instantiate a model.\n",
    "model_iso = PowerBeutler2017(isotropic=True)\n",
    "model_ani = PowerBeutler2017(isotropic=False)\n",
    "\n",
    "# Get the default values of the model and also as a dictionary. You should see that the\n",
    "# anisotropic model has a lot more polynomial terms and also separate BAO damping perpendicular and parallel\n",
    "# to the line of sight. This is because it fits the multipoles, rather than just the monopole.\n",
    "p_dict_iso = model_iso.get_param_dict(model_iso.get_defaults())\n",
    "p_dict_ani = model_ani.get_param_dict(model_ani.get_defaults())\n",
    "print(p_dict_iso, p_dict_ani)\n",
    "\n",
    "# Let's see some other combos. Include polynomials for hexadecapole:\n",
    "model = PowerBeutler2017(isotropic=False, poly_poles=(0,2,4)) \n",
    "# Fix the BAO damping parameters and beta=f/b to their default values:\n",
    "model = PowerBeutler2017(isotropic=False, poly_poles=(0,2,4), fix_params=(\"sigma_nl_perp\", \"sigma_nl_par\", \"beta\"))\n",
    "\n",
    "# Update the default values of the sigma_nl's. The default is 4 and 8 for perp and par respectively.\n",
    "# You can see these get updated to 5 and 11.\n",
    "print(model.get_param_dict(model.get_defaults()))\n",
    "model.set_default(\"sigma_nl_perp\", 5.0)\n",
    "model.set_default(\"sigma_nl_par\", 11.0)\n",
    "print(model.get_param_dict(model.get_defaults()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e454a504-c762-43b8-b81d-c90d7602232b",
   "metadata": {},
   "source": [
    "To return the actual model prediction, we need to first tell the model what the template cosmology is, then compute it. We'll start with unmarginalised models, as these return the actual model, rather than components. For fitting purposes it's better to use `marg=\"full\"`, but it's less interpretable what the model is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ca650-c481-49a8-83a7-b0ccab956869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from barry.models.bao_power_Ding2018 import PowerDing2018\n",
    "\n",
    "cosmology = {\n",
    "            \"om\": 0.31,\n",
    "            \"h0\": 0.67,\n",
    "            \"z\":  0.51,\n",
    "            \"ob\": 0.048,\n",
    "            \"ns\": 0.97,\n",
    "            \"mnu\": 0.0,\n",
    "            \"reconsmoothscale\": 15,\n",
    "        }\n",
    "model = PowerDing2018(isotropic=False)\n",
    "model.set_cosmology(cosmology)\n",
    "ks = model.camb.ks\n",
    "\n",
    "# This function returns the values of k'(k,mu), pk (technically only the unmarginalised terms)\n",
    "# and model components for analytically marginalised parameters\n",
    "p = model.get_param_dict(model.get_defaults())\n",
    "kprime, pk, marged = model.compute_power_spectrum(ks, p)\n",
    "\n",
    "# Plot the model multipoles\n",
    "plt.errorbar(ks, ks * pk[0], marker=\"None\", ls=\"-\", c=\"r\", label=r\"$P_{0}(k)$\")\n",
    "plt.errorbar(ks, ks * pk[2], marker=\"None\", ls=\"-\", c=\"b\", label=r\"$P_{2}(k)$\")\n",
    "plt.errorbar(ks, ks * pk[4], marker=\"None\", ls=\"-\", c=\"g\", label=r\"$P_{4}(k)$\")\n",
    "\n",
    "# Update alpha and epsilon, and show a comparison\n",
    "p[\"alpha\"] = 1.05\n",
    "p[\"epsilon\"] = -0.04\n",
    "kprime, pk_new, marged = model.compute_power_spectrum(ks, p)\n",
    "\n",
    "# Plot the model multipoles\n",
    "plt.errorbar(ks, ks * pk_new[0], marker=\"None\", ls=\"--\", c=\"r\", label=r\"$P_{0}(k)$\")\n",
    "plt.errorbar(ks, ks * pk_new[2], marker=\"None\", ls=\"--\", c=\"b\", label=r\"$P_{2}(k)$\")\n",
    "plt.errorbar(ks, ks * pk_new[4], marker=\"None\", ls=\"--\", c=\"g\", label=r\"$P_{4}(k)$\")\n",
    "plt.xlim(0.0, 0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f600005-f2e0-416b-a652-067fc9ad4ce8",
   "metadata": {},
   "source": [
    "## Including the window function and data binning\n",
    "To include the window function/wide angle matrix (for power spectra) and data binning we need to tell the model the properties of the data. We do this by loading a dataset, running `get_data()` on this, and then `set_data()` for the model. Setting the data for the model also sets the template cosmology of the model to the fiducial cosmology of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b1902-8bc3-422f-ad61-9b3e6b26cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a dataset\n",
    "dataset = PowerSpectrum_DESI_KP4(mocktype=\"abacus_cutsky\", fit_poles=(0,2,4), min_k=0.02, max_k=0.25, redshift_bin=1)\n",
    "data = dataset.get_data()\n",
    "\n",
    "# Set up a model and tell it about the data\n",
    "model = PowerBeutler2017(isotropic=False, poly_poles=(0,2), marg=None)\n",
    "model.set_data(data)\n",
    "\n",
    "# Get the model without window function convolution\n",
    "p = model.get_param_dict(model.get_defaults())\n",
    "kprime, pk, marged = model.compute_power_spectrum(ks, p)\n",
    "\n",
    "# And now with window function convolution\n",
    "kout = data[0][\"ks_output\"]\n",
    "pk_win, pk_win_odd, marged_win, marged_win_odd, mask = model.get_model(p, data[0])\n",
    "\n",
    "# Plot the convolved model multipoles\n",
    "plt.errorbar(ks, ks * pk[0], marker=\"None\", ls=\"-\", c=\"r\", label=r\"$P_{0}(k)$\")\n",
    "plt.errorbar(ks, ks * pk[2], marker=\"None\", ls=\"-\", c=\"b\", label=r\"$P_{2}(k)$\")\n",
    "plt.errorbar(ks, ks * pk[4], marker=\"None\", ls=\"-\", c=\"g\", label=r\"$P_{4}(k)$\")\n",
    "plt.errorbar(kout, kout * pk_win[:len(kout)], marker=\"None\", ls=\"--\", c=\"r\")\n",
    "plt.errorbar(kout, kout * pk_win[2*len(kout):3*len(kout)], marker=\"None\", ls=\"--\", c=\"b\")\n",
    "plt.errorbar(kout, kout * pk_win[4*len(kout):5*len(kout)], marker=\"None\", ls=\"--\", c=\"g\")\n",
    "plt.xlim(0.0, 0.3)\n",
    "plt.show()\n",
    "\n",
    "# Odd multipoles\n",
    "plt.errorbar(kout, kout * pk_win[1*len(kout):2*len(kout)], marker=\"None\", ls=\"--\", c=\"r\")\n",
    "plt.errorbar(kout, kout * pk_win[3*len(kout):4*len(kout)], marker=\"None\", ls=\"--\", c=\"b\")\n",
    "plt.xlim(0.0, 0.3)\n",
    "plt.show()\n",
    "\n",
    "# And now masked to the data fitting ranges\n",
    "kmasked = data[0][\"ks\"]\n",
    "pk_masked, pk_masked_odd = pk_win[mask], pk_win_odd[mask]\n",
    "\n",
    "# Model multipoles at data bins we are including in the fit\n",
    "plt.errorbar(ks, ks * pk[0], marker=\"None\", ls=\"-\", c=\"r\", label=r\"$P_{0}(k)$\")\n",
    "plt.errorbar(ks, ks * pk[2], marker=\"None\", ls=\"-\", c=\"b\", label=r\"$P_{2}(k)$\")\n",
    "plt.errorbar(ks, ks * pk[4], marker=\"None\", ls=\"-\", c=\"g\", label=r\"$P_{4}(k)$\")\n",
    "plt.errorbar(kmasked, kmasked * pk_masked[:len(kmasked)], marker=\"None\", ls=\"--\", c=\"r\")\n",
    "plt.errorbar(kmasked, kmasked * pk_masked[len(kmasked):2*len(kmasked)], marker=\"None\", ls=\"--\", c=\"b\")\n",
    "plt.errorbar(kmasked, kmasked * pk_masked[2*len(kmasked):3*len(kmasked)], marker=\"None\", ls=\"--\", c=\"g\")\n",
    "plt.xlim(0.0, 0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d104e72-fcc6-44af-8b09-f8049216b28f",
   "metadata": {},
   "source": [
    "# Fitting the data\n",
    "Okay, now let's do some proper fits. We first set the data, then we can run any fits we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e9789b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# We can import in this way too as everything is indexed in the relevant __init__.py files\n",
    "from barry.datasets import PowerSpectrum_DESI_KP4, CorrelationFunction_DESI_KP4\n",
    "from barry.models import PowerBeutler2017, PowerDing2018, CorrBeutler2017, CorrSeo2016\n",
    "\n",
    "# Load in the z=0.4-0.6 ezmock_cutsky dataset with and without the hexadecapole included in the fit\n",
    "pk_dataset = PowerSpectrum_DESI_KP4(mocktype=\"abacus_cubicbox\", fit_poles=(0,2), min_k=0.02, max_k=0.30, redshift_bin=1)\n",
    "pk_dataset_hexa = PowerSpectrum_DESI_KP4(mocktype=\"abacus_cubicbox\", fit_poles=(0,2,4), min_k=0.02, max_k=0.20, redshift_bin=1)\n",
    "xi_dataset = CorrelationFunction_DESI_KP4(mocktype=\"abacus_cubicbox\", fit_poles=(0,2), min_dist=35.0, max_dist=170.0, redshift_bin=1)\n",
    "xi_dataset_hexa = CorrelationFunction_DESI_KP4(mocktype=\"abacus_cubicbox\", fit_poles=(0,2,4), min_dist=50.0, max_dist=160.0, redshift_bin=1)\n",
    "\n",
    "# A random selection of model choices\n",
    "pk_model_ding = PowerDing2018(isotropic=False, poly_poles=(0,2), marg=\"full\")\n",
    "pk_model_beutler = PowerBeutler2017(isotropic=False, poly_poles=(0,2,4), marg=\"full\", n_poly=3, dilate_smooth=False)\n",
    "xi_model_beutler = CorrSeo2016(isotropic=False, poly_poles=(0,2), marg=\"full\")\n",
    "xi_model_seo = CorrBeutler2017(isotropic=False, poly_poles=(0,2,4), marg=\"full\")\n",
    "\n",
    "# Loop over all the model and appropriate dataset and run an opimisation on each one.\n",
    "names = [\"pk_model_ding\", \"pk_model_beutler\", \"xi_model_beutler\", \"xi_model_seo\"]\n",
    "datasets = [pk_dataset, pk_dataset_hexa, xi_dataset, xi_dataset_hexa]\n",
    "models = [pk_model_ding, pk_model_beutler, xi_model_beutler, xi_model_seo]\n",
    "for i, (name, dataset, model) in enumerate(zip(names, datasets, models)):\n",
    "    data = dataset.get_data()[0]\n",
    "    model.set_data(dataset.get_data())\n",
    "    print(\"Starting model optimisation. This may take some time.\")\n",
    "    p, maxlike = model.optimize()\n",
    "    print(name)\n",
    "    print(\"alpha, epsilon:\", p[\"alpha\"], p[\"epsilon\"])\n",
    "    print(\"alpha_par, alpha_perp:\", model.get_alphas(p[\"alpha\"], p[\"epsilon\"]))\n",
    "    print(\"-------------\")\n",
    "    # A convenient plotting function for the best-fit, very useful as pk/xi from compute_power_spectrum or \n",
    "    # compute_correlation_function is tough to interpret when using analytic marginalisation\n",
    "    model.plot(p)\n",
    "\n",
    "# the model.plot function can also be used to return useful things without the plot -- \n",
    "# chi2, degrees-of-freedom, best-fit values of any analytically marginalised parameters, \n",
    "# the best-fit model multipoles, and the best-fit smooth model multipoles\n",
    "new_chi_squared, dof, bband, mods, smooths = model.plot(p, display=False)\n",
    "\n",
    "# The previous set of functions to fit a model to data are also wrapped up in a convenient `sanity_check()` function.\n",
    "model.sanity_check(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62862ec0-e208-4a74-861e-e83db8b80e9a",
   "metadata": {},
   "source": [
    "And there we go! To run proper MCMC fits to the data, we also need to set up a sampler. There are currently the following scripts in the repo to fit all the KP4 data\n",
    "* /config/desi_kp4/desi_kp4_abacus_cubic_pk.py\n",
    "* /config/desi_kp4/desi_kp4_abacus_cubic_xi.py\n",
    "* /config/desi_kp4/desi_kp4_abacus_pk.py\n",
    "* /config/desi_kp4/desi_kp4_abacus_xi.py\n",
    "\n",
    "Each one can be run as a python code from the login node on NERSC (assuming you have set your environment as in the NERSC.md), i.e., `python desi_kp4_abacus_cubic_pk.py`. This will prepare and submit all the jobs for you, fitting the mock mean and 25 realisations for each redshift.\n",
    "\n",
    "Once the chains have finished running, if you the code again using i.e., `python desi_kp4_abacus_cubic_pk.py plot` it will read in the existing chains and make summary plots and files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd6b01-d570-46b4-84ce-a5e103201504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barry_env_desiproject_aw",
   "language": "python",
   "name": "barry_env_desiproject_aw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
